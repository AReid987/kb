{"version":3,"sources":["../../src/cache.ts","../../src/utils.ts","../../src/lint-result.ts","../../src/config.ts","../../src/constants.ts","../../src/rule.ts","../../src/rule-utils.ts","../../rules/custom/index.ts","../../rules/custom/effective-tsconfig.ts","../../rules/custom/prefer-fetch-over-axios.ts","../../src/built-in-rules.json","../../src/default-config.ts","../../src/lint-file.ts","../../src/errors.ts","../../src/gritql.ts","../../src/rule-violations.ts","../../src/markdown-utils.ts","../../src/parse-structured-output.ts","../../src/lint-files.ts","../../src/lint-task.ts","../../src/parse-inline-config.ts","../../src/pre-process-task.ts","../../src/parse-rule-file.ts","../../src/resolve-files.ts","../../src/is-valid-source-file.ts","../../src/is-binary-file.ts","../../src/resolve-rules.ts"],"sourcesContent":["import fsSync from 'node:fs'\nimport fs from 'node:fs/promises'\nimport path from 'node:path'\n\nimport { asyncExitHook } from 'exit-hook'\nimport stableStringify from 'fast-json-stable-stringify'\nimport hashObject from 'hash-object'\nimport { pathExists } from 'path-exists'\n\nimport type * as types from './types.js'\nimport { assert, pick, pruneUndefined } from './utils.js'\n\n/**\n * Content-based cache of previous linter results.\n */\nexport class LinterCache<\n  TKey extends string = string,\n  TValue extends object = types.LintResult\n> {\n  noCache: boolean\n  dryRun: boolean\n  cacheDir?: string\n  cacheFile?: string\n  cache?: Record<string, string>\n\n  protected _exitHookCleanupFn?: () => void\n\n  constructor({\n    cacheDir,\n    cacheFileName = 'cache.json',\n    noCache = false,\n    dryRun = false\n  }: {\n    cacheDir?: string\n    cacheFileName?: string\n    noCache?: boolean\n    dryRun?: boolean\n  }) {\n    this.cacheDir = cacheDir\n    this.noCache = !!noCache\n    this.dryRun = !!dryRun\n    this.cacheFile = this.cacheDir\n      ? path.join(this.cacheDir, cacheFileName)\n      : undefined\n\n    this._exitHookCleanupFn = asyncExitHook(() => this.close(), {\n      wait: 1000\n    })\n  }\n\n  async init(): Promise<this> {\n    if (this.cache) return this\n    this.cache = {}\n\n    // console.log('cache', {\n    //   cacheDir: this.cacheDir,\n    //   cacheFile: this.cacheFile,\n    //   noCache: this.noCache\n    // })\n\n    if (!this.cacheDir) {\n      return this\n    }\n\n    const cacheFile = this.cacheFile!\n\n    try {\n      await fs.mkdir(this.cacheDir, { recursive: true })\n\n      if (await pathExists(cacheFile)) {\n        const encodedCache = fsSync.readFileSync(cacheFile, {\n          encoding: 'utf8'\n        })\n\n        this.cache = JSON.parse(encodedCache) as Record<string, string>\n      }\n    } catch (err: any) {\n      console.warn(\n        `Failed to initialize cache \"${cacheFile}\". Continuing with empty cache.`,\n        err.message\n      )\n    }\n\n    return this\n  }\n\n  async close() {\n    if (this._exitHookCleanupFn) {\n      this.flush()\n      delete this.cache\n      delete this._exitHookCleanupFn\n    }\n  }\n\n  async get(key: TKey): Promise<TValue | undefined> {\n    if (this.noCache) return\n\n    assert(this.cache, 'Must call LinterCache.init')\n    const encodedValue = this.cache[key]\n\n    if (encodedValue === undefined) {\n      return undefined\n    } else {\n      const decodedValue = JSON.parse(encodedValue) as TValue\n      return decodedValue\n    }\n  }\n\n  async set(key: TKey, value: TValue) {\n    assert(this.cache, 'Must call LinterCache.init')\n    const encodedValue = JSON.stringify(value)\n    this.cache[key] = encodedValue\n\n    // TODO: don't write the value every time or move to a different local json db abstraction\n    await this.flush()\n  }\n\n  async flush() {\n    if (!this.cache || this.dryRun) return\n\n    const cacheFile = this.cacheFile\n    if (cacheFile) {\n      await fs.mkdir(this.cacheDir!, { recursive: true })\n      if (!this.cache) return\n\n      fsSync.writeFileSync(cacheFile, stableStringify(this.cache), {\n        encoding: 'utf8'\n      })\n    }\n  }\n}\n\nexport async function createLinterCache<\n  TKey extends string = string,\n  TValue extends object = types.LintResult\n>(config: types.ResolvedLinterConfig): Promise<LinterCache<TKey, TValue>> {\n  const cache = new LinterCache<TKey, TValue>({\n    cacheDir: config.linterOptions.cacheDir,\n    noCache: config.linterOptions.noCache,\n    dryRun: config.linterOptions.dryRun\n  })\n  await cache.init()\n  return cache\n}\n\nexport function createCacheKey({\n  rule,\n  file,\n  config,\n  ...extra\n}: {\n  rule: types.Rule\n  file?: types.SourceFile\n  config: types.LinterConfig\n} & Record<string, unknown>): string {\n  // TODO: add linter major version to the cache key\n  const cacheKeySource = pruneUndefined({\n    ...extra,\n\n    file: file\n      ? // Only keep the relative file path, content, and detected language\n        pruneUndefined(pick(file, 'fileRelativePath', 'content', 'language'))\n      : undefined,\n\n    // Only keep the rule fields which affect the linting logic\n    rule: pruneUndefined(\n      pick(\n        rule,\n        'name',\n        'title',\n        'description',\n        'positiveExamples',\n        'negativeExamples',\n        'level',\n        'scope',\n        'model',\n        'languages',\n        'gritql',\n        'gritqlNumLinesContext'\n        // TODO: include / exclude? languages?\n      )\n    ),\n\n    // Ensure the cache key depends on how the LLM is parameterized\n    llmOptions: pruneUndefined(\n      pick(\n        config.llmOptions ?? {},\n        'model',\n        'weakModel',\n        'temperature',\n        'apiBaseUrl'\n      )\n    ),\n\n    linterOptions: pruneUndefined(pick(config.linterOptions ?? {}, 'noGrit'))\n  })\n\n  return hashObject(cacheKeySource)\n}\n","import path from 'node:path'\nimport { fileURLToPath } from 'node:url'\n\nimport chalk from 'chalk'\nimport { gracefulExit } from 'exit-hook'\nimport { globby, type Options as GlobbyOptions } from 'globby'\nimport multimatch from 'multimatch'\n\nimport type * as types from './types.js'\nimport { getLintDurationMs } from './lint-result.js'\n\nexport { default as slugify } from '@sindresorhus/slugify'\nexport { default as dedupe } from 'array-uniq'\nexport { default as assert } from 'tiny-invariant'\n\n/**\n * From `inputObj`, create a new object that does not include `keys`.\n *\n * @example\n * ```js\n * omit({ a: 1, b: 2, c: 3 }, 'a', 'c') // { b: 2 }\n * ```\n */\nexport const omit = <\n  T extends Record<any, unknown>,\n  K extends keyof T = keyof T\n>(\n  inputObj: T,\n  ...keys: K[]\n): Omit<T, K> => {\n  const keysSet = new Set(keys)\n  return Object.fromEntries(\n    Object.entries(inputObj).filter(([k]) => !keysSet.has(k as any))\n  ) as any\n}\n\n/**\n * From `inputObj`, create a new object that only includes `keys`.\n *\n * @example\n * ```js\n * pick({ a: 1, b: 2, c: 3 }, 'a', 'c') // { a: 1, c: 3 }\n * ```\n */\nexport const pick = <\n  T extends Record<any, unknown>,\n  K extends keyof T = keyof T\n>(\n  inputObj: T,\n  ...keys: K[]\n): Pick<T, K> => {\n  const keysSet = new Set(keys)\n  return Object.fromEntries(\n    Object.entries(inputObj).filter(([k]) => keysSet.has(k as any))\n  ) as any\n}\n\nexport function pruneUndefined<T extends Record<string, any>>(\n  obj: T\n): NonNullable<T> {\n  return Object.fromEntries(\n    Object.entries(obj).filter(([, value]) => value !== undefined)\n  ) as NonNullable<T>\n}\n\n// TODO: consider using `cli-truncate` instead\nexport function trimMessage(\n  message: string | undefined,\n  { maxLength = 80 }: { maxLength?: number } = {}\n): string {\n  if (!message) return ''\n\n  message = message.trim().split('\\n')[0]!.trim()\n  if (message.length < maxLength) return message\n  message = `${message.slice(0, maxLength - 3)}...`\n\n  return message\n}\n\nexport function createEvalStats(): types.EvalStats {\n  return {\n    numFiles: 0,\n    numRules: 0,\n    numUnexpectedErrors: 0,\n    numFalseNegatives: 0,\n    numFalsePositives: 0,\n    numTrueNegatives: 0,\n    numTruePositives: 0\n  }\n}\n\nexport function mergeEvalStats(\n  evalStatsA: types.EvalStats,\n  evalStatsB: types.EvalStats\n): types.EvalStats {\n  return {\n    numFiles: evalStatsA.numFiles + evalStatsB.numFiles,\n    numRules: evalStatsA.numRules + evalStatsB.numRules,\n    numUnexpectedErrors:\n      evalStatsA.numUnexpectedErrors + evalStatsB.numUnexpectedErrors,\n    numFalseNegatives:\n      evalStatsA.numFalseNegatives + evalStatsB.numFalseNegatives,\n    numFalsePositives:\n      evalStatsA.numFalsePositives + evalStatsB.numFalsePositives,\n    numTrueNegatives: evalStatsA.numTrueNegatives + evalStatsB.numTrueNegatives,\n    numTruePositives: evalStatsA.numTruePositives + evalStatsB.numTruePositives\n  }\n}\n\nconst knownSupportedCodeFileExtensions = new Set([\n  'js',\n  'ts',\n  'mjs',\n  'cjs',\n  'jsx',\n  'tsx',\n  'py',\n  'r',\n  'rb',\n  'html',\n  'md',\n  'c',\n  'cpp',\n  'cs',\n  'h',\n  'go',\n  'java',\n  'lisp',\n  'lua',\n  'css',\n  'scss',\n  'swift',\n  'svg',\n  'tcl',\n  'txt',\n  'csv',\n  'tsv',\n  'yaml',\n  'json',\n  'elm',\n  'sh',\n  'bash',\n  'fish',\n  'd',\n  'dart'\n])\n\nconst knownCodeFileMappings: Record<string, string> = {\n  javascript: 'js',\n  typescript: 'ts',\n  markdown: 'md',\n  python: 'py',\n  text: 'txt'\n}\n\nexport function inferBestPossibleCodeFileExtension(\n  lang?: string | null,\n  { fallbacks }: { fallbacks?: string[] } = {}\n): string | undefined {\n  function handleFallbacks() {\n    if (fallbacks) {\n      for (const fallback of fallbacks) {\n        const alias = inferBestPossibleCodeFileExtension(fallback)\n        if (alias) return alias\n      }\n    }\n\n    // Fallback to no file extension\n    return undefined\n  }\n\n  lang = lang?.trim().toLowerCase()\n\n  if (!lang) return handleFallbacks()\n\n  if (knownSupportedCodeFileExtensions.has(lang)) return lang\n\n  const alias = knownCodeFileMappings[lang]\n  if (alias) return alias\n\n  return handleFallbacks()\n}\n\nexport function getEnv(\n  name: string,\n  defaultValue?: string\n): string | undefined {\n  try {\n    return (\n      (typeof process !== 'undefined'\n        ? // eslint-disable-next-line no-process-env\n          process.env?.[name]\n        : undefined) ?? defaultValue\n    )\n  } catch {\n    return defaultValue\n  }\n}\n\nexport function logDebugConfig({\n  files,\n  rules,\n  config\n}: {\n  files?: types.SourceFile[]\n  rules?: types.Rule[]\n  config: types.ResolvedLinterConfig\n}) {\n  console.log(\n    `\\n${chalk.italic('logging resolved config and then exiting because `printConfig` is enabled')}`\n  )\n\n  const sanitizedConfig = config.getSanitizedDebugConfig()\n  console.log(\n    `\\n${chalk.bold('config')}`,\n    JSON.stringify(sanitizedConfig, undefined, 2)\n  )\n\n  if (rules) {\n    if (rules.length) {\n      console.log(\n        `\\n${chalk.bold('rules')}`,\n        JSON.stringify(\n          rules.map((rule) => ({\n            ...rule,\n            title: rule.title ? trimMessage(rule.title) : undefined,\n            description: rule.description\n              ? trimMessage(rule.description)\n              : undefined,\n            gritql: rule.gritql ? trimMessage(rule.gritql) : undefined,\n            negativeExamples: rule.negativeExamples\n              ? rule.negativeExamples.map((e) => ({\n                  ...e,\n                  code: trimMessage(e.code)\n                }))\n              : undefined,\n            positiveExamples: rule.positiveExamples\n              ? rule.positiveExamples.map((e) => ({\n                  ...e,\n                  code: trimMessage(e.code)\n                }))\n              : undefined\n          })),\n          undefined,\n          2\n        )\n      )\n    } else {\n      console.warn(`\\n${chalk.bold('warning: no rules found')}`)\n    }\n  }\n\n  if (files) {\n    if (files.length) {\n      console.log(\n        `\\n${chalk.bold('input files')}`,\n        JSON.stringify(\n          files.map((file) => file.fileRelativePath),\n          undefined,\n          2\n        )\n      )\n    } else {\n      console.warn(`\\n${chalk.bold('warning: no input source files found')}`)\n    }\n  }\n}\n\nexport function logLintResultStats({\n  lintResult,\n  config,\n  prefix\n}: {\n  lintResult: types.LintResult\n  config: types.ResolvedLinterConfig\n  prefix?: string\n}) {\n  const lintDurationMs = getLintDurationMs(lintResult)\n  const lintDuration = lintDurationMs\n    ? `${Math.ceil(lintDurationMs / 1000)}s`\n    : undefined\n\n  console.log(\n    `${prefix ?? ''}Linter stats; ${config.linterOptions.dryRun ? 'dry run estimated cost' : 'total cost'} $${(\n      lintResult.totalCost / 100\n    ).toFixed(2)}`,\n    pruneUndefined({\n      ...pick(config.llmOptions, 'model', 'weakModel'),\n      ...pick(\n        lintResult,\n        'numModelCalls',\n        'numModelCallsCached',\n        'numPromptTokens',\n        'numCompletionTokens',\n        'numTotalTokens'\n      ),\n      lintDuration\n    })\n  )\n}\n\nexport function logEvalStats({\n  evalStats\n}: // ruleToEvalStats\n{\n  evalStats: types.EvalStats\n  // ruleToEvalStats: Record<string, types.EvalStats>\n}) {\n  const precision =\n    evalStats.numTruePositives /\n    (evalStats.numTruePositives + evalStats.numFalsePositives)\n  const recall =\n    evalStats.numTruePositives /\n    (evalStats.numTruePositives + evalStats.numFalseNegatives)\n  const f1Score = (2 * precision * recall) / (precision + recall)\n  const extendedStats = {\n    precision,\n    recall,\n    f1Score\n  }\n\n  console.log(`\\nEval results`, { ...evalStats, ...extendedStats })\n  return extendedStats\n}\n\n/** Polyfill for `Promise.withResolvers()` */\nexport function createPromiseWithResolvers<\n  T = unknown\n>(): PromiseWithResolvers<T> {\n  let resolve: (value: T | PromiseLike<T>) => void\n  let reject: (reason: any) => void\n\n  const promise = new Promise<T>((res, rej) => {\n    resolve = res\n    reject = rej\n  })\n\n  return { promise, resolve: resolve!, reject: reject! }\n}\n\n/**\n * Wraps [globby](https://github.com/sindresorhus/globby) to correctly handle\n * absolute file patterns that exist outside of the `cwd`.\n */\nexport async function resolveGlobFilePatterns(\n  patternOrPatterns: string | readonly string[],\n  options?: GlobbyOptions\n): Promise<string[]> {\n  const patterns = Array.isArray(patternOrPatterns)\n    ? (patternOrPatterns as readonly string[])\n    : [patternOrPatterns as string]\n\n  const invalidPatterns = patterns.filter((pattern) => !pattern)\n  if (invalidPatterns.length) {\n    throw new Error(\n      `Invalid file glob empty pattern: \"${invalidPatterns.join(', ')}\"`\n    )\n  }\n\n  options = {\n    followSymbolicLinks: false,\n    ...options\n  }\n\n  const cwd = (options?.cwd as string) ?? process.cwd()\n  const absolutePatterns = patterns\n    .filter((pattern) => path.isAbsolute(pattern) || pattern.startsWith('..'))\n    .map((pattern) => path.relative(cwd, pattern))\n  const relativePatterns = patterns\n    .filter(\n      (pattern) => !(path.isAbsolute(pattern) || pattern.startsWith('..'))\n    )\n    .map((pattern) => path.relative(cwd, pattern))\n\n  // TODO: workaround this `globby` restriction\n  // TODO: this will involve returning absolute file paths from this function\n  // TODO: this will likely involve using `multimatch` directly\n  for (const pattern of absolutePatterns) {\n    if (/\\*/.test(pattern)) {\n      throw new Error(\n        `File globs must be local to cwd or not use \"*\" glob syntax: ${pattern}`\n      )\n    }\n  }\n\n  try {\n    // console.log('resolveGlobFilePatterns', {\n    //   relativePatterns,\n    //   absolutePatterns,\n    //   options\n    // })\n    const resolvedFilePatterns = await globby(relativePatterns, options)\n\n    return absolutePatterns.concat(resolvedFilePatterns)\n  } catch (err: any) {\n    console.error('error resolving glob patterns:', err.message)\n    throw err\n  }\n}\n\nexport function dirname(meta = import.meta) {\n  return meta.dirname ?? path.dirname(fileURLToPath(meta.url))\n}\n\nexport function fileMatchesIncludeExclude(\n  file: types.SourceFile,\n  {\n    include,\n    exclude\n  }: {\n    include?: string[]\n    exclude?: string[]\n  }\n) {\n  if (include) {\n    const matches = multimatch(file.fileRelativePath, include)\n    if (!matches.length) {\n      return false\n    }\n  }\n\n  if (exclude?.length) {\n    const matches = multimatch(file.fileRelativePath, exclude)\n    if (matches.length) {\n      return false\n    }\n  }\n\n  return true\n}\n\nexport function validateLinterInputs({\n  config,\n  files,\n  rules\n}: {\n  config: types.ResolvedLinterConfig\n  files?: types.SourceFile[]\n  rules?: types.Rule[]\n}): boolean {\n  if (config.linterOptions.printConfig) {\n    logDebugConfig({ files, rules, config })\n    gracefulExit(0)\n    return false\n  }\n\n  if (files && !files.length) {\n    console.error(\n      `\\n${chalk.bold('Error: no source files found')} (${chalk.italic('run with --print-config to debug')})\\n`\n    )\n    gracefulExit(1)\n    return false\n  }\n\n  if (rules && !rules.length) {\n    console.error(\n      `\\n${chalk.bold('Error: no rules enabled')} (${chalk.italic('run with --print-config to debug')})\\n`\n    )\n    console.error(\n      '\\nNote: If you want to use the built-in rules with a custom config file, you must enable tem explicitly: https://gptlint.dev/guide/config#config-file\\n'\n    )\n    gracefulExit(1)\n    return false\n  }\n\n  return true\n}\n","import type * as types from './types.js'\nimport { pruneUndefined } from './utils.js'\n\nexport function createLintResult(\n  partialLintResult?: Readonly<Partial<types.LintResult>>\n): types.LintResult {\n  return {\n    lintErrors: [],\n    skipped: false,\n    numModelCalls: 0,\n    numModelCallsCached: 0,\n    numPromptTokens: 0,\n    numCompletionTokens: 0,\n    numTotalTokens: 0,\n    totalCost: 0,\n    startedAtMs: Date.now(),\n    ...partialLintResult\n  }\n}\n\nexport function mergeLintResults(\n  lintResultA: types.LintResult,\n  lintResultB: types.LintResult\n): types.LintResult {\n  return {\n    lintErrors: lintResultA.lintErrors.concat(lintResultB.lintErrors),\n    skipped: lintResultA.skipped || lintResultB.skipped,\n    skipReason: lintResultB.skipReason ?? lintResultA.skipReason,\n    skipDetail: lintResultB.skipDetail ?? lintResultA.skipDetail,\n    message: lintResultB.message ?? lintResultA.message,\n    numModelCalls: lintResultA.numModelCalls + lintResultB.numModelCalls,\n    numModelCallsCached:\n      lintResultA.numModelCallsCached + lintResultB.numModelCallsCached,\n    numPromptTokens: lintResultA.numPromptTokens + lintResultB.numPromptTokens,\n    numCompletionTokens:\n      lintResultA.numCompletionTokens + lintResultB.numCompletionTokens,\n    numTotalTokens: lintResultA.numTotalTokens + lintResultB.numTotalTokens,\n    totalCost: lintResultA.totalCost + lintResultB.totalCost,\n    startedAtMs: Math.min(lintResultA.startedAtMs, lintResultB.startedAtMs),\n    endedAtMs:\n      lintResultA.endedAtMs !== undefined && lintResultB.endedAtMs !== undefined\n        ? Math.max(lintResultA.endedAtMs, lintResultB.endedAtMs)\n        : lintResultB.endedAtMs ?? lintResultB.endedAtMs\n  }\n}\n\nexport function getLintDurationMs(\n  lintResult: types.LintResult\n): number | undefined {\n  if (lintResult.endedAtMs === undefined) return undefined\n  return Math.max(0, lintResult.endedAtMs - lintResult.startedAtMs)\n}\n\nexport function resolvePartialLintResult(\n  partialLintResult: Readonly<types.PartialLintResult> | undefined,\n  {\n    rule,\n    file,\n    filePath,\n    language,\n    model\n  }: Readonly<\n    {\n      rule: types.Rule\n      file?: types.SourceFile\n      filePath?: string\n      language?: string\n      model?: string\n    } & (\n      | {\n          file: types.SourceFile\n          filePath?: never\n        }\n      | {\n          file?: never\n          filePath: string\n        }\n    )\n  >\n): types.LintResult {\n  return createLintResult({\n    ...partialLintResult,\n    lintErrors:\n      partialLintResult?.lintErrors?.map(\n        (partialLintError) =>\n          ({\n            model,\n            level: rule.level,\n            filePath,\n            language,\n            ...partialLintError,\n            ruleName: rule.name,\n            ...(file\n              ? pruneUndefined({\n                  filePath: file.fileRelativePath,\n                  language: file.language\n                })\n              : {})\n          }) as types.LintError\n      ) ?? []\n  })\n}\n\nexport function dedupeLintErrors(\n  lintErrors: types.LintError[]\n): types.LintError[] {\n  const lintErrorsMap = new Map<string, types.LintError>()\n\n  return lintErrors.filter((lintError) => {\n    const key = JSON.stringify(\n      pruneUndefined({\n        ruleName: lintError.ruleName,\n        filePath: lintError.filePath,\n        codeSnippet: lintError.codeSnippet,\n        message: lintError.message\n      })\n    )\n\n    if (lintErrorsMap.has(key)) {\n      return false\n    }\n\n    lintErrorsMap.set(key, lintError)\n    return true\n  })\n}\n","import path from 'node:path'\n\nimport type { MergeDeep, SetRequired, Simplify, SimplifyDeep } from 'type-fest'\nimport findCacheDirectory from 'find-cache-dir'\nimport { z } from 'zod'\n\nimport type * as types from './types.js'\nimport { defaultFiles } from './constants.js'\nimport { RuleDefinitionSchema } from './rule.js'\nimport {\n  dedupe,\n  fileMatchesIncludeExclude,\n  getEnv,\n  pruneUndefined\n} from './utils.js'\n\nexport const LinterConfigRuleSettingSchema = z.enum(['off', 'warn', 'error'])\nexport type LinterConfigRuleSetting = z.infer<\n  typeof LinterConfigRuleSettingSchema\n>\n\nexport const LinterConfigRuleSettingsSchema = z.record(\n  z.string(),\n  LinterConfigRuleSettingSchema\n)\nexport type LinterConfigRuleSettings = z.infer<\n  typeof LinterConfigRuleSettingsSchema\n>\n\nexport const defaultCacheDir =\n  findCacheDirectory({ name: 'gptlint' }) ?? path.join('.gptlint', 'cache')\n\nexport const LLMOptionsSchema = z\n  .object({\n    model: z\n      .string()\n      .optional()\n      .describe('Which LLM to use for assessing rule conformance.'),\n\n    weakModel: z\n      .string()\n      .optional()\n      .nullable()\n      .describe(\n        'If defined, will use a two-pass approach for assessing rule conformance. The `weakModel` should be cheaper and will be used to generate potential rule violations, with the stronger `model` being used in a second pass to validate these potential rule violations and filter out false positives. Set to \"none\" or `null` to disable two-pass linting.'\n      ),\n\n    temperature: z\n      .number()\n      .min(0.0)\n      .max(2.0)\n      .optional()\n      .describe('LLM temperature parameter.'),\n\n    modelSupportsJsonResponseFormat: z\n      .boolean()\n      .optional()\n      .describe(\n        \"A Boolean value indicating whether or not `model` supports OpenAI's JSON output mode.\"\n      ),\n\n    apiKey: z\n      .string()\n      .optional()\n      .describe(\n        'API key for the OpenAI-compatible LLM API. Defaults to the value of the `OPENAI_API_KEY` environment variable.'\n      ),\n\n    apiOrganizationId: z\n      .string()\n      .optional()\n      .describe(\n        'Optional organization ID that should be billed for LLM API requests. This is only necessary if your OpenAI API key is scoped to multiple organizations.'\n      ),\n\n    apiBaseUrl: z\n      .string()\n      .optional()\n      .describe(\n        'Base URL for the OpemAI-compatible LLM API. Defaults to the OpenAI API `https://api.openai.com/v1`'\n      ),\n\n    kyOptions: z\n      .record(z.any())\n      .optional()\n      .describe(\n        'Additional options for customizing HTTP calls to the LLM API, such as custom `headers` to pass with every request. All options are passed to `ky` which is the HTTP `fetch` wrapper used under the hood.'\n      )\n  })\n  .strict()\nexport type LLMOptions = z.infer<typeof LLMOptionsSchema>\n\nexport const LinterOptionsSchema = z\n  .object({\n    noInlineConfig: z\n      .boolean()\n      .optional()\n      .describe('A Boolean value for whether inline configuration is allowed.'),\n\n    earlyExit: z\n      .boolean()\n      .optional()\n      .describe(\n        'A Boolean value for whether to exit greedily after finding the first error.'\n      ),\n\n    debug: z.boolean().optional().describe('Enables debug logging.'),\n    printConfig: z\n      .boolean()\n      .optional()\n      .describe(\n        'When enabled, logs the resolved config and parsed rules and then exits.'\n      ),\n    debugModel: z.boolean().optional().describe('Enables verbose LLM logging.'),\n    debugGrit: z.boolean().optional().describe('Enables verbose Grit logging.'),\n    debugStats: z\n      .boolean()\n      .optional()\n      .describe(\n        'Enables logging of cumulative LLM stats (total tokens and cost).'\n      ),\n\n    noCache: z.boolean().optional().describe('Disables the built-in cache.'),\n    noGrit: z.boolean().optional().describe('Disables grit.'),\n    disabled: z.boolean().optional().describe('Disables linting entirely.'),\n\n    dryRun: z\n      .boolean()\n      .optional()\n      .describe(\n        'Disables all external LLM calls and outputs an estimate of what it would cost to run the linter on the given config.'\n      ),\n\n    cacheDir: z\n      .string()\n      .optional()\n      .describe('A string path to the shared cache directory.'),\n\n    concurrency: z\n      .number()\n      .int()\n      .nonnegative()\n      .optional()\n      .describe('Limits the maximum number of concurrent tasks.')\n  })\n  .strict()\nexport type LinterOptions = z.infer<typeof LinterOptionsSchema>\n\nexport const LinterConfigOverrideSchema = z\n  .object({\n    include: z\n      .array(z.string())\n      .optional()\n      .describe(\n        'An optional array of glob patterns for the files to process. If not specified, the configuration object applies to all files matched by any other configuration object.'\n      ),\n\n    exclude: z\n      .array(z.string())\n      .optional()\n      .describe(\n        'An optional array of glob patterns for source files that should be ignored.'\n      ),\n\n    rules: LinterConfigRuleSettingsSchema.optional().describe(\n      'An object customizing the configured rules.'\n    )\n  })\n  .strict()\nexport type LinterConfigOverride = z.infer<typeof LinterConfigOverrideSchema>\n\nexport const LinterConfigOverridesSchema = z.array(LinterConfigOverrideSchema)\nexport type LinterConfigOverrides = z.infer<typeof LinterConfigOverridesSchema>\n\nexport const LinterConfigSchema = z\n  .object({\n    files: z\n      .array(z.string())\n      .optional()\n      .describe(\n        'An optional array of glob patterns for the files to process. If not specified, the configuration object applies to all files matched by any other configuration object.'\n      ),\n\n    ignores: z\n      .array(z.string())\n      .optional()\n      .describe(\n        'An optional array of glob patterns for source files that should be ignored.'\n      ),\n\n    ruleFiles: z\n      .array(z.string())\n      .optional()\n      .describe('An array of glob patterns to rule definition markdown files.'),\n\n    ruleDefinitions: z\n      .array(RuleDefinitionSchema)\n      .optional()\n      .describe(\n        'An array of custom rule definitions which are better expressed in code as opposed to the `ruleFiles` definitions which are expressed as markdown. These rule definitions will be merged with the rules definitions inferred by `ruleFiles`.'\n      ),\n\n    rules: LinterConfigRuleSettingsSchema.optional().describe(\n      'An object customizing the configured rules.'\n    ),\n\n    linterOptions: LinterOptionsSchema.optional().describe(\n      'An object containing settings related to the linting process.'\n    ),\n\n    llmOptions: LLMOptionsSchema.optional().describe(''),\n\n    overrides: LinterConfigOverridesSchema.optional().describe(\n      'Rule config overrides for specific file patterns.'\n    )\n  })\n  .strict()\nexport type LinterConfig = z.infer<typeof LinterConfigSchema>\nexport type GPTLintConfig = LinterConfig[]\n\nexport type ResolvedLinterOptions = Simplify<\n  SetRequired<LinterOptions, keyof LinterOptions>\n>\nexport type ResolvedLLMOptions = Simplify<SetRequired<LLMOptions, 'model'>>\n\nexport type FullyResolvedLinterConfig = Simplify<\n  Omit<\n    SetRequired<LinterConfig, keyof LinterConfig>,\n    'linterOptions' | 'llmOptions'\n  > & {\n    linterOptions: ResolvedLinterOptions\n    llmOptions: ResolvedLLMOptions\n  }\n>\n\nexport const defaultLinterOptions: Readonly<LinterOptions> = {\n  noInlineConfig: false,\n  earlyExit: false,\n  concurrency: 24,\n  debug: false,\n  printConfig: false,\n  debugModel: false,\n  debugGrit: false,\n  debugStats: true,\n  disabled: false,\n  noCache: false,\n  noGrit: false,\n  dryRun: false,\n  cacheDir: defaultCacheDir\n}\n\nexport const defaultLLMOptions: Readonly<LLMOptions> = {\n  apiKey: getEnv('OPENAI_API_KEY'),\n  apiBaseUrl: 'https://api.openai.com/v1',\n  model: 'gpt-4o',\n  weakModel: 'gpt-4o-mini',\n  temperature: 0\n}\n\nexport const defaultLinterConfig: Readonly<\n  SetRequired<LinterConfig, 'linterOptions' | 'llmOptions'>\n> = {\n  ruleFiles: ['.gptlint/**/*.md', '!.gptlint/readme.md', '!.gptlint/README.md'],\n  linterOptions: defaultLinterOptions,\n  llmOptions: defaultLLMOptions\n}\n\nexport function parseLinterConfig(config: Partial<LinterConfig>): LinterConfig {\n  return LinterConfigSchema.parse(config)\n}\n\nexport function isValidModel(\n  model?: string | null\n): model is NonNullable<string> {\n  return !!model && model !== 'none'\n}\n\nfunction dedupeRuleDefinitions(ruleDefinitions: types.RuleDefinition[]) {\n  const seen = new Set<string>()\n  return ruleDefinitions.filter((ruleDefinition) => {\n    if (!seen.has(ruleDefinition.name)) {\n      seen.add(ruleDefinition.name)\n      return true\n    }\n\n    return false\n  })\n}\n\n/** Union two configs together, with the second one taking precedence */\nexport function mergeLinterConfigs<\n  ConfigTypeA extends LinterConfig = LinterConfig,\n  ConfigTypeB extends LinterConfig = LinterConfig\n>(\n  configA: ConfigTypeA,\n  configB: ConfigTypeB\n): SimplifyDeep<MergeDeep<ConfigTypeA, ConfigTypeB>> {\n  return pruneUndefined({\n    ...pruneUndefined(configA),\n    ...pruneUndefined(configB),\n    files:\n      configA.files || configB.files\n        ? dedupe(\n            [...(configA.files ?? []), ...(configB.files ?? [])].filter(Boolean)\n          )\n        : undefined,\n    ignores:\n      configA.ignores || configB.ignores\n        ? dedupe(\n            [...(configA.ignores ?? []), ...(configB.ignores ?? [])].filter(\n              Boolean\n            )\n          )\n        : undefined,\n    ruleFiles:\n      configA.ruleFiles || configB.ruleFiles\n        ? dedupe(\n            [...(configA.ruleFiles ?? []), ...(configB.ruleFiles ?? [])].filter(\n              Boolean\n            )\n          )\n        : undefined,\n    ruleDefinitions:\n      configA.ruleDefinitions || configB.ruleDefinitions\n        ? dedupeRuleDefinitions([\n            ...(configA.ruleDefinitions ?? []),\n            ...(configB.ruleDefinitions ?? [])\n          ])\n        : undefined,\n    rules:\n      configA.rules || configB.rules\n        ? {\n            ...pruneUndefined(configA.rules ?? {}),\n            ...pruneUndefined(configB.rules ?? {})\n          }\n        : undefined,\n    linterOptions:\n      configA.linterOptions || configB.linterOptions\n        ? {\n            ...pruneUndefined(configA.linterOptions ?? {}),\n            ...pruneUndefined(configB.linterOptions ?? {})\n          }\n        : undefined,\n    llmOptions:\n      configA.llmOptions || configB.llmOptions\n        ? {\n            ...pruneUndefined(configA.llmOptions ?? {}),\n            ...pruneUndefined(configB.llmOptions ?? {})\n          }\n        : undefined,\n    overrides:\n      configA.overrides || configB.overrides\n        ? [...(configA.overrides ?? []), ...(configB.overrides ?? [])].filter(\n            Boolean\n          )\n        : undefined\n  }) as any\n}\n\n/**\n * Union two configs together, with the second one taking precedence, but\n * allow certain fields of the second config to override the first instead of\n * joining them together.\n *\n * This is used to allow CLI config values to completely override other configs.\n */\nexport function mergeLinterConfigsOverride<\n  ConfigTypeA extends LinterConfig = LinterConfig,\n  ConfigTypeB extends LinterConfig = LinterConfig\n>(\n  configA: ConfigTypeA,\n  configB: ConfigTypeB\n): SimplifyDeep<MergeDeep<ConfigTypeA, ConfigTypeB>> {\n  return pruneUndefined({\n    ...pruneUndefined(configA),\n    ...pruneUndefined(configB),\n    ruleFiles:\n      configB.ruleFiles || configB.ruleDefinitions\n        ? configB.ruleFiles ?? []\n        : configA.ruleFiles,\n    ruleDefinitions:\n      configB.ruleFiles || configB.ruleDefinitions\n        ? configB.ruleDefinitions ?? []\n        : configA.ruleDefinitions,\n    linterOptions:\n      configA.linterOptions || configB.linterOptions\n        ? {\n            ...pruneUndefined(configA.linterOptions ?? {}),\n            ...pruneUndefined(configB.linterOptions ?? {})\n          }\n        : undefined,\n    llmOptions:\n      configA.llmOptions || configB.llmOptions\n        ? {\n            ...pruneUndefined(configA.llmOptions ?? {}),\n            ...pruneUndefined(configB.llmOptions ?? {})\n          }\n        : undefined,\n    overrides:\n      configA.overrides || configB.overrides\n        ? [...(configA.overrides ?? []), ...(configB.overrides ?? [])].filter(\n            Boolean\n          )\n        : undefined\n  }) as any\n}\n\nexport function mergeLinterConfigRuleSettings(\n  rulesA?: LinterConfigRuleSettings,\n  rulesB?: LinterConfigRuleSettings\n): LinterConfigRuleSettings {\n  return {\n    ...pruneUndefined(rulesA ?? {}),\n    ...pruneUndefined(rulesB ?? {})\n  }\n}\n\nexport function resolveLinterConfig(\n  config: Partial<LinterConfig>\n): FullyResolvedLinterConfig {\n  return mergeLinterConfigs(\n    {\n      files: [],\n      ignores: [],\n      ruleFiles: [],\n      ruleDefinitions: [],\n      rules: {},\n      linterOptions: defaultLinterOptions,\n      llmOptions: defaultLLMOptions,\n      overrides: []\n    },\n    config\n  ) as FullyResolvedLinterConfig\n}\n\nexport class ResolvedLinterConfig\n  implements\n    Pick<\n      FullyResolvedLinterConfig,\n      | 'files'\n      | 'ignores'\n      | 'ruleFiles'\n      | 'ruleDefinitions'\n      | 'rules'\n      | 'linterOptions'\n      | 'llmOptions'\n    >\n{\n  readonly config: FullyResolvedLinterConfig\n  readonly ruleSettingsFileCache = new Map<\n    string,\n    types.LinterConfigRuleSettings\n  >()\n\n  constructor({\n    configs,\n    cliConfigOverride\n  }: {\n    configs: LinterConfig[]\n    cliConfigOverride: LinterConfig\n  }) {\n    let linterConfig: types.LinterConfig = {}\n\n    for (const config of configs) {\n      linterConfig = mergeLinterConfigs(linterConfig, config)\n    }\n\n    linterConfig = mergeLinterConfigsOverride(linterConfig, cliConfigOverride)\n    this.config = resolveLinterConfig(linterConfig)\n\n    if (this.config.files.length === 0 && !cliConfigOverride.files) {\n      this.config.files = defaultFiles\n    }\n\n    // console.log(\n    //   'config',\n    //   JSON.stringify(\n    //     {\n    //       configs: configs.map((c) => sanitizeConfig(c)),\n    //       cliConfigOverride: sanitizeConfig(cliConfigOverride),\n    //       resolvedConfig: sanitizeConfig(this.config)\n    //     },\n    //     null,\n    //     2\n    //   )\n    // )\n  }\n\n  get files(): string[] {\n    return this.config.files\n  }\n\n  get ignores(): string[] {\n    return this.config.ignores\n  }\n\n  get ruleFiles(): string[] {\n    return this.config.ruleFiles\n  }\n\n  get rules(): LinterConfigRuleSettings {\n    return this.config.rules\n  }\n\n  get ruleDefinitions(): types.RuleDefinition[] {\n    return this.config.ruleDefinitions\n  }\n\n  get linterOptions(): ResolvedLinterOptions {\n    return this.config.linterOptions\n  }\n\n  get llmOptions(): ResolvedLLMOptions {\n    return this.config.llmOptions\n  }\n\n  getRuleSettingsForFile(\n    file: types.SourceFile\n  ): types.LinterConfigRuleSettings {\n    if (this.ruleSettingsFileCache.has(file.fileRelativePath)) {\n      return this.ruleSettingsFileCache.get(file.fileRelativePath)!\n    }\n\n    const settings =\n      this.config.overrides ??\n      [].filter((override) => fileMatchesIncludeExclude(file, override))\n\n    let rules: LinterConfigRuleSettings = {}\n    for (const setting of settings) {\n      rules = mergeLinterConfigRuleSettings(rules, setting.rules)\n    }\n\n    this.ruleSettingsFileCache.set(file.fileRelativePath, rules)\n    return rules\n  }\n\n  getSanitizedDebugConfig() {\n    return sanitizeConfig(this.config)\n  }\n}\n\nexport function sanitizeConfig(\n  config: LinterConfig\n): Omit<LinterConfig, 'ruleDefinitions'> & { ruleDefinitions?: string[] } {\n  return pruneUndefined({\n    ...config,\n    ruleDefinitions: config.ruleDefinitions?.map(\n      (ruleDefinition) => `${ruleDefinition.name} { ... }`\n    ),\n    llmOptions: pruneUndefined({\n      ...config.llmOptions,\n      apiKey: config.llmOptions?.apiKey ? '<redacted>' : undefined\n    })\n  })\n}\n","export const minSourceFileSizeBytes = 0\nexport const maxSourceFileSizeBytes = 200 * 1024 // 200kb\n\nexport const maxSourceFileNumLines = 10_000\nexport const maxSourceFileLineLength = 1024\n\nexport const gritNumLinesContext = 0\n\nexport const defaultFiles = ['**/*.{js,ts,jsx,tsx,cjs,mjs}']\n","import { z } from 'zod'\n\nimport type * as types from './types.js'\nimport { isValidRuleName } from './rule-utils.js'\n\nexport type RuleMetadata<K extends string = string, V = any> = Record<K, V>\n\nexport type RuleDefinition<Metadata extends RuleMetadata = RuleMetadata> = {\n  // core rule definition\n  name: string\n  title: string\n  description?: string\n  positiveExamples?: types.RuleExample[]\n  negativeExamples?: types.RuleExample[]\n  level: types.LintRuleLevel\n  scope: types.LintRuleScope\n\n  // optional metadata\n  fixable?: boolean\n  cacheable?: boolean\n  languages?: string[]\n  tags?: string[]\n  eslint?: string[]\n  include?: string[]\n  exclude?: string[]\n  resources?: string[]\n  model?: string\n  gritql?: string\n  gritqlNumLinesContext?: number\n\n  // optional custom functionality for rules scoped to the file-level\n  preProcessFile?: types.RulePreProcessFileFn<Metadata>\n  processFile?: types.RuleProcessFileFn<Metadata>\n  postProcessFile?: types.RulePostProcessFileFn<Metadata>\n\n  // optional custom functionality for rules scoped to the project-level\n  preProcessProject?: types.RulePreProcessProjectFn<Metadata>\n  processProject?: types.RuleProcessProjectFn<Metadata>\n  postProcessProject?: types.RulePostProcessProjectFn<Metadata>\n\n  init?: types.RuleInitFn<Metadata>\n}\n\nexport type Rule<Metadata extends RuleMetadata = RuleMetadata> =\n  RuleDefinition<Metadata> & {\n    // internal metadata\n    source: string\n    metadata: Metadata\n  }\n\nexport const RuleDefinitionExampleSchema = z\n  .object({\n    code: z.string().describe('Example code.'),\n\n    language: z\n      .string()\n      .optional()\n      .describe('Language of the example code snippet.')\n  })\n  .strict()\n\nexport const RuleDefinitionSchema = z\n  .object({\n    name: z\n      .string()\n      .refine((name) => isValidRuleName(name))\n      .describe(\n        \"Primary identifier for the rule. Uses lowercase kebab-case. Examples: 'consistent-identifier-casing' and '@foo/bar'.\"\n      ),\n\n    title: z\n      .string()\n      .describe(\n        'A short, human-readable title for the rule. Defaults to the name if not set.'\n      ),\n\n    description: z\n      .string()\n      .optional()\n      .describe(\n        \"Longer description of the rule which is passed to the linting engine's LLM as part of the rule's prompt. Accepts Markdown.\"\n      ),\n\n    positiveExamples: z\n      .array(RuleDefinitionExampleSchema)\n      .optional()\n      .describe('Example code snippets which correctly conform to the rule.'),\n\n    negativeExamples: z\n      .array(RuleDefinitionExampleSchema)\n      .optional()\n      .describe('Example code snippets which violate to the rule.'),\n\n    fixable: z\n      .boolean()\n      .optional()\n      .describe('Whether or not this rule is auto-fixable.'),\n\n    cacheable: z\n      .boolean()\n      .optional()\n      .describe('Whether or not this rule should be cached.'),\n\n    level: z\n      .enum(['off', 'warn', 'error'])\n      .optional()\n      .default('error')\n      .describe('Default rule severity.'),\n\n    scope: z\n      .enum(['file', 'project', 'repo'])\n      .optional()\n      .default('file')\n      .describe('Granularity at which this rule is applied.'),\n\n    languages: z\n      .array(z.string())\n      .optional()\n      .describe(\n        'Programming languages this rule should be restricted to. If empty, this rule will apply to all languages.'\n      ),\n\n    tags: z\n      .array(z.string())\n      .optional()\n      .describe(\n        'An optional array of tags / labels to associate with this rule.'\n      ),\n\n    eslint: z\n      .array(z.string())\n      .optional()\n      .describe(\n        'An optional array of `eslint` rule identifiers which are related to this rule.'\n      ),\n\n    resources: z\n      .array(z.string())\n      .optional()\n      .describe(\n        \"An optional array of URLs which give more detail around this rule's intent.\"\n      ),\n\n    model: z\n      .string()\n      .optional()\n      .describe(\n        \"Specific model to use for this rule. Useful for using a fine-tuned model which is specfic to a single rule. If a `model` is given, it will override the general config's `model` and `weakModel` when enforcing this rule with the built-in LLM-based linting engine.\"\n      ),\n\n    include: z\n      .array(z.string())\n      .optional()\n      .describe(\n        'An optional array of file glob patterns to include when enforcing this rule. If not specified, will operate on all input source files not excluded by `exclude`.'\n      ),\n\n    exclude: z\n      .array(z.string())\n      .optional()\n      .describe(\n        'An optional array of file glob patterns to ignore when enforcing this rule.'\n      ),\n\n    gritql: z\n      .string()\n      .optional()\n      .describe(\n        'An optional GritQL pattern to filter source code by for this rule.'\n      ),\n\n    gritqlNumLinesContext: z\n      .number()\n      .optional()\n      .describe(\n        'Number of lines before & after GritQL matches to include in the context sent to the LLM. Defaults to 0.'\n      ),\n\n    preProcessFile: z\n      .function(z.tuple([z.any()]), z.any())\n      .optional()\n      .describe(\n        'Optional pre-processing linter logic specific to this rule. Will be run after the built-in pre-processing logic which handles caching and validation.'\n      ),\n\n    processFile: z\n      .function(z.tuple([z.any()]), z.any())\n      .optional()\n      .describe(\n        \"Optional file processing / linting logic specific to this rule. If provided, this will **override** the default LLM-based file linting engine and is intended to be an escape hatch for fully customizing the linting logic for rules which aren't a good fit for LLM-based linting. If you still want to use the built-in LLM-based linting and just want to customize it's functionality, consider using `preProcessFile` or `postProcessFile` instead.\"\n      ),\n\n    postProcessFile: z\n      .function(z.tuple([z.any()]), z.any())\n      .optional()\n      .describe(\n        'Optional post-processing linter logic specific to this rule. Will be run after the built-in post-processing logic. Useful for customizing the linting results in a rule-specific way such as pruning common false positives.'\n      ),\n\n    preProcessProject: z\n      .function(z.tuple([z.any()]), z.any())\n      .optional()\n      .describe(\n        'Optional pre-processing linter logic specific to this rule. Will be run after the built-in pre-processing logic which handles caching and validation.'\n      ),\n\n    processProject: z\n      .function(z.tuple([z.any()]), z.any())\n      .optional()\n      .describe(\n        'Optional project processing / linting logic specific to this rule.'\n      ),\n\n    postProcessProject: z\n      .function(z.tuple([z.any()]), z.any())\n      .optional()\n      .describe(\n        'Optional post-processing linter logic specific to this rule. Will be run after the built-in post-processing logic. Useful for customizing the linting results in a rule-specific way such as pruning common false positives.'\n      ),\n\n    source: z.string().optional()\n  })\n  // It is important for this to be a `passthrough` because we use additional\n  // properties on the rule object which are not defined in the rule definition\n  // schema.\n  .passthrough()\n","import type * as types from './types.js'\nimport { RuleDefinitionSchema } from './rule.js'\nimport { assert } from './utils.js'\n\nexport function stringifyRuleForModel(rule: types.Rule): string {\n  return `<RULE ${rule.name}>\n\n# ${rule.title}\n\n${rule.description ?? ''}\n\n${\n  rule.negativeExamples?.length\n    ? '<INCORRECT EXAMPLES>\\n\\nThese are examples of bad code snippets which would VIOLATE this rule if they appear in the SOURCE:\\n\\n'\n    : ''\n}\n${stringifyExamples(rule.negativeExamples)}\n${rule.negativeExamples?.length ? '</INCORRECT EXAMPLES>' : ''}\n\n${\n  rule.positiveExamples?.length\n    ? '<CORRECT EXAMPLES>\\n\\nThese are examples of good code snippets which conform to this rule and should be ignored in the SOURCE:\\n\\n'\n    : ''\n}\n${stringifyExamples(rule.positiveExamples)}\n${rule.positiveExamples?.length ? '</CORRECT EXAMPLES>' : ''}\n\n</RULE ${rule.name}>\n`\n}\n\nexport function stringifyExamples(examples?: types.RuleExample[]): string {\n  return examples\n    ? examples\n        .map(\n          (example) =>\n            `\\`\\`\\`${example.language ?? ''}\\n${example.code}\\n\\`\\`\\``\n        )\n        .join('\\n\\n')\n    : ''\n}\n\nexport function validateRule(\n  ruleDefinition: types.RuleDefinition | types.Rule\n): types.Rule {\n  const name = ruleDefinition?.name || 'unknown'\n  const parsedRule =\n    RuleDefinitionSchema.passthrough().safeParse(ruleDefinition)\n  assert(\n    parsedRule.success,\n    `Invalid rule \"${name}\": ${parsedRule.error?.message}`\n  )\n\n  const rule: types.Rule = {\n    source: 'custom',\n    cacheable: true,\n    metadata: {},\n    ...parsedRule.data\n  }\n  assert(isValidRuleName(rule.name), `Invalid rule name \"${name}\"`)\n  assert(\n    isValidRuleScope(rule.scope),\n    `Invalid rule scope \"${rule.scope}\" for rule \"${rule.name}\"`\n  )\n  assert(\n    isValidRuleSetting(rule.level),\n    `Invalid rule level \"${rule.level}\" for rule \"${rule.name}\"`\n  )\n\n  if (rule.scope !== 'file') {\n    assert(\n      rule.gritql === undefined,\n      `Rule \"${rule.name}\" with scope \"${rule.scope}\" cannot have a \"gritql\" pattern because they are only supported for \"file\" scoped rules.`\n    )\n  }\n\n  return rule\n}\n\nexport function isValidRuleName(name: string): name is NonNullable<string> {\n  if (!name) return false\n  if (name.toLowerCase() !== name) return false\n\n  const parts = name.split('/')\n  if (parts.length === 2) {\n    if (!/^@[a-z][\\w-]*$/i.test(parts[0]!)) return false\n    if (!/^[a-z][\\w-]*$/i.test(parts[1]!)) return false\n  } else if (!/^[a-z][\\w-]*$/i.test(name)) return false\n\n  return true\n}\n\nexport function isValidRuleSetting(\n  value: string\n): value is types.LinterConfigRuleSetting {\n  if (!value) return false\n  if (value.toLowerCase() !== value) return false\n\n  return value === 'off' || value === 'warn' || value === 'error'\n}\n\nexport function isValidRuleScope(\n  value: string\n): value is types.LinterConfigRuleSetting {\n  if (!value) return false\n  if (value.toLowerCase() !== value) return false\n\n  return value === 'file' || value === 'project' || value === 'repo'\n}\n","export * from './effective-tsconfig.js'\nexport * from './prefer-fetch-over-axios.js'\n","import { getTsconfig } from 'get-tsconfig'\n\nimport {\n  createCacheKey,\n  type PartialLintError,\n  type RuleDefinition\n} from '../../src/index.js'\n\nconst tsConfigCache = new Map<string, any>()\n\nexport const effectiveTSConfig: Readonly<RuleDefinition> = {\n  name: 'effective-tsconfig',\n  title: 'Follow tsconfig best practices',\n  level: 'error',\n  scope: 'project',\n  resources: [\n    'https://typescriptlang.org/tsconfig',\n    'https://www.youtube.com/watch?v=eJXVEju3XLM&ab_channel=MattPocock'\n  ],\n\n  preProcessProject: async ({ rule, cache, config, cwd }) => {\n    const parsedTSConfig = getTsconfig(cwd, 'tsconfig.json', tsConfigCache)\n\n    if (!parsedTSConfig) {\n      return {\n        lintErrors: [\n          {\n            message: 'No tsconfig found.'\n          }\n        ]\n      }\n    }\n\n    const { config: tsconfig, path: filePath } = parsedTSConfig\n    const lintErrors: PartialLintError[] = []\n\n    // TODO: how to pass cacheKey along? need `lintTask` instead of just spread `lintTask`?\n    const cacheKey = createCacheKey({ rule, config, filePath, tsconfig })\n    const cachedResult = await cache.get(cacheKey)\n    if (cachedResult) {\n      return cachedResult\n    }\n\n    // TODO: should these checks be in processProject or processFile?\n    // maybe add a new file-level task for tsconfig and disable caching on\n    // this project-level task?\n\n    if (!tsconfig.compilerOptions?.strict) {\n      lintErrors.push({\n        message: 'Recommended setting \"strict\" to `true`.',\n        level: 'warn',\n        filePath\n      })\n    }\n\n    if (!tsconfig.compilerOptions?.forceConsistentCasingInFileNames) {\n      lintErrors.push({\n        message:\n          'Recommended setting \"forceConsistentCasingInFileNames\" to `true`.',\n        level: 'warn',\n        filePath\n      })\n    }\n\n    if (!tsconfig.compilerOptions?.noUncheckedIndexedAccess) {\n      lintErrors.push({\n        message: 'Recommended setting \"noUncheckedIndexedAccess\" to `true`.',\n        level: 'warn',\n        filePath\n      })\n    }\n\n    await cache.set(cacheKey, { lintErrors } as any)\n    return { lintErrors }\n  }\n}\n","import type { RuleDefinition } from '../../src/index.js'\n\nexport const preferFetchOverAxios: Readonly<RuleDefinition> = {\n  name: 'prefer-fetch-over-axios',\n  title: 'Prefer fetch over axios',\n  level: 'error',\n  scope: 'file',\n  description: `The NPM package \\`axios\\` should be avoided in favor of native \\`fetch\\`. Now that native \\`fetch\\` has widespread support, \\`axios\\` is effectively deprecated and is generally a code smell when encountered.\n\n  Convenience wrappers around \\`fetch\\` such as \\`ky\\` and \\`ofetch\\` are encouraged.\n  \n  Code which doesn't use the \\`axios\\` module should be ignored.`,\n\n  tags: ['best practices'],\n  eslint: ['no-restricted-imports'],\n\n  preProcessFile: async (ctx) => {\n    if (!/[\"']axios[\"']/g.test(ctx.file.content)) {\n      // Skip linting because we know the file doesn't use axios\n      return {\n        lintErrors: []\n      }\n    } else {\n      // Lint the file normally if it contains axios\n    }\n  }\n}\n","[\n  {\n    \"source\": \"/Users/tfischer/dev/modules/gptlint/rules/always-handle-promises.md\",\n    \"cacheable\": true,\n    \"metadata\": {},\n    \"name\": \"always-handle-promises\",\n    \"title\": \"Always handle Promises\",\n    \"description\": \"Promises (and `async` functions which implicitly create Promises) must always be handled at some level of the program, either via:\\n\\n- using `await` to wait for the Promise to resolve successfully\\n- using `.then` or `.catch` to handle Promise resolution\\n- returning a Promise to a calling function which itself has to handle the Promise\\n\\nCreating a Promise or calling an `async` function and NOT awaiting or propagating the resulting Promise using one of these approaches is a code smell and violates this rule.\\n\\n**Important**: This rule should only apply to function calls which you are 100% sure return a `Promise`. If you do not know for sure that a function returns a `Promise`, then disregard it.\\n\",\n    \"positiveExamples\": [\n      {\n        \"code\": \"async function saveFile() {\\n  // ...\\n}\\n\\n// This is fine because we explicitly `await` the Promise returned by `saveFile`\\nawait saveFile()\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"async function saveFile() {\\n  // ...\\n}\\n\\n// This is fine because the Promise returned from `saveFile` is propagated to `main`'s caller\\nasync function main() {\\n  return saveFile()\\n}\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"async function saveFile() {\\n  // ...\\n}\\n\\n// This is fine because we explicitly `await` the promise results\\nawait Promise.all([saveFile(), saveFile()])\",\n        \"language\": \"js\"\n      }\n    ],\n    \"negativeExamples\": [\n      {\n        \"code\": \"async function saveFile() {\\n  // ...\\n}\\n\\n// This is bad because we're not handling the Promise returned by `saveFile`\\nsaveFile()\",\n        \"language\": \"js\"\n      }\n    ],\n    \"fixable\": false,\n    \"level\": \"error\",\n    \"scope\": \"file\",\n    \"languages\": [\n      \"javascript\",\n      \"typescript\"\n    ],\n    \"tags\": [\n      \"best practices\"\n    ]\n  },\n  {\n    \"source\": \"/Users/tfischer/dev/modules/gptlint/rules/avoid-type-info-in-docs.md\",\n    \"cacheable\": true,\n    \"metadata\": {},\n    \"name\": \"avoid-type-info-in-docs\",\n    \"title\": \"Don’t repeat type information in documentation\",\n    \"description\": \"Avoid repeating type information in comments and variable names. In the best case it is duplicative of type declarations, and in the worst it will lead to conflicting information.\\n\\nConsider including units in variable names if they aren’t clear from the type (e.g., timeMs or temperatureC).\\n\\nHere is an example of incorrect code:\\n\\n```ts\\n/**\\n * Returns a string with the foreground color.\\n * Takes zero or one arguments. With no arguments, returns the standard\\n * foreground color. With one argument, returns the foreground color for a\\n * particular page.\\n */\\nfunction getForegroundColor(page?: string) {\\n  return page === 'login' ? { r: 127, g: 127, b: 127 } : { r: 0, g: 0, b: 0 }\\n}\\n```\\n\\nThis is a VIOLATION because the comment describes the types of the function parameters and return type which duplicates the more precise TS definition. Even worse, this example is a VIOLATION because the code and the comment contradict each other.\\n\\nLet’s assume that the code represents the desired behavior. There are a few issues with this comment:\\n\\n- It says that the function returns the color as a string when it actually returns an `{r, g, b}` object.\\n- It explains that the function takes zero or one arguments, which is already clear from the type signature.\\n- It’s needlessly wordy: the comment is longer than the function declaration and implementation.\\n\\nSince your type annotations are checked by the TypeScript compiler, they’ll never get out of sync with the implementation.\\n\\nA better comment might look like this:\\n\\n```ts\\n/** Get the foreground color for the application or a specific page. */\\nfunction getForegroundColor(page?: string): Color {\\n  // ...\\n}\\n```\\n\\nComments about a lack of mutation are also suspect. Don’t just say that you don’t modify a parameter:\\n\\n```ts\\n/** Does not modify nums */\\nfunction sort(nums: number[]) {\\n  /* ... */\\n}\\n```\\n\\nInstead, declare the parameter as `readonly` and let TypeScript enforce the contract:\\n\\n```ts\\nfunction sort(nums: readonly number[]) {\\n  /* ... */\\n}\\n```\\n\\n## Caveats\\n\\nNote that you do NOT have to include JSDoc comments for a function, and you do NOT have to include `@param` or `@returns` JSDoc properties. These are purely optional, but if they are included, they should not discuss the types of function parameters because TypeScript does a better job of capturing this info in the function definition itself.\\n\\nIf a comment is providing useful context or clarifying what a parameter is used for, then it should be ignored. This rule is only aimed at comments which duplicate type info or comments which imply immutability.\\n\",\n    \"positiveExamples\": [\n      {\n        \"code\": \"/**\\n * Upserts a user into the database.\\n */\\nexport async function upsertUser(\\n  user: User | NewUserData,\\n  ctx?: Context\\n): Promise<User> {\\n  // ...\\n}\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"/**\\n * Upserts a user into the database.\\n *\\n * @param user - The user to upsert.\\n * @param ctx - Optional context for the database operation.\\n *\\n * @returns The upserted user.\\n */\\nexport async function upsertUser(\\n  user: User | NewUserData,\\n  ctx?: Context\\n): Promise<User> {\\n  // ...\\n}\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"/**\\n * Parses a string using a zod schema.\\n *\\n * @param output - string to parse\\n * @param outputSchema - zod schema\\n *\\n * @returns parsed output\\n */\\nexport function parseStructuredOutput<T>(\\n  output: string,\\n  outputSchema: ZodType<T>\\n): T {\\n  // ...\\n}\\n\\n// This example is fine because the type info in the JSDoc `@param` comments is relevant and simple.\",\n        \"language\": \"ts\"\n      }\n    ],\n    \"negativeExamples\": [],\n    \"fixable\": false,\n    \"level\": \"error\",\n    \"scope\": \"file\",\n    \"languages\": [\n      \"typescript\"\n    ],\n    \"tags\": [\n      \"best practices\"\n    ],\n    \"resources\": [\n      \"https://effectivetypescript.com\"\n    ],\n    \"exclude\": [\n      \"**/*\\\\.test\\\\.{js,ts,jsx,tsx,cjs,mjs}\"\n    ],\n    \"gritql\": \"comment\",\n    \"gritqlNumLinesContext\": 3\n  },\n  {\n    \"source\": \"/Users/tfischer/dev/modules/gptlint/rules/consistent-identifier-casing.md\",\n    \"cacheable\": true,\n    \"metadata\": {},\n    \"name\": \"consistent-identifier-casing\",\n    \"title\": \"Be consistent with identifier casing\",\n    \"description\": \"Identifiers of the same type should try to use consistent casing.\\n\\nVariable names should use camelCase.\\nGlobal const variable names should either use camelCase, PascalCase, or CONSTANT\\\\_CASE.\\nType names should use PascalCase.\\nClass names should use PascalCase.\\nFunction names should use camelCase.\\n\\nExamples of camelCase identifiers include: foo, fooBar, h1RuleNodes, cwd, apiBaseUrl, apiBaseURL, validRuleTableKeysL, and \\\\_getKey.\\n\\n## Caveats\\n\\nThird-party APIs may use inconsistent casing, which is an exception to this rule.\\n\\nKeys in JSON objects, JS objects, and TypeScript objects may use inconsistent casing, so they are exceptions to this rule.\\n\\nIgnore identifiers which mix PascalCase with camelCase.\\n\\nIgnore the casing of common acronyms like API, IP, HTTP, and LLM.\\n\\nIgnore the casing of identifiers which start with acronyms like `LLMOptionsSchema`.\\n\\nIgnore parameter names used in inline functions.\\n\\nIgnore string literals and module names for this rule.\\n\\nClass member variables and functions may include `_` prefixes.\\n\",\n    \"positiveExamples\": [\n      {\n        \"code\": \"const fooBar = true\\nconst defaultTimeout = 5000\\n\\nfunction helloWorld() {}\\nfunction helloTwitter() {}\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"import foo from 'foo'\\n\\n// This is fine because `foo` is a third-party API which this rule should ignore.\\nfoo({ camelCase: true, snake_case: true, SNAKE_CASE: true })\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"// These are all fine as common exceptions to this rule\\nexport const HTTPConfig = {}\\nconst LLMOptions = {}\\nconst validKeysL = new Set()\\nconst loadingP = new Promise()\\nconst cwd = process.cwd\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"// This is fine because `i` is a parameter of an inline function and `res` is a common exception.\\nconst res = [1, 2, 3].filter((i) => i >= 0)\",\n        \"language\": \"ts\"\n      }\n    ],\n    \"negativeExamples\": [\n      {\n        \"code\": \"// These are bad because variable identifiers should use consistent casing.\\nconst fooBar = true\\nconst default_timeout = 5000\\n\\n// These are bad because function identifiers should use consistent casing.\\nfunction helloWorld() {}\\nfunction hello_twitter() {}\",\n        \"language\": \"ts\"\n      }\n    ],\n    \"fixable\": false,\n    \"level\": \"error\",\n    \"scope\": \"file\",\n    \"languages\": [\n      \"javascript\",\n      \"typescript\"\n    ],\n    \"tags\": [\n      \"best practices\"\n    ],\n    \"eslint\": [\n      \"@typescript-eslint/naming-convention\",\n      \"camelcase\"\n    ],\n    \"gritql\": \"or {\\n  type_identifier() as $id where {\\n    and {\\n      $id <: within or {\\n        type_alias_declaration($name),\\n        interface_declaration($name),\\n        class_declaration($name)\\n      },\\n      $id <: $name\\n    }\\n  },\\n\\n  identifier() as $id where {\\n    or {\\n      and {\\n        $id <: within or {\\n          variable_declarator($name),\\n          function_declaration($name),\\n          class_declaration($name),\\n          method_signature($name),\\n          method_definition($name),\\n          required_parameter($name),\\n          optional_parameter($name)\\n        },\\n        $id <: $name\\n      },\\n\\n      or {\\n        and {\\n          $id <: within `function $func($props): $ret {$body}`,\\n          $id <: not or { within $body, within $func }\\n        },\\n        and {\\n          $id <: within `function $func($props) {$body}`,\\n          $id <: not or { within $body, within $func }\\n        },\\n        and {\\n          $id <: within `($props) => $body`,\\n          $id <: not or { within $body }\\n        }\\n      }\\n    }\\n  },\\n\\n  property_identifier() as $id where {\\n    and {\\n      $id <: within or { method_signature($name), method_definition($name) },\\n      $id <: $name\\n    }\\n  }\\n}\"\n  },\n  {\n    \"source\": \"/Users/tfischer/dev/modules/gptlint/rules/liberal-accept-strict-produce.md\",\n    \"cacheable\": true,\n    \"metadata\": {},\n    \"name\": \"liberal-accept-strict-produce\",\n    \"title\": \"Be liberal in what you accept and strict in what you produce\",\n    \"description\": \"This idea is known as the robustness principle or Postel’s Law.\\n\\nAs a general best practice, input types should be broader than output types. Optional properties and union types are more common in parameter types than return types.\\n\\nTo reuse types between parameters and return types, it's often useful to introduce a canonical form (for return types) and a looser form (for parameters).\\n\\n---\\n\\nAs an example, a 3D mapping API might provide a way to position the camera and to calculate a viewport for a bounding box:\\n\\n```ts\\ndeclare function setCamera(camera: CameraOptions): void\\ndeclare function viewportForBounds(bounds: LngLatBounds): CameraOptions\\n```\\n\\nIt is convenient that the result of `viewportForBounds` can be passed directly to `setCamera` to position the camera.\\n\\nLet’s look at the definitions of these types:\\n\\n```ts\\ninterface CameraOptions {\\n  center?: LngLat\\n  zoom?: number\\n  bearing?: number\\n  pitch?: number\\n}\\n\\ntype LngLat =\\n  | { lng: number; lat: number }\\n  | { lon: number; lat: number }\\n  | [number, number]\\n```\\n\\nThe fields in `CameraOptions` are all optional because you might want to set just the center or zoom without changing the bearing or pitch. The `LngLat` type also makes `setCamera` liberal in what it accepts: you can pass in a `{lng, lat}` object, a `{lon, lat}` object, or a `[lng, lat]` pair if you’re confident you got the order right. These accommodations make the function easy to call.\\n\\nThe viewportForBounds function takes in another “liberal” type:\\n\\n```ts\\ntype LngLatBounds =\\n  | { northeast: LngLat; southwest: LngLat }\\n  | [LngLat, LngLat]\\n  | [number, number, number, number]\\n```\\n\\nYou can specify the bounds either using named corners, a pair of lat/lngs, or a four- tuple if you’re confident you got the order right. Since LngLat already accommodates three forms, there are no fewer than 19 possible forms for LngLatBounds. Liberal indeed!\\n\\nNow let’s write a function that adjusts the viewport to accommodate a GeoJSON Fea‐ ture and stores the new viewport in the URL:\\n\\n```ts\\nfunction focusOnFeature(f: Feature) {\\n  const bounds = calculateBoundingBox(f)\\n  const camera = viewportForBounds(bounds)\\n  setCamera(camera)\\n  const {\\n    center: { lat, lng },\\n    zoom\\n  } = camera\\n  // ~~~ Property 'lat' does not exist on type ...\\n  // ~~~ Property 'lng' does not exist on type ... zoom; // Type is number | undefined\\n  window.location.search = `?v=@${lat},${lng}z${zoom}`\\n}\\n```\\n\\nWhoops! Only the zoom property exists, but its type is inferred as `number|undefined`, which is also problematic. The issue is that the type declaration for `viewportFor Bounds` indicates that it is liberal not just in what it accepts but also in what it pro‐ duces. The only type-safe way to use the camera result is to introduce a code branch for each component of the union type.\\n\\nThe return type with lots of optional properties and union types makes `viewportFor Bounds` difficult to use. **Its broad parameter type is convenient, but its broad return type is not. A more convenient API would be strict in what it produces.**\\n\\nOne way to do this is to distinguish a canonical format for coordinates. Following JavaScript’s convention of distinguishing “Array” and “Array-like”, you can draw a distinction between `LngLat` and `LngLatLike`. You can also distinguish between a fully defined Camera type and the partial version accepted by setCamera:\\n\\n```ts\\ninterface LngLat {\\n  lng: number\\n  lat: number\\n}\\ntype LngLatLike = LngLat | { lon: number; lat: number } | [number, number]\\ninterface Camera {\\n  center: LngLat\\n  zoom: number\\n  bearing: number\\n  pitch: number\\n}\\ninterface CameraOptions extends Omit<Partial<Camera>, 'center'> {\\n  center?: LngLatLike\\n}\\ntype LngLatBounds =\\n  | { northeast: LngLatLike; southwest: LngLatLike }\\n  | [LngLatLike, LngLatLike]\\n  | [number, number, number, number]\\n\\ndeclare function setCamera(camera: CameraOptions): void\\ndeclare function viewportForBounds(bounds: LngLatBounds): Camera\\n```\\n\\nThe loose `CameraOptions` type adapts the stricter `Camera` type.\\n\\nUsing `Partial<Camera>` as the parameter type in `setCamera` would not work here since you do want to allow `LngLatLike` objects for the `center` property. And you can’t write `\\\"CameraOptions extends Partial<Camera>\\\"` since `LngLatLike` is a superset of `LngLat`, not a subset. If this seems too complicated, you could also write the type out explicitly at the cost of some repetition:\\n\\n```ts\\ninterface CameraOptions {\\n  center?: LngLatLike\\n  zoom?: number\\n  bearing?: number\\n  pitch?: number\\n}\\n```\\n\\nIn either case, with these new type declarations the `focusOnFeature` function passes the type checker:\\n\\n```ts\\nfunction focusOnFeature(f: Feature) {\\n  const bounds = calculateBoundingBox(f)\\n  const camera = viewportForBounds(bounds)\\n  setCamera(camera)\\n\\n  const {\\n    center: { lat, lng },\\n    zoom\\n  } = camera // OK zoom; // Type is number\\n  window.location.search = `?v=@${lat},${lng}z${zoom}`\\n}\\n```\\n\\nThis time the type of zoom is number, rather than `number|undefined`. The `viewport ForBounds` function is now much easier to use. If there were any other functions that produced bounds, you would also need to introduce a canonical form and a distinction between `LngLatBounds` and `LngLatBoundsLike`.\\n\\nIs allowing 19 possible forms of bounding box a good design? Perhaps not. But if you’re writing type declarations for a library that does this, you need to model its behavior. Just don’t have 19 return types.\\n\",\n    \"positiveExamples\": [],\n    \"negativeExamples\": [],\n    \"fixable\": false,\n    \"level\": \"error\",\n    \"scope\": \"file\",\n    \"languages\": [\n      \"typescript\"\n    ],\n    \"tags\": [\n      \"best practices\"\n    ],\n    \"resources\": [\n      \"https://effectivetypescript.com\"\n    ],\n    \"exclude\": [\n      \"**/*\\\\.test\\\\.{js,ts,jsx,tsx,cjs,mjs}\"\n    ],\n    \"gritql\": \"function_declaration\",\n    \"gritqlNumLinesContext\": 3\n  },\n  {\n    \"source\": \"/Users/tfischer/dev/modules/gptlint/rules/no-hardcoded-secrets.md\",\n    \"cacheable\": true,\n    \"metadata\": {},\n    \"name\": \"no-hardcoded-secrets\",\n    \"title\": \"No hardcoded secrets\",\n    \"description\": \"Sensitive secrets should never be hardcoded in git because they represent a serious security risk.\\n\\nCommon use cases for secrets include:\\n\\n- private API keys and tokens\\n- authentication and authorization\\n- third-party service config\\n- private encryption keys\\n- cryptographic secrets for signing requests\\n\\nThe most common solution is to only access secrets from environment variables so they aren't committed as code.\\n\",\n    \"positiveExamples\": [\n      {\n        \"code\": \"const apiKey = process.env.OPENAI_API_KEY\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"const apiKey = process.env['OPENAI_API_KEY']\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"const apiKey = getEnv('OPENAI_API_KEY')\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"import OpenAI from 'openai'\\n\\nconst openai = new OpenAI({\\n  apiKey: process.env.OPENAI_API_KEY\\n})\",\n        \"language\": \"ts\"\n      }\n    ],\n    \"negativeExamples\": [\n      {\n        \"code\": \"const apiKey = 'sk-J6tsSvil9M7zF76PkyU...'\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"import OpenAI from 'openai'\\n\\nconst openai = new OpenAI({\\n  apiKey: 'sk-J6tsSvil9M7zF76PkyU...'\\n})\",\n        \"language\": \"js\"\n      }\n    ],\n    \"fixable\": false,\n    \"level\": \"error\",\n    \"scope\": \"file\",\n    \"languages\": [\n      \"all\"\n    ],\n    \"tags\": [\n      \"security\"\n    ],\n    \"gritql\": \"or { string(), template_string() } as $str where {\\n  $str <: not within import_statement(),\\n  $length = length($str),\\n  not or {\\n    $length <: 1,\\n    $length <: 2,\\n    $length <: 3,\\n    $length <: 4,\\n    $length <: 5,\\n    $length <: 6,\\n  }\\n}\",\n    \"gritqlNumLinesContext\": 3\n  },\n  {\n    \"source\": \"/Users/tfischer/dev/modules/gptlint/rules/prefer-array-at-negative-indexing.md\",\n    \"cacheable\": true,\n    \"metadata\": {},\n    \"name\": \"prefer-array-at-negative-indexing\",\n    \"title\": \"Prefer using Array.at when indexing from the end of an array\",\n    \"description\": \"When accessing items in an array from the end, like the last item, prefer using `Array.at` with a negative index because it is less error-prone. Note that using `Array.at` with a positive index is equivalent to indexing into the array normally, and if `Array.at` references a non-existing index, it will return `undefined`.\\n\",\n    \"positiveExamples\": [\n      {\n        \"code\": \"const items = [1, 2, 3, 4, 5, 6, 7]\\nconst lastItem = items.at(-1)\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"const items = [1, 2, 3, 4, 5, 6, 7]\\n\\n// This example is fine because it uses a normal, positive index\\nconst firstItem = items[0]\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"const items = [1, 2, 3, 4, 5, 6, 7]\\nconst index = example()\\n\\n// This example is fine because it uses a variable index\\nconst item = items[index]\",\n        \"language\": \"ts\"\n      }\n    ],\n    \"negativeExamples\": [\n      {\n        \"code\": \"const items = [1, 2, 3, 4, 5, 6, 7]\\nconst lastItem = items[items.length - 1]\",\n        \"language\": \"ts\"\n      }\n    ],\n    \"fixable\": false,\n    \"level\": \"error\",\n    \"scope\": \"file\",\n    \"languages\": [\n      \"javascript\",\n      \"typescript\"\n    ],\n    \"tags\": [\n      \"best practices\"\n    ],\n    \"eslint\": [\n      \"@unicorn/prefer-negative-index\"\n    ],\n    \"resources\": [\n      \"https://twitter.com/housecor/status/1768622518179369036\"\n    ],\n    \"gritql\": \"subscript_expression\",\n    \"gritqlNumLinesContext\": 3\n  },\n  {\n    \"source\": \"/Users/tfischer/dev/modules/gptlint/rules/prefer-loose-array-bounds-checks-in-loops.md\",\n    \"cacheable\": true,\n    \"metadata\": {},\n    \"name\": \"prefer-loose-array-bounds-checks-in-loops\",\n    \"title\": \"Prefer loose array bounds checks in loops\",\n    \"description\": \"Array bounds checks within loops should verify if a variable is `>=` or `<=` the array length instead of exactly equal to the array length. Performing strict bound checks on arrays in loops is brittle and a common cause of subtle bugs.\\n\\n```js\\nfunction handleTasks() {\\n  const tasks = [\\n    // ...\\n  ]\\n  let currentTaskIndex = 0\\n\\n  do {\\n    const currentTask = tasks[currentTaskIndex]\\n\\n    // process task\\n    // ...\\n\\n    currentTaskIndex++\\n  } while (currentTaskIndex !== tasks.length)\\n}\\n```\\n\\nThis example has two bugs:\\n\\n- if `tasks` is empty, the first iteration of the while loop will throw an error\\n- the `while` loop guard is very brittle which is a code smell. if `currentTaskIndex` somehow gets changed in an unexpected way with future code changes, then the `while` loop guard could end up going past the end of the tasks array!\\n\\nAn improved version of this code which fixes these buse looks like:\\n\\n```js\\nfunction handleTasks() {\\n  const tasks = [\\n    // ...\\n  ]\\n  let currentTaskIndex = 0\\n\\n  while (currentTaskIndex < tasks.length) {\\n    const currentTask = tasks[currentTaskIndex]\\n\\n    // process task\\n    // ...\\n\\n    currentTaskIndex++\\n  }\\n}\\n```\\n\",\n    \"positiveExamples\": [\n      {\n        \"code\": \"for (let i = 0; i < arr.length; i++) {}\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"for (let i = arr.length; i >= 0; i--) {}\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"while (i < tasks.length) {\\n  ++i\\n}\",\n        \"language\": \"js\"\n      }\n    ],\n    \"negativeExamples\": [\n      {\n        \"code\": \"for (let i = 0; i !== arr.length; i++) {\\n  // this is bad because it should use `i < arr.length` to be safer\\n}\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"for (let i = arr.length; i !== -1; i--) {\\n  // this is bad because it should use `i >= 0` or `i > -1` to be safer\\n}\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"while (i !== tasks.length) {\\n  // this is bad because it should use `i < tasks.length` to be safer\\n  ++i\\n}\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"const length = arr.length\\nlet i = 0\\nwhile (i !== length) {\\n  // this is bad because the while loop should use `i < length` to be safer\\n  ++i\\n}\",\n        \"language\": \"ts\"\n      }\n    ],\n    \"fixable\": false,\n    \"level\": \"error\",\n    \"scope\": \"file\",\n    \"languages\": [\n      \"javascript\",\n      \"typescript\"\n    ],\n    \"tags\": [\n      \"best practices\"\n    ],\n    \"exclude\": [\n      \"**/*.test\\\\.{js,ts,jsx,tsx,cjs,mjs}\"\n    ],\n    \"gritql\": \"or {\\n  any_equals(a = `$foo.length`, $b),\\n  any_not_equals(a = `$foo.length`, $b)\\n} as $op where {\\n  $op <: within or {\\n    do_statement(),\\n    while_statement(),\\n    for_statement()\\n  }\\n}\"\n  },\n  {\n    \"source\": \"/Users/tfischer/dev/modules/gptlint/rules/prefer-types-always-valid-states.md\",\n    \"cacheable\": true,\n    \"metadata\": {},\n    \"name\": \"prefer-types-always-valid-states\",\n    \"title\": \"Prefer types that always represent valid states\",\n    \"description\": \"A key to effective type design is crafting types that can only represent a valid state. This rule walks through a few examples of how this can go wrong and shows you how to fix them.\\n\\nAs an example, suppose you’re building a web application that lets you select a page, loads the con‐ tent of that page, and then displays it. You might write the state like this:\\n\\n```ts\\ninterface State {\\n  pageText: string\\n  isLoading: boolean\\n  error?: string\\n}\\n```\\n\\nWhen you write your code to render the page, you need to consider all of these fields:\\n\\n```ts\\nfunction renderPage(state: State) {\\n  if (state.error) {\\n    return `Error! Unable to load ${currentPage}: ${state.error}`\\n  } else if (state.isLoading) {\\n    return `Loading ${currentPage}...`\\n  }\\n  return `<h1>${currentPage}</h1>\\\\n${state.pageText}`\\n}\\n```\\n\\nIs this right, though? What if `isLoading` and `error` are both set? What would that mean? Is it better to display the loading message or the error message? It’s hard to say! There’s not enough information available.\\n\\nOr what if you’re writing a `changePage` function? Here’s an attempt:\\n\\n```ts\\nasync function changePage(state: State, newPage: string) {\\n  state.isLoading = true\\n  try {\\n    const response = await fetch(getUrlForPage(newPage))\\n    if (!response.ok) {\\n      throw new Error(`Unable to load ${newPage}: ${response.statusText}`)\\n    }\\n    const text = await response.text()\\n    state.isLoading = false\\n    state.pageText = text\\n  } catch (e) {\\n    state.error = '' + e\\n  }\\n}\\n```\\n\\nThere are many problems with this! Here are a few:\\n\\n- We forgot to set `state.isLoading` to `false` in the error case.\\n- We didn’t clear out `state.error`, so if the previous request failed, then you’ll keep seeing that error message instead of a loading message.\\n- If the user changes pages again while the page is loading, who knows what will happen. They might see a new page and then an error, or the first page and not the second depending on the order in which the responses come back.\\n\\nThe problem is that the state includes both too little information (which request failed? which is loading?) and too much: the `State` type allows both `isLoading` and `error` to be set, **even though this represents an invalid state**. This makes both `render()` and `changePage()` impossible to implement well.\\n\\nHere’s a better way to represent the application state:\\n\\n```ts\\ninterface RequestPending {\\n  state: 'pending'\\n}\\ninterface RequestError {\\n  state: 'error'\\n  error: string\\n}\\ninterface RequestSuccess {\\n  state: 'ok'\\n  pageText: string\\n}\\ntype RequestState = RequestPending | RequestError | RequestSuccess\\ninterface State {\\n  currentPage: string\\n  requests: { [page: string]: RequestState }\\n}\\n```\\n\\nThis uses a tagged union (also known as a “discriminated union”) to explicitly model the different states that a network request can be in. This version of the state is three to four times longer, but it has the enormous advantage of not admitting invalid states. The current page is modeled explicitly, as is the state of every request that you issue. As a result, the `renderPage` and `changePage` functions are easy to implement:\\n\\n```ts\\nfunction renderPage(state: State) {\\n  const { currentPage } = state\\n  const requestState = state.requests[currentPage]\\n\\n  switch (requestState.state) {\\n    case 'pending':\\n      return `Loading ${currentPage}...`\\n    case 'error':\\n      return `Error! Unable to load ${currentPage}: ${requestState.error}`\\n    case 'ok':\\n      return `<h1>${currentPage}</h1>\\\\n${requestState.pageText}`\\n  }\\n}\\n\\nasync function changePage(state: State, newPage: string) {\\n  state.requests[newPage] = { state: 'pending' }\\n  state.currentPage = newPage\\n\\n  try {\\n    const response = await fetch(getUrlForPage(newPage))\\n    if (!response.ok) {\\n      throw new Error(`Unable to load ${newPage}: ${response.statusText}`)\\n    }\\n    const pageText = await response.text()\\n    state.requests[newPage] = { state: 'ok', pageText }\\n  } catch (e) {\\n    state.requests[newPage] = { state: 'error', error: '' + e }\\n  }\\n}\\n```\\n\\nThe ambiguity from the first implementation is entirely gone: it’s clear what the cur‐ rent page is, and every request is in exactly one state. If the user changes the page after a request has been issued, that’s no problem either. The old request still com‐ pletes, but it doesn’t affect the UI.\\n\\n---\\n\\nOftentimes this rule pairs with the ideal of having as little mutable state as possible and preferring to derive state based on a small source of truth which is always valid.\\n\\nFor example, let's say you have a product resource:\\n\\n```ts\\nclass Product {\\n  isInStock: boolean\\n  quantityAvailable: number\\n}\\n```\\n\\n`Product` has a few problems here:\\n\\n- `isInStock` can be false with `quantityAvailable > 0` which doesn't make any sense\\n- `isInStock` can be true with `quantityAvailable === 0` which doesn't make any sense\\n\\nThe problem comes from `Product.isInStock` and `Product.quantityAvailable` both representing different aspects of the same underling data: in this case, how much of a product is currently available.\\n\\nA better solution would be to only store the minimal state necessary to model the `Product`'s valid states, and then derive any additional fields based on the model's minimal, valid state:\\n\\n```ts\\nclass Product {\\n  quantityAvailable: number\\n\\n  get isInStock() {\\n    // Derived based on `quantityAvailable` which guarantees that the product's\\n    // state is always valid.\\n    return this.quantityAvailable > 0\\n  }\\n}\\n```\\n\\n## Caveats\\n\\nWhen working with external APIs and data sources, it's not always possible to work with types which only represent valid state. So this rule should ignore any data coming from external dependencies and focus instead on types used internally within this project.\\n\\n## Key Takeaways\\n\\nTypes that represent both valid and invalid states are likely to lead to confusing and error-prone code.\\n\\nPrefer types that only represent valid states. Even if they are longer or harder to express, they will save you time and pain in the end.\\n\\nIf a field is useful, but adding it to a type could result the type representing invalid states, then consider whether that field can be derived from a minimal set of state that is always valid.\\n\",\n    \"positiveExamples\": [],\n    \"negativeExamples\": [],\n    \"fixable\": false,\n    \"level\": \"error\",\n    \"scope\": \"file\",\n    \"languages\": [\n      \"typescript\"\n    ],\n    \"tags\": [\n      \"best practices\"\n    ],\n    \"resources\": [\n      \"https://effectivetypescript.com\"\n    ],\n    \"exclude\": [\n      \"**/*\\\\.test\\\\.{js,ts,jsx,tsx,cjs,mjs}\",\n      \"**/*\\\\.{js,cjs,mjs,json}\"\n    ],\n    \"gritql\": \"or {\\n  type_alias_declaration(),\\n  interface_declaration()\\n}\",\n    \"gritqlNumLinesContext\": 3\n  },\n  {\n    \"source\": \"/Users/tfischer/dev/modules/gptlint/rules/react-avoid-class-components.md\",\n    \"cacheable\": true,\n    \"metadata\": {},\n    \"name\": \"react-avoid-class-components\",\n    \"title\": \"Don't use React class components\",\n    \"description\": \"React class components are deprecated. Use React functions and hooks instead.\\n\\nNote that uses `classes` is fine for non-react components.\\n\",\n    \"positiveExamples\": [\n      {\n        \"code\": \"export function Button() {\\n  return <div>Hello</div>\\n}\",\n        \"language\": \"tsx\"\n      },\n      {\n        \"code\": \"import EventEmitter from 'eventemitter3'\\n\\n// This is fine because it is a normal class and not a React component.\\nclass Foo extends EventEmitter {\\n  constructor() {}\\n}\",\n        \"language\": \"ts\"\n      }\n    ],\n    \"negativeExamples\": [\n      {\n        \"code\": \"import { Component } from 'react'\\n\\nexport class Label extends Component {\\n  render() {\\n    return <div>Hello</div>\\n  }\\n}\",\n        \"language\": \"tsx\"\n      },\n      {\n        \"code\": \"import react from 'react'\\n\\nexport class Label extends react.Component {\\n  render() {\\n    return <div />\\n  }\\n}\",\n        \"language\": \"tsx\"\n      }\n    ],\n    \"fixable\": false,\n    \"level\": \"error\",\n    \"scope\": \"file\",\n    \"languages\": [\n      \"javascript\",\n      \"typescript\"\n    ],\n    \"tags\": [\n      \"react\"\n    ],\n    \"eslint\": [\n      \"eslint-plugin-react-prefer-function-component\"\n    ],\n    \"include\": [\n      \"**/*.{jsx,tsx}\"\n    ],\n    \"gritql\": \"react_class_component\"\n  },\n  {\n    \"source\": \"/Users/tfischer/dev/modules/gptlint/rules/semantic-variable-names.md\",\n    \"cacheable\": true,\n    \"metadata\": {},\n    \"name\": \"semantic-variable-names\",\n    \"title\": \"Use semantic variable names\",\n    \"description\": \"Variable names should be descriptive and capture the semantics of the value they represent. This makes it easier to read and understand code. It also makes it clearer when variables are being misused.\\n\\n## Caveats\\n\\nAn exception to this rule is that it is acceptable to use simple variable names like `i` in `for` loops.\\n\\nAn exception to this rule is that math-heavy code may use simple variable names within the scope of a mathematically dense function.\\n\\nCommon acronyms like `api`, `ast`, and `llm` are fine even though they aren't as descriptive.\\n\\n`res`, `result`, and `data` are common exceptions that are okay to ignore.\\n\\nVariables names which mirror the corresponding type name are okay to ignore.\\n\\nKeys in objects and JS/TS strings are not variable names, so they should be ignored.\\n\\nIf a value isn't a variable name, then it should be ignored.\\n\\nThis rule should be ignored in test files.\\n\\nThe names of file imports from third-party APIs and modules should be ignored because we have no control over them.\\n\\nIf you are unsure whether or not a variable name is descriptive enough, err on the side of caution by setting `confidence` to `low`.\\n\",\n    \"positiveExamples\": [\n      {\n        \"code\": \"// Good because \\\"numTokens\\\" is descriptive\\nconst numTokens = 5\\n\\n// Good because \\\"isFinished\\\" is descriptive\\nconst isFinished = true\\n\\n// Good because \\\"ast\\\" is an acronym\\nconst ast = parseAST()\\n\\n// Good because \\\"fileTypeToParserMap\\\" is very descriptive\\nconst fileTypeToParserMap: Record<string, string> = {}\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"// \\\"i\\\" is okay here because it is a simple for loop\\nfor (let i = 0; i < 10; i++) {}\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"// \\\"x\\\", \\\"y\\\", and \\\"r\\\" are all okay here because they represent real, mathematical\\n// concepts, and concise variable names are often preferred in math-heavy code.\\nfunction normalDist(mu = 0, sigma = 1) {\\n  let x: number, y: number, r: number\\n\\n  do {\\n    x = Math.random() * 2 - 1\\n    y = Math.random() * 2 - 1\\n    r = x * x + y * y\\n  } while (!r || r > 1)\\n\\n  return mu + sigma * y * Math.sqrt((-2 * Math.log(r)) / r)\\n}\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"// These are fine because the simple variable names match the corresponding type names.\\nconst rule: Rule = {}\\nconst data: Data = {}\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"// This is fine because `z` is an external dependency that we have no control over.\\nimport { z } from 'zod'\",\n        \"language\": \"ts\"\n      }\n    ],\n    \"negativeExamples\": [\n      {\n        \"code\": \"// Bad because \\\"a\\\" is not a descriptive variable name\\nconst a = 5\\n\\n// Bad because \\\"b\\\" is not a descriptive variable name\\nconst b = false\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"// Bad because \\\"obj\\\" is not a descriptive variable name\\nconst obj = { id: 5, name: 'Bob' }\",\n        \"language\": \"js\"\n      }\n    ],\n    \"fixable\": false,\n    \"level\": \"error\",\n    \"scope\": \"file\",\n    \"languages\": [\n      \"javascript\",\n      \"typescript\"\n    ],\n    \"tags\": [\n      \"best practices\"\n    ],\n    \"exclude\": [\n      \"**/*\\\\.test\\\\.{js,ts,jsx,tsx,cjs,mjs}\"\n    ],\n    \"gritql\": \"identifier() as $id where {\\n  or {\\n    and {\\n      $id <: within or {\\n        variable_declarator($name),\\n        required_parameter($name),\\n        optional_parameter($name)\\n      },\\n      $id <: $name\\n    },\\n\\n    or {\\n      and {\\n        $id <: within `function $func($props): $ret {$body}`,\\n        $id <: not or { within $body, within $func }\\n      },\\n      and {\\n        $id <: within `function $func($props) {$body}`,\\n        $id <: not or { within $body, within $func }\\n      },\\n      and {\\n        $id <: within `($props) => $body`,\\n        $id <: not within $body\\n      }\\n    }\\n  }\\n}\",\n    \"gritqlNumLinesContext\": 2\n  },\n  {\n    \"source\": \"/Users/tfischer/dev/modules/gptlint/rules/soc2-no-leak-user-data.md\",\n    \"cacheable\": true,\n    \"metadata\": {},\n    \"name\": \"soc2-no-leak-user-data\",\n    \"title\": \"SOC2 Don't leak user data\",\n    \"description\": \"Don't log potentially sensitive customer data or we'll lose our SOC2 certification.\\n\\nNon-identifying user data such as internal IDs or other internal models related to a user are fine to log and expose.\\n\",\n    \"positiveExamples\": [\n      {\n        \"code\": \"// Logging non-identifying user data such as internal IDs is fine\\nconsole.log(user.id)\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"// Logging non-identifying user data such as internal IDs is fine\\nlogger.warn(`Invalid user: ${user.id}`)\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"// Exposing non-identifying user data such as internal IDs is fine\\nthrow new Error(`User error ${user.id}`)\",\n        \"language\": \"ts\"\n      },\n      {\n        \"code\": \"// Logging internal resources related to a user is okay\\nconsole.log(user.posts)\",\n        \"language\": \"js\"\n      }\n    ],\n    \"negativeExamples\": [\n      {\n        \"code\": \"// Don't log potentially sensitive user data\\nconsole.log(user)\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"// Don't log potentially sensitive user data\\nlog.info(user)\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"// Don't log sensitive user information like `email`\\nconsole.error('Invalid user', user.email)\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"// Don't log request bodies which may contain sensitive user data\\nlog.info({ body: req.body })\",\n        \"language\": \"js\"\n      },\n      {\n        \"code\": \"// Don't expose request bodies which may contain sensitive user data\\nthrow new Error('error', { body: req.body })\",\n        \"language\": \"js\"\n      }\n    ],\n    \"fixable\": false,\n    \"level\": \"error\",\n    \"scope\": \"file\",\n    \"languages\": [\n      \"javascript\",\n      \"typescript\"\n    ],\n    \"tags\": [\n      \"security\"\n    ],\n    \"gritql\": \"or {\\n  `console.$method($args)`,\\n  `logger.$method($args)`,\\n  `log.$method($args)`,\\n  `throw new $Error($msg)`\\n}\",\n    \"gritqlNumLinesContext\": 2\n  },\n  {\n    \"source\": \"/Users/tfischer/dev/modules/gptlint/rules/use-correct-english.md\",\n    \"cacheable\": true,\n    \"metadata\": {},\n    \"name\": \"use-correct-english\",\n    \"title\": \"Docs should use correct English spelling and grammar\",\n    \"description\": \"All comments and documentation should use correct English spelling and grammar. Obvious spelling errors should be repoted as violations.\\n\\nThis rule applies to code comments, JSDoc comments, and markdown documentation.\\n\\n## Caveats\\n\\nThis rule does *not* apply to code identifiers (variable names, function names, type names, etc) which often use shorthand.\\n\\nThis rule also does not apply to `TODO` comments.\\n\",\n    \"positiveExamples\": [],\n    \"negativeExamples\": [\n      {\n        \"code\": \"This is a violation becuse it includs spelling errors.\",\n        \"language\": \"md\"\n      },\n      {\n        \"code\": \"This example uses broken english grammar because bad.\",\n        \"language\": \"md\"\n      }\n    ],\n    \"fixable\": false,\n    \"level\": \"error\",\n    \"scope\": \"file\",\n    \"tags\": [\n      \"best practices\"\n    ],\n    \"gritql\": \"comment\"\n  }\n]","import type * as types from './types.js'\nimport * as customRuleDefinitions from '../rules/custom/index.js'\nimport builtInRules from './built-in-rules.json'\nimport { defaultFiles } from './constants.js'\n\nconst ruleDefinitions: types.RuleDefinition[] = [\n  ...(builtInRules as types.RuleDefinition[]),\n  ...Object.values(customRuleDefinitions)\n]\n\nconst ruleSettings: types.LinterConfigRuleSettings = Object.fromEntries(\n  ruleDefinitions.map((rule) => [rule.name, 'error'])\n)\n\nexport const recommendedConfig: types.GPTLintConfig = [\n  {\n    files: defaultFiles,\n    ruleDefinitions,\n    rules: ruleSettings\n  }\n]\n\n// console.log(JSON.stringify(recommendedConfig.map(sanitizeConfig), null, 2))\n","import { Msg, type Prompt } from '@dexaai/dexter'\nimport plur from 'plur'\n\nimport type * as types from './types.js'\nimport { defaultLinterConfig, isValidModel } from './config.js'\nimport {\n  AbortError,\n  type FailedAttemptError,\n  RetryableError\n} from './errors.js'\nimport { preProcessFileWithGrit } from './gritql.js'\nimport { createLintResult, dedupeLintErrors } from './lint-result.js'\nimport { stringifyRuleForModel } from './rule-utils.js'\nimport {\n  isRuleViolationLikelyFalsePositive,\n  parseRuleViolationsFromJSONModelResponse,\n  parseRuleViolationsFromMarkdownModelResponse,\n  type RuleViolation,\n  stringifyExampleRuleViolationsArrayOutputForModel,\n  stringifyExampleRuleViolationsObjectOutputForModel,\n  stringifyRuleViolationForModel,\n  stringifyRuleViolationSchemaForModel\n} from './rule-violations.js'\nimport { pruneUndefined, trimMessage } from './utils.js'\n\n// TODO: Improve the duplication between `lintFile` and `validateRuleViolations`\n// for two-pass linting.\n\n/**\n * Core linting logic which takes in a single `rule` and a single `file` and\n * uses the `chatModel` LLM to extract rule violations using structured output.\n */\nexport async function lintFile({\n  file,\n  rule,\n  lintResult,\n  chatModel,\n  cache,\n  config,\n  cwd,\n  retryOptions = {\n    retries: 2\n  },\n  enableGrit = false\n}: types.RuleProcessFileFnParams & {\n  enableGrit?: boolean\n}): Promise<types.LintResult> {\n  lintResult = createLintResult(lintResult)\n\n  const isTwoPassLintingEnabled = isValidModel(config.llmOptions.weakModel)\n  const model =\n    rule.model ?? isTwoPassLintingEnabled\n      ? config.llmOptions.weakModel!\n      : config.llmOptions.model\n\n  // This path is only used for running evals with grit enabled, since the evals\n  // don't call `lintFiles` but rather `lintFile` directly.\n  if (enableGrit && rule.gritql) {\n    const ruleNameToPartialSourceFileMap = new Map<\n      string,\n      Promise<Map<string, types.PartialSourceFile>>\n    >()\n\n    const maybeLintResult = await preProcessFileWithGrit({\n      file,\n      rule,\n      config,\n      ruleNameToPartialSourceFileMap\n    })\n\n    if (maybeLintResult) {\n      return maybeLintResult\n    }\n  }\n\n  if (config.linterOptions.debug) {\n    console.log(\n      `>>> Linting rule \"${rule.name}\" file \"${file.fileRelativePath}\" with model \"${model}\"`\n    )\n  }\n\n  const messages: Prompt.Msg[] = [\n    Msg.system(`<INSTRUCTIONS>\n\nYou are an expert senior TypeScript software engineer at Vercel who loves to lint code. You make sure source code conforms to project-specific guidelines and best practices. You will be given a RULE with a description of the RULE's intent and some positive examples where the RULE is used correctly and some negative examples where the RULE is VIOLATED (used incorrectly).\n\nYour task is to take the given SOURCE code and determine whether any portions of it VIOLATE the RULE's intent.\n\n</INSTRUCTIONS>\n\n---\n\n${stringifyRuleForModel(rule)}\n\n---\n\n<SOURCE ${file.fileName}>\n\n${file.partialContent || file.content}\n\n</SOURCE ${file.fileName}> \n`),\n\n    Msg.user(`Your job is to identify any portions of the SOURCE ${\n      file.fileName\n    } which are related to the RULE ${rule.name} and explain whether they VIOLATE or conform to the RULE's intent. Your answer should contain two markdown sections, EXPLANATION and VIOLATIONS.\n\nAccuracy is important, so be sure to think step-by-step and explain your reasoning briefly in the EXPLANATION section. Do not list out all variable names or identifiers in the EXPLANATION section, but rather focus on listing out the most relevant portions of the SOURCE that the given RULE may apply to.\n\nIf you find any code snippets which VIOLATE the RULE, then output them as RULE_VIOLATION objects in the VIOLATIONS section. The VIOLATIONS section should be a JSON array of RULE_VIOLATION objects. This array may be empty if there are no RULE VIOLATIONS. Ignore code snippets which correctly conform to the RULE.\n\n---\n\n<RULE_VIOLATION schema>\n\n${stringifyRuleViolationSchemaForModel(rule, file)}\n\n</RULE_VIOLATION schema>\n\n---\n\nExample markdown output format:\n\n# EXPLANATION\n\nPlain text explanation of any areas of the SOURCE code which may be affected by the RULE and brief reasoning for any potential VIOLATIONS.\n\n# VIOLATIONS\n\n${stringifyExampleRuleViolationsArrayOutputForModel(rule)}\n`)\n  ]\n\n  let retries = retryOptions.retries\n\n  do {\n    try {\n      // Useful for testing fake errors\n      // if (rule.name === 'use-esm') {\n      //   throw new RetryableError('example error for testing')\n      // } else if (rule.name === 'semantic-variable-names') {\n      //   lintResult.lintErrors.push({\n      //     message: rule.title,\n      //     filePath: file.fileRelativePath,\n      //     language: file.language,\n      //     model,\n      //     ruleName: rule.name,\n      //     codeSnippet: 'const TODO = 1',\n      //     confidence: 'high',\n      //     reasoning: 'EXAMPLE',\n      //     level: 'error'\n      //   })\n      //   return lintResult\n      // }\n\n      const res = await chatModel.run({\n        model,\n        messages\n      })\n\n      const response = res.message.content!\n      lintResult.message = response\n\n      if (config.linterOptions.debug) {\n        console.log(\n          `\\nrule \"${rule.name}\" file \"${file.fileRelativePath}\" response from model \"${model}\":\\n\\n${response}\\n\\n`\n        )\n      }\n\n      messages.push(Msg.assistant(response))\n\n      if (res.cached) {\n        lintResult.numModelCallsCached++\n      } else {\n        lintResult.numModelCalls++\n      }\n\n      if (res.cost) {\n        lintResult.totalCost += res.cost\n      } else if ((res.usage as any)?.total_cost) {\n        lintResult.totalCost += 100 * (res.usage as any).total_cost\n      }\n\n      if (res.usage) {\n        lintResult.numPromptTokens += res.usage.prompt_tokens\n        lintResult.numCompletionTokens += res.usage.completion_tokens\n        lintResult.numTotalTokens += res.usage.total_tokens\n      }\n\n      const ruleViolations =\n        parseRuleViolationsFromMarkdownModelResponse(response)\n\n      for (const ruleViolation of ruleViolations) {\n        if (isRuleViolationLikelyFalsePositive({ ruleViolation, rule, file })) {\n          // Ignore any false positives\n          continue\n        }\n\n        const { confidence, codeSnippet, reasoning } = ruleViolation\n\n        lintResult.lintErrors.push({\n          message: rule.title,\n          filePath: file.filePath,\n          language: file.language,\n          ruleName: rule.name,\n          level: rule.level,\n          model,\n          codeSnippet,\n          confidence,\n          reasoning\n        })\n      }\n\n      // We've successfully processed the model output, so break out of the\n      // retry loop.\n      break\n    } catch (err: any) {\n      if (err instanceof AbortError || err.name === 'AbortError') {\n        throw err\n      }\n\n      if (retries-- <= 0) {\n        throw err\n      }\n\n      if (err instanceof RetryableError) {\n        if (config.linterOptions.debug) {\n          console.warn(\n            `\\nRETRYING error processing rule \"${rule.name}\" file \"${file.fileRelativePath}\": ${err.message}\\n\\n`\n          )\n        }\n\n        if (retryOptions?.onFailedAttempt) {\n          if (retryOptions?.onFailedAttempt) {\n            ;(err as any).attemptNumber = Math.max(\n              0,\n              retryOptions.retries - retries - 1\n            )\n            ;(err as any).retriesLeft = retries\n\n            await Promise.resolve(\n              retryOptions.onFailedAttempt(err as FailedAttemptError)\n            )\n          }\n        }\n\n        // Retry\n        const errMessage = err.message\n        messages.push(\n          Msg.user(\n            `There was an error validating the response. Please check the error message and try again.\\nError:\\n${errMessage}`\n          )\n        )\n      } else {\n        if (config.linterOptions.debug) {\n          console.error(\n            `Unexpected error processing rule \"${rule.name}\" file \"${file.fileRelativePath}\":`,\n            trimMessage(err.message, { maxLength: 400 })\n          )\n        }\n\n        throw new TypeError(\n          `Unexpected error processing rule \"${rule.name}\" file \"${file.fileRelativePath}\": ${trimMessage(err.message)}`,\n          { cause: err }\n        )\n      }\n    }\n  } while (true)\n\n  lintResult.lintErrors = dedupeLintErrors(lintResult.lintErrors)\n\n  if (lintResult.lintErrors.length > 0 && isTwoPassLintingEnabled) {\n    const { lintErrors: originalLintErrors } = lintResult\n    if (config.linterOptions.debug) {\n      console.log(\n        `\\n>>> VALIDATING ${originalLintErrors.length} ${plur(\n          'error',\n          originalLintErrors.length\n        )} for rule \"${rule.name}\" file \"${file.fileRelativePath}\":`,\n        originalLintErrors\n      )\n    }\n\n    lintResult = await validateRuleViolations({\n      file,\n      rule,\n      lintResult,\n      chatModel,\n      cache,\n      config,\n      retryOptions,\n      cwd\n    })\n\n    if (config.linterOptions.debug) {\n      const { lintErrors } = lintResult\n\n      console.log(\n        `\\n<<< DONE VALIDATING ${originalLintErrors.length} ${plur(\n          'error',\n          originalLintErrors.length\n        )} ⇒ ${lintErrors.length} ${plur(\n          'error',\n          lintErrors.length\n        )} for rule \"${rule.name}\" file \"${file.fileRelativePath}\":`,\n        lintErrors\n      )\n    }\n  }\n\n  if (config.linterOptions.debug) {\n    const { lintErrors } = lintResult\n\n    if (lintErrors.length > 0) {\n      console.log(\n        `\\n<<< FAIL Rule \"${rule.name}\" file \"${file.fileRelativePath}\": ${\n          lintErrors.length\n        } ${plur('error', lintErrors.length)} found:`,\n        lintErrors\n      )\n    } else {\n      console.log(\n        `\\n<<< PASS Rule \"${rule.name}\" file \"${file.fileRelativePath}\"`\n      )\n    }\n  }\n\n  return lintResult\n}\n\n/**\n * If two-pass linting is enabled, then this function is called after the first\n * pass to validate the potential rule violations from the first pass using a\n * smarter model.\n *\n * This pass is aimed at reducing false positives.\n */\nexport async function validateRuleViolations({\n  file,\n  rule,\n  lintResult,\n  chatModel,\n  config,\n  retryOptions = {\n    retries: 2\n  }\n}: types.RulePostProcessFileFnParams): Promise<types.LintResult> {\n  const model = rule.model ?? config.llmOptions.model\n  lintResult = createLintResult(lintResult)\n\n  // Determine if the model supports JSON response format, which is preferred,\n  // or fallback to the default behavior of parsing JSON in a markdown code block\n  // from the model's text response.\n  // TODO: supporting both JSON output and markdown output here isn't ideal, but\n  // for OpenAI models, the JSON output is much more reliable so we'd like to\n  // take advantage of that if possible. For compatibility with other LLMs,\n  // however, we need to support the non-JSON-mode output as well which makes\n  // the implementation harder to debug, evaluate, and maintain.\n  const modelSupportsJsonResponseFormat =\n    config.llmOptions.modelSupportsJsonResponseFormat ??\n    ((config.llmOptions.apiBaseUrl ===\n      defaultLinterConfig.llmOptions.apiBaseUrl! &&\n      model !== 'gpt-4') ||\n      config.llmOptions.apiBaseUrl === 'https://api.groq.com/openai/v1')\n\n  const potentialRuleViolations: Partial<RuleViolation>[] =\n    lintResult.lintErrors.map((error) => ({\n      ruleName: rule.name,\n      codeSnippet: error.codeSnippet,\n      codeSnippetSource: 'unknown'\n      // We intentionally omit the weak model's `reasoning` here because it may\n      // be misleading, and that's what we're relying on the strong model for.\n    }))\n\n  const messages: Prompt.Msg[] = [\n    Msg.system(`<INSTRUCTIONS>\n\nYou are an expert senior TypeScript software engineer at Vercel who loves to lint code. You make sure source code conforms to project-specific guidelines and best practices. You will be given a RULE with a description of the RULE's intent and some positive examples where the RULE is used correctly and some negative examples where the RULE is VIOLATED (used incorrectly).\n\nYour task is to take the given SOURCE code and an array of POTENTIAL RULE_VIOLATION objects and determine whether these rule violations actually VIOLATE the RULE's intent.\n\n</INSTRUCTIONS>\n\n---\n\n${stringifyRuleForModel(rule)}\n\n---\n\n<SOURCE ${file.fileName}>\n\n${file.partialContent || file.content}\n\n</SOURCE ${file.fileName}> \n`),\n\n    Msg.user(`Given the POTENTIAL RULE_VIOLATION objects from the SOURCE code ${\n      file.fileName\n    }, determine whether these rule violations actually VIOLATE the RULE's intent.\n\nFor any potential RULE_VIOLATION objects which VIOLATE the RULE, include them in the output with \\`violation\\` set to \\`true\\` and explain your \\`reasoning\\`. For any potential RULE_VIOLATION objects which correctly conform to the RULE, then include them in the output with \\`violation\\` set to \\`false\\` and explain your \\`reasoning\\`.\n\n---\n\n<RULE_VIOLATION schema>\n\n${stringifyRuleViolationSchemaForModel(rule, file)}\n\n</RULE_VIOLATION schema>\n\n---\n\nPOTENTIAL RULE_VIOLATION objects to check:\n\n${stringifyRuleViolationForModel(potentialRuleViolations)}\n\n---\n\nExample ${modelSupportsJsonResponseFormat ? 'JSON' : 'markdown'} output format:\n\n${\n  modelSupportsJsonResponseFormat\n    ? stringifyExampleRuleViolationsObjectOutputForModel(rule)\n    : `# VIOLATIONS\n\n${stringifyExampleRuleViolationsArrayOutputForModel(rule)}`\n}\n`)\n  ]\n\n  let retries = retryOptions.retries\n\n  do {\n    try {\n      const res = await chatModel.run(\n        pruneUndefined({\n          model,\n          messages,\n          response_format: modelSupportsJsonResponseFormat\n            ? { type: 'json_object' }\n            : undefined\n        })\n      )\n\n      const response = res.message.content!\n      lintResult.message = response\n\n      if (config.linterOptions.debug) {\n        console.log(\n          `\\nrule \"${rule.name}\" file \"${file.fileRelativePath}\" response from model \"${model}\":\\n\\n${response}\\n\\n`\n        )\n      }\n\n      messages.push(Msg.assistant(response))\n\n      if (res.cached) {\n        lintResult.numModelCallsCached++\n      } else {\n        lintResult.numModelCalls++\n      }\n\n      if (res.cost) {\n        lintResult.totalCost += res.cost\n      } else if ((res.usage as any)?.total_cost) {\n        lintResult.totalCost += 100 * (res.usage as any).total_cost\n      }\n\n      if (res.usage) {\n        lintResult.numPromptTokens += res.usage.prompt_tokens\n        lintResult.numCompletionTokens += res.usage.completion_tokens\n        lintResult.numTotalTokens += res.usage.total_tokens\n      }\n\n      const ruleViolations = modelSupportsJsonResponseFormat\n        ? parseRuleViolationsFromJSONModelResponse(response)\n        : parseRuleViolationsFromMarkdownModelResponse(response, {\n            numExpectedMarkdownHeadings: 1\n          })\n\n      // Overwrite lint errors from the first-pass with the validated violations\n      // NOTE: This should appear after we've successfully validated the model's\n      // response, so we don't prematurely overwrite the original lint errors.\n      lintResult.lintErrors = []\n\n      for (const ruleViolation of ruleViolations) {\n        if (isRuleViolationLikelyFalsePositive({ ruleViolation, rule, file })) {\n          // Ignore any false positives\n          continue\n        }\n\n        const { confidence, codeSnippet, reasoning } = ruleViolation\n\n        lintResult.lintErrors.push({\n          message: rule.title,\n          filePath: file.filePath,\n          language: file.language,\n          ruleName: rule.name,\n          level: rule.level,\n          model,\n          codeSnippet,\n          confidence,\n          reasoning\n        })\n      }\n\n      // We've successfully processed the model output, so break out of the\n      // retry loop.\n      break\n    } catch (err: any) {\n      if (err instanceof AbortError || err.name === 'AbortError') {\n        throw err\n      }\n\n      if (retries-- <= 0) {\n        throw err\n      }\n\n      if (err instanceof RetryableError) {\n        if (config.linterOptions.debug) {\n          console.warn(\n            `\\nRETRYING error processing rule \"${rule.name}\" file \"${file.fileRelativePath}\": ${err.message}\\n\\n`\n          )\n        }\n\n        if (retryOptions?.onFailedAttempt) {\n          ;(err as any).attemptNumber = Math.max(\n            0,\n            retryOptions.retries - retries - 1\n          )\n          ;(err as any).retriesLeft = retries\n\n          await Promise.resolve(\n            retryOptions.onFailedAttempt(err as FailedAttemptError)\n          )\n        }\n\n        // Retry\n        const errMessage = err.message\n        messages.push(\n          Msg.user(\n            `There was an error validating the response. Please check the error message and try again.\\nError:\\n${errMessage}`\n          )\n        )\n      } else {\n        if (config.linterOptions.debug) {\n          console.error(\n            `Unexpected error processing rule \"${rule.name}\" file \"${file.fileRelativePath}\":`,\n            trimMessage(err.message, { maxLength: 400 })\n          )\n        }\n\n        throw new TypeError(\n          `Unexpected error processing rule \"${rule.name}\" file \"${file.fileRelativePath}\": ${trimMessage(err.message)}`,\n          { cause: err }\n        )\n      }\n    }\n  } while (true)\n\n  lintResult.lintErrors = dedupeLintErrors(lintResult.lintErrors)\n  return lintResult\n}\n","export { AbortError, type FailedAttemptError } from 'p-retry'\n\nexport class RetryableError extends Error {}\n\nexport class ParseError extends RetryableError {}\n","import fs from 'node:fs/promises'\nimport path from 'node:path'\n\nimport { execa } from 'execa'\nimport { packageDirectory } from 'pkg-dir'\nimport plur from 'plur'\nimport which from 'which'\n\nimport type * as types from './types.js'\nimport * as constants from './constants.js'\nimport { createLintResult } from './lint-result.js'\nimport { assert, dirname } from './utils.js'\n\n/**\n * @see https://github.com/getgrit/gritql\n */\nexport namespace grit {\n  export interface Match {\n    __typename: Typename\n    messages: any[]\n    variables: Variable[]\n    sourceFile: string\n    ranges: Range[]\n    level?: number\n    message?: string\n    debug?: string\n  }\n\n  export type Typename = 'Match' | 'AnalysisLog' | 'AllDone'\n\n  export interface Range {\n    start: FileOffset\n    end: FileOffset\n    startByte: number\n    endByte: number\n  }\n\n  export interface FileOffset {\n    line: number\n    column: number\n  }\n\n  export interface Variable {\n    name: VariableName\n    scopedName: ScopedName\n    ranges: Range[]\n  }\n\n  export type VariableName =\n    | '$absolute_filename'\n    | '$all_imports'\n    | '$anchor'\n    | '$body'\n    | '$filename'\n    | '$GLOBAL_IMPORTED_NAMES'\n    | '$GLOBAL_IMPORTED_SOURCES'\n    | '$h'\n    | '$imported_names'\n    | '$imports'\n    | '$joined_imported_names'\n    | '$match'\n    | '$name'\n    | '$new_files'\n    | '$p'\n    | '$program'\n    | '$source'\n    | '$statements'\n    | string\n\n  export type ScopedName = string\n}\n\n/**\n * Resolves a GritQL pattern against the given source files and then resolves\n * the matches to construct partial source files containing only the matched\n * portions.\n */\nexport async function resolveGritQLPattern(\n  pattern: string,\n  {\n    files,\n    numLinesContext = constants.gritNumLinesContext\n  }: {\n    files: types.SourceFile[]\n    // Number of lines of context to include around each matching range\n    numLinesContext?: number\n  }\n): Promise<Map<string, types.PartialSourceFile>> {\n  if (!(await hasGrit())) {\n    return new Map()\n  }\n\n  const matches = await applyGritQLPattern(pattern, { files })\n  return resolveGritQLMatches(matches, { files, numLinesContext })\n}\n\n/**\n * Runs `grit apply --dry-run --jsonl` on the given `pattern` and `files`.\n *\n * Returns an array of matches.\n */\nexport async function applyGritQLPattern(\n  pattern: string,\n  {\n    files\n  }: {\n    files: types.SourceFile[]\n  }\n): Promise<grit.Match[]> {\n  const gritBinary = await whichGritBinary()\n  if (!gritBinary) {\n    throw new Error(`Could not find 'grit' binary in $PATH`)\n  }\n\n  const paths = files.map((file) => file.filePath)\n\n  const res = await execa(gritBinary, [\n    'apply',\n    '--dry-run',\n    '--jsonl',\n    pattern,\n    ...paths\n  ])\n\n  // Parse the jsonl output for matches\n  const lines = res.stdout\n    .split('\\n')\n    .map((line) => line.trim())\n    .filter(Boolean)\n  const gritMatches = lines\n    .map((line) => {\n      try {\n        const potentialMatch = JSON.parse(line) as grit.Match\n        if (potentialMatch?.__typename !== 'Match') {\n          return undefined\n        }\n\n        const { debug: _, ...match } = potentialMatch\n        return match\n      } catch {\n        return undefined\n      }\n    })\n    .filter(Boolean)\n\n  return gritMatches\n}\n\nexport async function hasGrit(): Promise<boolean> {\n  const gritBinary = await whichGritBinary()\n  return !!gritBinary\n}\n\nexport async function whichGritBinary(): Promise<string | null> {\n  const gritBinary = await which('grit', { nothrow: true })\n  if (gritBinary) return gritBinary\n\n  // Resolve optional local install of `node_modules/.bin/grit`\n  const pkgDir = await packageDirectory({\n    cwd: dirname()\n  })\n  if (!pkgDir) return null\n\n  const maybeLocalGritBinary = path.resolve(\n    pkgDir,\n    'node_modules',\n    '.bin',\n    'grit'\n  )\n\n  try {\n    await fs.access(maybeLocalGritBinary, fs.constants.R_OK | fs.constants.X_OK)\n    return maybeLocalGritBinary\n  } catch {\n    return null\n  }\n}\n\n/**\n * Takes an array of GritQL `matches` and the `files` they're matched against,\n * and returns an array of partial source files containing only the matched\n * portions of the given files.\n */\nexport function resolveGritQLMatches(\n  matches: grit.Match[],\n  {\n    files,\n    numLinesContext = constants.gritNumLinesContext\n  }: {\n    files: types.SourceFile[]\n    // Number of lines of context to include around each matching range\n    numLinesContext?: number\n  }\n): Map<string, types.PartialSourceFile> {\n  const matchesByFilePath = new Map<string, grit.Match[]>()\n\n  // Group matches by absolute file path\n  for (const match of matches) {\n    // TODO: verify if this is using absolute or relative paths\n    if (!matchesByFilePath.has(match.sourceFile)) {\n      matchesByFilePath.set(match.sourceFile, [])\n    }\n    matchesByFilePath.get(match.sourceFile)!.push(match)\n  }\n\n  const partialFilesByFilePath = new Map<string, types.PartialSourceFile>()\n\n  // Group partial files by absolute file path\n  for (const file of files) {\n    const { filePath } = file\n\n    if (!partialFilesByFilePath.has(filePath)) {\n      partialFilesByFilePath.set(filePath, {\n        ...file,\n        ranges: [],\n        partialContent: ''\n      })\n    }\n  }\n\n  // Concat all the ranges for each file\n  for (const [filePath, matches] of matchesByFilePath.entries()) {\n    const partialFile = partialFilesByFilePath.get(filePath)!\n    assert(partialFile)\n\n    const matchRanges = matches.flatMap(\n      (m) => m.variables.find((v) => v.name === '$match')?.ranges ?? m.ranges\n    )\n\n    partialFile.ranges = partialFile.ranges\n      .concat(matchRanges)\n      .sort((a, b) => a.start.line - b.start.line)\n  }\n\n  // Aggregate the partial content for each file based on the matched ranges\n  for (const partialFile of partialFilesByFilePath.values()) {\n    const lines = partialFile.content.split('\\n')\n    const { ranges } = partialFile\n\n    let partialContentLines: string[] = []\n    let maxLine = -1\n\n    for (const range of ranges) {\n      const startLine = Math.max(\n        Math.max(0, maxLine),\n        range.start.line - 1 - numLinesContext\n      )\n      const endLine = range.end.line + numLinesContext\n      if (startLine >= endLine) continue\n\n      maxLine = Math.max(endLine, maxLine)\n      const partialLines = lines.slice(startLine, endLine)\n      partialContentLines = partialContentLines.concat(partialLines)\n    }\n\n    partialFile.partialContent = partialContentLines\n      // .filter((line) => !!line.trim())\n      .join('\\n')\n      .trim()\n  }\n\n  return partialFilesByFilePath\n}\n\nexport async function preProcessFileWithGrit({\n  file,\n  files,\n  rule,\n  config,\n  ruleNameToPartialSourceFileMap\n}: {\n  file: types.SourceFile | types.PartialSourceFile\n  rule: types.Rule\n  config: types.ResolvedLinterConfig\n  files?: (types.SourceFile | types.PartialSourceFile)[]\n  ruleNameToPartialSourceFileMap: Map<\n    string,\n    Promise<Map<string, types.PartialSourceFile>>\n  >\n}): Promise<types.LintResult | undefined> {\n  if (!rule.gritql || config.linterOptions.noGrit) {\n    return\n  }\n\n  if (!ruleNameToPartialSourceFileMap.has(rule.name)) {\n    // NOTE: We're purposefully not awaiting the result of this promise here.\n    const partialSourceFileMapP = resolveGritQLPattern(rule.gritql, {\n      files: files ?? [file],\n      numLinesContext: rule.gritqlNumLinesContext\n    })\n    ruleNameToPartialSourceFileMap.set(rule.name, partialSourceFileMapP)\n\n    const partialSourceFileMap = await partialSourceFileMapP\n    if (config.linterOptions.debugGrit) {\n      console.log(\n        `rule ${rule.name} gritql matches:\\n\\n${[\n          ...partialSourceFileMap.values()\n        ]\n          .map(\n            (f) =>\n              `  ${f.fileRelativePath} found ${f.ranges?.length || 0} ${plur('match', f.ranges?.length || 0)}`\n          )\n          .join('\\n\\n')}\\n\\n`\n      )\n    }\n  }\n\n  const partialSourceFileMap = await ruleNameToPartialSourceFileMap.get(\n    rule.name\n  )!\n\n  const partialSourceFile = partialSourceFileMap.get(file.filePath)\n  if (!partialSourceFile) {\n    return\n  }\n\n  file.ranges = partialSourceFile.ranges\n  file.partialContent = partialSourceFile.partialContent.trim()\n\n  if (!file.ranges.length || !file.partialContent) {\n    return createLintResult({\n      skipped: true,\n      skipReason: 'grit-pattern',\n      skipDetail: 'no gritql matches'\n    })\n  }\n}\n","import type { Code } from 'mdast'\nimport { toString } from 'mdast-util-to-string'\nimport { z } from 'zod'\n\nimport type * as types from './types.js'\nimport { RetryableError } from './errors.js'\nimport {\n  findAllBetween,\n  findAllCodeBlockNodes,\n  findAllHeadingNodes,\n  parseMarkdownAST\n} from './markdown-utils.js'\nimport { safeParseStructuredOutput } from './parse-structured-output.js'\n\n/**\n * The core zod schema which is used to parse the LLM's structured output.\n *\n * Note that the order of the keys is empirically important to help the LLM\n * \"think\" in the right order.\n *\n * Note that `codeSnippetSource`, `reasoning`, `violation`, and `confidence`\n * were all added empirically to increase the LLM's accuracy and to mitigate\n * common forms of false positives.\n */\nexport const ruleViolationSchema = z.object({\n  ruleName: z\n    .string()\n    .optional()\n    .describe('The name of the RULE which this `codeSnippet` violates.'),\n\n  codeSnippet: z\n    .string()\n    .describe(\n      'The offending code snippet which fails to conform to the given RULE. CODE SNIPPETS MUST BE SHORT and should include an ellipsis \"...\" if they would be more than 10 lines of code.'\n    ),\n\n  codeSnippetSource: z\n    .enum(['examples', 'source', 'unknown'])\n    .optional()\n    .describe(\n      'Where this rule violation\\'s `codeSnippet` comes from. If it comes from the RULE examples, then use \"examples\". If it comes from the SOURCE, then use \"source\".'\n    ),\n\n  reasoning: z\n    .string()\n    .optional()\n    .describe(\n      'An explanation of why this code snippet VIOLATES the RULE. Think step-by-step when describing your reasoning.'\n    ),\n\n  violation: z\n    .boolean()\n    .describe(\n      'Whether or not this `codeSnippet` violates the RULE. If the `codeSnippet` does VIOLATE the RULE, then `violation` should be `true`. If the `codeSnippet` conforms to the RULE correctly or does not appear in the SOURCE, then `violation` should be `false`.'\n    ),\n\n  confidence: z\n    .enum(['low', 'medium', 'high'])\n    .describe('Your confidence that the `codeSnippet` VIOLATES the RULE.')\n})\nexport type RuleViolation = z.infer<typeof ruleViolationSchema>\n\nexport const ruleViolationsOutputSchema = z.array(ruleViolationSchema)\nexport type RuleViolationsOutput = z.infer<typeof ruleViolationsOutputSchema>\n\nexport const ruleViolationsValidatedOutputSchema = z.object({\n  ruleViolations: ruleViolationsOutputSchema\n})\nexport type RuleViolationsValidatedOutput = z.infer<\n  typeof ruleViolationsValidatedOutputSchema\n>\n\nexport function parseRuleViolationsFromJSONModelResponse(\n  response: string\n): RuleViolation[] {\n  const ruleViolationsParseResult = safeParseStructuredOutput(\n    response,\n    ruleViolationsValidatedOutputSchema\n  )\n  if (!ruleViolationsParseResult.success) {\n    throw new RetryableError(\n      `Invalid output: the JSON output failed to parse according to the given RULE_VIOLATION schema. Parser error: ${ruleViolationsParseResult.error}`\n    )\n  }\n\n  return ruleViolationsParseResult.data.ruleViolations\n}\n\n/**\n * Attempts to parse an array of `RuleViolation` objects from a JSON code block\n * in the given markdown response.\n *\n * Will throw a `RetryableError` if the response is invalid with an error\n * message that the LLM can use to retry the request.\n */\nexport function parseRuleViolationsFromMarkdownModelResponse(\n  response: string,\n  {\n    numExpectedMarkdownHeadings = 2\n  }: {\n    numExpectedMarkdownHeadings?: number\n  } = {}\n): RuleViolation[] {\n  const ast = parseMarkdownAST(response)\n  const codeBlocksNodes = findAllCodeBlockNodes(ast)\n  let codeBlockNode: Code | undefined\n\n  if (codeBlocksNodes.length === 0) {\n    const h1Nodes = findAllHeadingNodes(ast, { depth: 1 })\n\n    if (h1Nodes.length >= numExpectedMarkdownHeadings) {\n      // The output is formatted properly, but there are no rule violations.\n      return []\n    }\n\n    throw new RetryableError(\n      'Invalid output: missing VIOLATIONS code block which should contain an array of RULE_VIOLATION objects.'\n    )\n  } else if (codeBlocksNodes.length > 1) {\n    const h1Nodes = findAllHeadingNodes(ast, { depth: 1 })\n\n    if (h1Nodes.length === 0) {\n      throw new RetryableError('Invalid output: missing VIOLATIONS header.')\n    } else {\n      const headers = h1Nodes.map((node) => toString(node).toLowerCase().trim())\n      const violationsHeaderIndex = headers.findLastIndex((header) =>\n        /violation/i.test(header)\n      )\n\n      if (violationsHeaderIndex < 0) {\n        throw new RetryableError(\n          'Invalid output: missing VIOLATIONS header section which should contain a json code block with an array of RULE_VIOLATION objects.'\n        )\n      }\n\n      const violationsNode = h1Nodes[violationsHeaderIndex]!\n      const violationsBodyNodes = findAllBetween(ast, violationsNode)\n      let violationsCodeBlocksNodes = findAllCodeBlockNodes({\n        type: 'root',\n        children: violationsBodyNodes as any\n      })\n\n      if (violationsCodeBlocksNodes.length > 1) {\n        const jsonViolationCodeBlockNodes = violationsCodeBlocksNodes.filter(\n          (node) => node.lang === 'json'\n        )\n\n        if (jsonViolationCodeBlockNodes.length === 0) {\n          const parseableCodeBlockNodes = violationsCodeBlocksNodes.filter(\n            (node) =>\n              safeParseStructuredOutput(node.value, ruleViolationsOutputSchema)\n                .success\n          )\n\n          if (parseableCodeBlockNodes.length === 0) {\n            // Ignore and fallback to retrying anyway below\n          } else if (parseableCodeBlockNodes.length >= 1) {\n            violationsCodeBlocksNodes = parseableCodeBlockNodes\n          }\n        } else if (jsonViolationCodeBlockNodes.length === 1) {\n          violationsCodeBlocksNodes = jsonViolationCodeBlockNodes\n        }\n      }\n\n      if (!violationsCodeBlocksNodes.length) {\n        throw new RetryableError(\n          'Invalid output: missing a valid json code block with an array of RULE_VIOLATION objects.'\n        )\n      } else if (violationsCodeBlocksNodes.length > 1) {\n        throw new RetryableError(\n          'Invalid output: the VIOLATIONS section should contain a single json code block with an array of RULE_VIOLATION objects.'\n        )\n      } else {\n        codeBlockNode = violationsCodeBlocksNodes[0]!\n      }\n    }\n  } else {\n    codeBlockNode = codeBlocksNodes[0]!\n  }\n\n  if (!codeBlockNode) {\n    throw new RetryableError(\n      'Invalid output: the VIOLATIONS section should contain a single json code block with an array of RULE_VIOLATION objects.'\n    )\n  }\n\n  const parsedRuleViolationsResult = safeParseStructuredOutput(\n    codeBlockNode!.value,\n    ruleViolationsOutputSchema\n  )\n\n  if (!parsedRuleViolationsResult.success) {\n    throw new RetryableError(\n      `Invalid output: the VIOLATIONS code block does not contain valid RULE_VIOLATION objects. Please make sure the RULE_VIOLATION objects are formatted correctly according to their schema. Parser error: ${parsedRuleViolationsResult.error}`\n    )\n  }\n\n  const ruleViolations = parsedRuleViolationsResult.data\n  return ruleViolations\n}\n\nexport function stringifyRuleViolationSchemaForModel(\n  rule: types.Rule,\n  file: types.SourceFile\n): string {\n  // TODO: Ideally, we would generate this from the zod schema to ensure a\n  // single source of truth, but this was easier for now and doesn't involve\n  // adding any larger dependencies.\n  return `\\`\\`\\`ts\ninterface RULE_VIOLATION {\n  // The name of the RULE which this \\`codeSnippet\\` violates.\n  ruleName: string\n\n  // The offending code snippet which fails to conform to the given RULE. CODE SNIPPETS MUST BE SHORT and should include an ellipsis \"...\" if they would be more than 10 lines of code.\n  codeSnippet: string\n\n  // Where this rule violation's \\`codeSnippet\\` comes from. If it comes from the RULE ${rule.name} examples, then use \"examples\". If it comes from the SOURCE code \"${file.fileRelativePath}\", then use \"source\".\n  codeSnippetSource: \"examples\" | \"source\"\n\n  // An explanation of why this code snippet VIOLATES the RULE. Think step-by-step when describing your reasoning.\n  reasoning: string\n\n  // Whether or not this \\`codeSnippet\\` violates the RULE. If this \\`codeSnippet\\` does VIOLATE the RULE, then \\`violation\\` should be \\`true\\`. If the \\`codeSnippet\\` conforms to the RULE correctly or does not appear in the SOURCE, then \\`violation\\` should be \\`false\\`.\n  violation: boolean\n\n  // Your confidence that the \\`codeSnippet\\` VIOLATES the RULE.\n  confidence: \"low\" | \"medium\" | \"high\"\n}\n\\`\\`\\``\n}\n\nexport function stringifyExampleRuleViolationsObjectOutputForModel(\n  rule: types.Rule\n): string {\n  return `\\`\\`\\`json\n{\n  \"ruleViolations\": [\n    {\n      \"ruleName\": \"${rule.name}\",\n      \"codeSnippet\": \"...\",\n      \"codeSnippetSource\": \"source\",\n      \"reasoning\": \"...\"\n      \"violation\": true,\n      \"confidence\": \"high\"\n    }\n  ]\n}\n\\`\\`\\``\n}\n\nexport function stringifyExampleRuleViolationsArrayOutputForModel(\n  rule: types.Rule\n): string {\n  return `\\`\\`\\`json\n[\n  {\n    \"ruleName\": \"${rule.name}\",\n    \"codeSnippet\": \"...\",\n    \"codeSnippetSource\": \"source\",\n    \"reasoning\": \"...\"\n    \"violation\": true,\n    \"confidence\": \"high\"\n  }\n]\n\\`\\`\\``\n}\n\nexport function stringifyRuleViolationForModel(\n  ruleViolations: Partial<RuleViolation>[]\n): string {\n  return `\\`\\`\\`json\n{\n  ruleViolations: ${JSON.stringify(ruleViolations, null, 2)}\n}\n\\`\\`\\``\n}\n\nexport function isRuleViolationLikelyFalsePositive({\n  ruleViolation,\n  rule,\n  file\n}: {\n  ruleViolation: RuleViolation\n  rule: Pick<types.Rule, 'name' | 'negativeExamples'>\n  file: Pick<\n    types.SourceFile,\n    'fileRelativePath' | 'content' | 'partialContent'\n  >\n}): boolean {\n  const { violation, confidence } = ruleViolation\n  if (!violation) {\n    return true\n  }\n\n  if (confidence !== 'high' && confidence !== 'medium') {\n    return true\n  }\n\n  const ruleName = ruleViolation.ruleName?.toLowerCase().trim()\n  if (ruleName && rule.name !== ruleName) {\n    return true\n  }\n\n  if (\n    isRuleViolationLikelyFalsePositiveFromExamples({\n      ruleViolation,\n      rule,\n      file\n    })\n  ) {\n    return true\n  }\n\n  return false\n}\n\nexport function isRuleViolationLikelyFalsePositiveFromExamples({\n  ruleViolation,\n  rule,\n  file\n}: {\n  ruleViolation: RuleViolation\n  rule: Pick<types.Rule, 'name' | 'negativeExamples'>\n  file: Pick<\n    types.SourceFile,\n    'fileRelativePath' | 'content' | 'partialContent'\n  >\n}): boolean {\n  if (ruleViolation.codeSnippetSource !== 'source') {\n    return true\n  }\n\n  if (!rule.negativeExamples) {\n    return false\n  }\n\n  const codeSnippetExample = rule.negativeExamples.find((example) =>\n    fuzzyStringEquality(example.code, ruleViolation.codeSnippet)\n  )\n\n  // If the code snippet also verbatim in the source examples, then it's likely\n  // a false positive\n  // TODO: need a better way to determine if the violation is from the RULE's negative examples or the SOURCE\n  if (!codeSnippetExample) {\n    return false\n  }\n\n  // console.log('false positive', { ruleViolation, codeSnippetExample })\n\n  // If the code snippet also appears in the file, then it's likely a true\n  // positive\n  const fileContent = file.partialContent || file.content\n  if (fuzzyStringEquality(fileContent, ruleViolation.codeSnippet)) {\n    return false\n  }\n\n  return true\n}\n\nfunction fuzzyStringEquality(a: string, b: string): boolean {\n  a = a.toLowerCase().trim()\n  b = b.toLowerCase().trim()\n\n  if (a.length > b.length) {\n    return a.includes(b)\n  } else if (a.length < b.length) {\n    return b.includes(a)\n  } else {\n    return a === b\n  }\n}\n","import path from 'node:path'\n\nimport type { Code, Heading, Node, Nodes, Parent, Root, Yaml } from 'mdast'\nimport { gfmToMarkdown } from 'mdast-util-gfm'\nimport { toMarkdown } from 'mdast-util-to-markdown'\nimport { toString } from 'mdast-util-to-string'\nimport remarkFrontmatter from 'remark-frontmatter'\nimport remarkGfm from 'remark-gfm'\nimport remarkParse from 'remark-parse'\nimport { unified } from 'unified'\nimport { is, type Test } from 'unist-util-is'\n\nimport type * as types from './types.js'\nimport { isValidRuleName } from './rule-utils.js'\nimport { assert, pruneUndefined, slugify } from './utils.js'\n\nexport function parseMarkdownAST(content: string) {\n  return unified()\n    .use(remarkParse)\n    .use(remarkFrontmatter)\n    .use(remarkGfm)\n    .parse(content)\n}\n\nexport { inspectColor as inspectNode } from 'unist-util-inspect'\n\nexport function convertASTToMarkdown(nodes: Nodes) {\n  return toMarkdown(nodes, {\n    bullet: '-',\n    rule: '-',\n    extensions: [gfmToMarkdown()]\n  })\n}\n\nexport function convertASTToPlaintext(node?: Node) {\n  return toString(node)\n}\n\nexport function parseRuleNode({\n  headingRuleNode,\n  bodyRuleNodes,\n  filePath,\n  partialRule\n}: {\n  headingRuleNode: Node\n  bodyRuleNodes: Node[]\n  filePath: string\n  partialRule?: Partial<types.RuleDefinition>\n}): types.Rule {\n  const firstNonBodyRuleNodeIndex = bodyRuleNodes.findIndex(\n    (node) => node.type === 'heading' && (node as Heading).depth >= 3\n  )\n\n  let exampleRuleNodes: Node[] = []\n\n  if (firstNonBodyRuleNodeIndex >= 0) {\n    exampleRuleNodes = bodyRuleNodes.slice(firstNonBodyRuleNodeIndex)\n    bodyRuleNodes = bodyRuleNodes.slice(0, firstNonBodyRuleNodeIndex)\n  }\n\n  const bodyRuleNode: Root = {\n    type: 'root',\n    children: bodyRuleNodes as any\n  }\n\n  const title = convertASTToPlaintext(headingRuleNode)\n  assert(title, 'Rule title must not be empty')\n\n  const fileNameRuleName = path.basename(filePath).replace(/\\.\\w+$/, '')\n  const defaultRuleName = isValidRuleName(fileNameRuleName)\n    ? fileNameRuleName\n    : slugify(title).trim()\n\n  const description = convertASTToMarkdown(bodyRuleNode)\n\n  const rule: types.Rule = pruneUndefined({\n    name: defaultRuleName,\n    title,\n    description,\n    positiveExamples: [],\n    negativeExamples: [],\n    cacheable: true,\n    level: 'error',\n    scope: 'file',\n    source: filePath,\n    metadata: {},\n    ...partialRule\n  })\n  assert(rule.name, `Rule name must not be empty: ${title}`)\n\n  assert(\n    isValidRuleName(rule.name),\n    `Rule name is invalid \"${rule.name}\": ${title}`\n  )\n\n  const exampleRuleNode: Root = {\n    type: 'root',\n    children: exampleRuleNodes as any\n  }\n\n  const h3Nodes = exampleRuleNodes.filter(\n    (node) => node.type === 'heading' && (node as Heading).depth >= 3\n  ) as Heading[]\n\n  assert(\n    h3Nodes.length <= 2,\n    `Rule must not contain more than 2 H3 markdown nodes: ${rule.name} (${filePath})`\n  )\n\n  let numPositiveSections = 0\n  let numNegativeSections = 0\n\n  for (let i = 0; i < h3Nodes.length; ++i) {\n    const h3Node = h3Nodes[i]!\n    const sectionNodes = findAllBetween(exampleRuleNode, h3Node, h3Nodes[i + 1])\n\n    const sectionLabel = convertASTToPlaintext(h3Node).toLowerCase().trim()\n    const isPositive =\n      /\\bgood\\b/i.test(sectionLabel) ||\n      /\\bcorrect\\b/.test(sectionLabel) ||\n      /\\bpass\\b/.test(sectionLabel)\n    const isNegative =\n      /\\bbad\\b/i.test(sectionLabel) ||\n      /\\bincorrect\\b/.test(sectionLabel) ||\n      /\\bfail\\b/.test(sectionLabel)\n\n    assert(\n      isPositive || isNegative,\n      `Rule h3 header for examples section \"${sectionLabel}\" must include a known positive label (good, correct, or pass) or negative label (bad, incorrect, or fail): ${rule.name} (${filePath})`\n    )\n\n    const codeBlockNodes = sectionNodes.filter(\n      (node) => node.type === 'code'\n    ) as Code[]\n\n    if (isPositive) {\n      numPositiveSections++\n    } else if (isNegative) {\n      numNegativeSections++\n    }\n\n    // console.log(\n    //   'sectionNode',\n    //   {\n    //     sectionLabel,\n    //     isPositive,\n    //     isNegative,\n    //     numCodeBlockNodes: codeBlockNodes.length\n    //   },\n    //   inspectColor(\n    //     { type: 'root', children: sectionNodes },\n    //     { showPositions: false }\n    //   )\n    // )\n\n    for (const codeBlockNode of codeBlockNodes) {\n      const code = convertASTToPlaintext(codeBlockNode)\n      const language = codeBlockNode.lang || undefined\n\n      if (isPositive) {\n        rule.positiveExamples!.push({ code, language })\n      } else if (isNegative) {\n        rule.negativeExamples!.push({ code, language })\n      }\n    }\n  }\n\n  assert(\n    numPositiveSections <= 1,\n    `Rule must not contain more than 1 positive examples section: ${rule.name} (${filePath})`\n  )\n\n  assert(\n    numNegativeSections <= 1,\n    `Rule must not contain more than 1 negative examples section: ${rule.name} (${filePath})`\n  )\n\n  // console.log(\n  //   'bodyRuleNode',\n  //   inspectColor(bodyRuleNode, { showPositions: false })\n  // )\n  // console.log(\n  //   'exampleRuleNode',\n  //   inspectColor(exampleRuleNode, { showPositions: false })\n  // )\n  // console.log()\n\n  return rule\n}\n\n/**\n * A unist utility to get all children of a parent between two nodes or indices.\n *\n * This differs from the official `unist-util-find-all-between` to behave more like\n * `Array.slice` so if we don't specify the `end` parameter, it will default to\n * returning all nodes up until the end of the parent's children.\n *\n * @param parent Parent node to search in\n * @param start A node or index to start from (exclusive)\n * @param end An optional node or index to end with (exclusive)\n * @param test An optional test passed to `unist-util-is` that nodes must pass to be included in the results\n */\nexport function findAllBetween(\n  parent: Parent,\n  start: Node | number,\n  end?: Node | number,\n  test?: Test\n): Node[] {\n  if (!parent || !parent.type || !parent.children) {\n    throw new Error('Expected parent node')\n  }\n\n  const { children } = parent\n  const results: Node[] = []\n  const startIndex = check(start)\n  const endIndex = check(end)\n  let child: Node\n  let index = startIndex\n\n  while (++index < endIndex) {\n    child = children[index] as Node\n\n    if (is(child, test, index, parent)) {\n      results.push(child)\n    }\n  }\n\n  // console.log('findAllBetween', { startIndex, endIndex, results })\n  return results\n\n  function check(indexOrNode: Node | number | undefined) {\n    let index = 0\n\n    if (indexOrNode === undefined) {\n      return children.length\n    } else if (typeof indexOrNode === 'number') {\n      index = indexOrNode\n\n      if (index < 0) {\n        index = children.length\n      }\n    } else if ((indexOrNode as any).type) {\n      index = parent.children.indexOf(indexOrNode as any)\n    }\n\n    if (\n      Number.isNaN(index) ||\n      index < 0 ||\n      index === Number.POSITIVE_INFINITY\n    ) {\n      throw new Error('Expected positive finite index or child node')\n    }\n\n    if (index > children.length) {\n      index = children.length\n    }\n\n    return index\n  }\n}\n\nexport function findAllCodeBlockNodes(tree: Root) {\n  return tree.children.filter((node) => node.type === 'code') as Code[]\n}\n\nexport function findAllHeadingNodes(\n  tree: Root,\n  { depth }: { depth?: number } = {}\n) {\n  return tree.children.filter(\n    (node) =>\n      node.type === 'heading' && (depth === undefined || node.depth === depth)\n  ) as Heading[]\n}\n\nexport function findAllYAMLNodes(tree: Root) {\n  return tree.children.filter((node) => node.type === 'yaml') as Yaml[]\n}\n","import type { JsonValue } from 'type-fest'\nimport { jsonrepair, JSONRepairError } from 'jsonrepair'\nimport { z, type ZodType } from 'zod'\n\nimport { ParseError } from './errors.js'\n\nexport type SafeParseResult<T> =\n  | {\n      success: true\n      data: T\n      error?: never\n    }\n  | {\n      success: false\n      data?: never\n      error: string\n    }\n\n/**\n * Parses a string which is expected to contain a structured JSON value.\n *\n * The JSON value is fuzzily parsed in order to support common issues like\n * missing commas, trailing commas, and unquoted keys.\n *\n * The JSON value is then parsed against a `zod` schema to enforce the shape of\n * the output.\n *\n * @param output - string to parse\n * @param outputSchema - zod schema\n *\n * @returns parsed output\n */\nexport function parseStructuredOutput<T>(\n  output: string,\n  outputSchema: ZodType<T>\n): T {\n  let result\n  if (outputSchema instanceof z.ZodArray) {\n    result = parseArrayOutput(output)\n  } else if (outputSchema instanceof z.ZodObject) {\n    result = parseObjectOutput(output)\n  } else if (outputSchema instanceof z.ZodBoolean) {\n    result = parseBooleanOutput(output)\n  } else if (outputSchema instanceof z.ZodNumber) {\n    result = parseNumberOutput(output, outputSchema)\n  } else {\n    // Default to string output...\n    result = output\n  }\n\n  // TODO: fix typescript issue here with recursive types\n  const safeResult = (outputSchema.safeParse as any)(result)\n\n  if (!safeResult.success) {\n    throw new ParseError(safeResult.error)\n  }\n\n  return safeResult.data\n}\n\nexport function safeParseStructuredOutput<T>(\n  output: string,\n  outputSchema: ZodType<T>\n): SafeParseResult<T> {\n  try {\n    const data = parseStructuredOutput<T>(output, outputSchema)\n    return {\n      success: true,\n      data\n    }\n  } catch (err: any) {\n    return {\n      success: false,\n      error: err.message\n    }\n  }\n}\n\n/**\n * Checks if character at the specified index in a string is escaped.\n *\n * @param str - string to check\n * @param i - index of the character to check\n * @returns whether the character is escaped\n */\nfunction isEscaped(str: string, i: number): boolean {\n  return i > 0 && str[i - 1] === '\\\\' && !(i > 1 && str[i - 2] === '\\\\')\n}\n\n/**\n * Extracts JSON objects or arrays from a string.\n *\n * @param input - string to extract JSON from\n * @param jsonStructureType - type of JSON structure to extract\n * @returns array of extracted JSON objects or arrays\n */\nexport function extractJSONFromString(\n  input: string,\n  jsonStructureType: 'object' | 'array'\n) {\n  const startChar = jsonStructureType === 'object' ? '{' : '['\n  const endChar = jsonStructureType === 'object' ? '}' : ']'\n  const extractedJSONValues: JsonValue[] = []\n  let nestingLevel = 0\n  let startIndex = 0\n  const isInsideQuoted = { '\"': false, \"'\": false }\n\n  for (let i = 0; i < input.length; i++) {\n    const ch = input.charAt(i)\n    switch (ch) {\n      case '\"':\n      case \"'\":\n        if (!isInsideQuoted[ch === '\"' ? \"'\" : '\"'] && !isEscaped(input, i)) {\n          isInsideQuoted[ch] = !isInsideQuoted[ch]\n        }\n\n        break\n\n      default:\n        if (!isInsideQuoted['\"'] && !isInsideQuoted[\"'\"]) {\n          switch (ch) {\n            case startChar:\n              if (nestingLevel === 0) {\n                startIndex = i\n              }\n\n              nestingLevel += 1\n\n              break\n\n            case endChar:\n              nestingLevel -= 1\n              if (nestingLevel === 0) {\n                const candidate = input.slice(startIndex, i + 1)\n                const parsed = JSON.parse(jsonrepair(candidate))\n                if (parsed && typeof parsed === 'object') {\n                  extractedJSONValues.push(parsed as JsonValue)\n                }\n              } else if (nestingLevel < 0) {\n                throw new ParseError(\n                  `Invalid JSON string: unexpected ${endChar} at position ${i}`\n                )\n              }\n          }\n        }\n    }\n  }\n\n  if (nestingLevel !== 0) {\n    throw new ParseError(\n      'Invalid JSON string: unmatched ' + startChar + ' or ' + endChar\n    )\n  }\n\n  return extractedJSONValues\n}\n\nconst BOOLEAN_OUTPUTS: Record<string, boolean> = {\n  true: true,\n  false: false,\n  t: true,\n  f: false,\n  yes: true,\n  no: false,\n  y: true,\n  n: false,\n  '1': true,\n  '0': false\n}\n\n/**\n * Parses an array output from a string.\n *\n * @param output - string to parse\n * @returns parsed array\n */\nexport function parseArrayOutput(output: string): Array<any> {\n  try {\n    const arrayOutput = extractJSONFromString(output, 'array')\n    if (arrayOutput.length === 0) {\n      throw new ParseError(`Invalid JSON array: ${output}`)\n    }\n\n    const parsedOutput = arrayOutput[0]\n    if (!Array.isArray(parsedOutput)) {\n      throw new ParseError(\n        `Invalid JSON array: ${JSON.stringify(parsedOutput)}`\n      )\n    }\n\n    return parsedOutput\n  } catch (err: any) {\n    if (err instanceof JSONRepairError) {\n      throw new ParseError(err.message, { cause: err })\n    } else if (err instanceof SyntaxError) {\n      throw new ParseError(`Invalid JSON array: ${err.message}`, { cause: err })\n    } else {\n      throw err\n    }\n  }\n}\n\n/**\n * Parses an object output from a string.\n *\n * @param output - string to parse\n * @returns parsed object\n */\nexport function parseObjectOutput(output: string) {\n  try {\n    const arrayOutput = extractJSONFromString(output, 'object')\n    if (arrayOutput.length === 0) {\n      throw new ParseError(`Invalid JSON object: ${output}`)\n    }\n\n    let parsedOutput = arrayOutput[0]\n    if (Array.isArray(parsedOutput)) {\n      // TODO\n      parsedOutput = parsedOutput[0]\n    } else if (typeof parsedOutput !== 'object') {\n      throw new ParseError(\n        `Invalid JSON object: ${JSON.stringify(parsedOutput)}`\n      )\n    }\n\n    return parsedOutput\n  } catch (err: any) {\n    if (err instanceof JSONRepairError) {\n      throw new ParseError(err.message, { cause: err })\n    } else if (err instanceof SyntaxError) {\n      throw new ParseError(`Invalid JSON object: ${err.message}`, {\n        cause: err\n      })\n    } else {\n      throw err\n    }\n  }\n}\n\n/**\n * Parses a boolean output from a string.\n *\n * @param output - string to parse\n * @returns parsed boolean\n */\nexport function parseBooleanOutput(output: string): boolean {\n  output = output\n    .toLowerCase()\n    .trim()\n    .replace(/[!.?]+$/, '')\n\n  const booleanOutput = BOOLEAN_OUTPUTS[output]\n\n  if (booleanOutput === undefined) {\n    throw new ParseError(`Invalid boolean output: ${output}`)\n  } else {\n    return booleanOutput\n  }\n}\n\n/**\n * Parses a number output from a string.\n *\n * @param output - string to parse\n * @param outputSchema - zod number schema\n * @returns parsed number\n */\nexport function parseNumberOutput(\n  output: string,\n  outputSchema: z.ZodNumber\n): number {\n  output = output.trim()\n\n  const numberOutput = outputSchema.isInt\n    ? Number.parseInt(output)\n    : Number.parseFloat(output)\n\n  if (Number.isNaN(numberOutput)) {\n    throw new ParseError(`Invalid number output: ${output}`)\n  }\n\n  return numberOutput\n}\n","import type { ChatModel } from '@dexaai/dexter'\nimport pMap from 'p-map'\nimport plur from 'plur'\nimport task from 'tasuku'\n\nimport type { LinterCache } from './cache.js'\nimport type * as types from './types.js'\nimport { preProcessFileWithGrit } from './gritql.js'\nimport { lintFile } from './lint-file.js'\nimport {\n  createLintResult,\n  mergeLintResults,\n  resolvePartialLintResult\n} from './lint-result.js'\nimport { createLintTask, stringifyLintTask } from './lint-task.js'\nimport { preProcessTask } from './pre-process-task.js'\nimport {\n  assert,\n  createPromiseWithResolvers,\n  pruneUndefined,\n  trimMessage\n} from './utils.js'\n\n// TODO: refactor `file` scope vs `project` scope to be less verbose\n\n/**\n * Takes in a list of source files and rules, transforms these into a set\n * of LintTasks, pre-processes each lint task (e.g. caching, validation),\n * processes the non-cached tasks with the LLM-based linting engine, post-\n * processes the results, and then returns an aggregated LintResult.\n */\nexport async function lintFiles({\n  files,\n  rules,\n  config,\n  cache,\n  chatModel,\n  cwd = process.cwd(),\n  retryOptions = {\n    retries: 2\n  },\n  onProgress,\n  onProgressInit\n}: {\n  files: types.SourceFile[]\n  rules: types.Rule[]\n  config: types.ResolvedLinterConfig\n  cache: LinterCache\n  chatModel: ChatModel\n  cwd?: string\n  retryOptions?: types.RetryOptions\n  onProgress?: types.ProgressHandlerFn\n  onProgressInit?: types.ProgressHandlerInitFn\n}): Promise<types.LintResult> {\n  await pMap(rules, async (rule) =>\n    // TODO: add error handling to this so one rule doesn't prevent others from\n    // running properly\n    rule.init?.({\n      rule,\n      cache,\n      config,\n      chatModel,\n      cwd,\n      retryOptions\n    })\n  )\n\n  const fileScopeRules = rules.filter((rule) => rule.scope === 'file')\n\n  const projectLintTasks: types.LintTask[] = rules\n    .map((rule) => {\n      if (rule.scope === 'project' || rule.scope === 'repo') {\n        return createLintTask({ rule, config })\n      } else {\n        return undefined\n      }\n    })\n    .filter(Boolean)\n\n  const fileLintTasks: types.LintTask[] = fileScopeRules.flatMap((rule) =>\n    files.map((file) => createLintTask({ file, rule, config })).filter(Boolean)\n  )\n\n  const initialLintTasks = projectLintTasks.concat(fileLintTasks)\n\n  let lintResult = createLintResult()\n  let earlyExitTripped = false\n  const warnings: Error[] = []\n\n  const ruleNameToPartialSourceFileMap = new Map<\n    string,\n    Promise<Map<string, types.PartialSourceFile>>\n  >()\n\n  // Preprocess the file / rule tasks so we have a clear indication of how many\n  // non-cached, non-disabled tasks need to be processed.\n  const preProcessTaskRunner = await task(\n    `Preprocessing ${files.length} files and ${rules.length} rules`,\n    async () =>\n      pMap<types.LintTask, types.LintTask | undefined>(\n        initialLintTasks,\n        async (lintTask) => {\n          if (earlyExitTripped) {\n            return\n          }\n\n          try {\n            const { rule, scope } = lintTask\n            const model =\n              rule.model ??\n              config.llmOptions.weakModel ??\n              config.llmOptions.model\n\n            if (rule.preProcessProject) {\n              const partialProjectLintResult = await Promise.resolve(\n                rule.preProcessProject({\n                  ...lintTask,\n                  chatModel,\n                  cache,\n                  retryOptions,\n                  cwd\n                })\n              )\n\n              if (partialProjectLintResult) {\n                const { lintErrors, skipped } = partialProjectLintResult\n\n                lintTask.lintResult = resolvePartialLintResult(\n                  lintErrors || skipped\n                    ? {\n                        ...partialProjectLintResult,\n                        skipped: true,\n                        skipReason: 'pre-process-project'\n                      }\n                    : partialProjectLintResult,\n                  {\n                    model,\n                    rule,\n                    filePath: cwd\n                  }\n                )\n              }\n            }\n\n            if (lintTask.lintResult) {\n              return lintTask\n            }\n\n            // Always run the built-in pre-processing logic for caching and validation\n            // purposes. Then run any custom, rule-specific pre-processing logic if\n            // it exists.\n            lintTask = await preProcessTask(lintTask, { cache })\n\n            if (lintTask.lintResult) {\n              return lintTask\n            }\n\n            if (scope === 'file') {\n              const file = lintTask.file\n              assert(file)\n\n              if (rule.gritql) {\n                const maybeFileLintResult = await preProcessFileWithGrit({\n                  file,\n                  files,\n                  rule,\n                  config,\n                  ruleNameToPartialSourceFileMap\n                })\n\n                if (maybeFileLintResult) {\n                  lintTask.lintResult = maybeFileLintResult\n                  return lintTask\n                }\n              }\n\n              if (rule.preProcessFile) {\n                const partialFileLintResult = await Promise.resolve(\n                  rule.preProcessFile({\n                    ...lintTask,\n                    file,\n                    chatModel,\n                    cache,\n                    retryOptions,\n                    cwd\n                  })\n                )\n\n                if (partialFileLintResult) {\n                  const { lintErrors, skipped } = partialFileLintResult\n\n                  lintTask.lintResult = resolvePartialLintResult(\n                    lintErrors || skipped\n                      ? {\n                          ...partialFileLintResult,\n                          skipped: true,\n                          skipReason: 'pre-process-file'\n                        }\n                      : partialFileLintResult,\n                    {\n                      model,\n                      rule,\n                      file\n                    }\n                  )\n                }\n              }\n            }\n\n            return lintTask\n          } catch (err: any) {\n            const error = new Error(\n              `${stringifyLintTask(lintTask)} unexpected preProcess error: ${err.message}`,\n              { cause: err }\n            )\n            console.warn(error)\n            warnings.push(error)\n          } finally {\n            if (lintTask.lintResult) {\n              lintResult = mergeLintResults(lintResult, lintTask.lintResult)\n            }\n\n            if (\n              config.linterOptions.earlyExit &&\n              lintResult.lintErrors.length > 0\n            ) {\n              earlyExitTripped = true\n            }\n          }\n        },\n        {\n          concurrency: config.linterOptions.concurrency\n        }\n      )\n  )\n\n  const preProcessedLintTasks: types.LintTask[] =\n    preProcessTaskRunner.result.filter(Boolean)\n  const outstandingLintTasks = preProcessedLintTasks.filter(\n    (r) => !r.lintResult?.skipped && !r.lintResult?.lintErrors\n  )\n  const skippedLintTasks = preProcessedLintTasks.filter(\n    (r) => r.lintResult?.skipped || r.lintResult?.lintErrors\n  ) as types.ResolvedLintTask[]\n  const numTasksCached = skippedLintTasks.filter(\n    (r) => r.lintResult.skipReason === 'cached'\n  ).length\n  const numTasksEmpty = skippedLintTasks.filter(\n    (r) => r.lintResult.skipReason === 'empty'\n  ).length\n  const numTasksFilteredPrecheck = skippedLintTasks.filter(\n    (r) =>\n      r.lintResult.skipReason === 'pre-process-file' ||\n      r.lintResult.skipReason === 'pre-process-project'\n  ).length\n  const numTasksFilteredGrit = skippedLintTasks.filter(\n    (r) => r.lintResult.skipReason === 'grit-pattern'\n  ).length\n  const numTasksDisabled = skippedLintTasks.filter(\n    (r) =>\n      r.lintResult.skipReason === 'inline-linter-disabled' ||\n      r.lintResult.skipReason === 'rule-disabled'\n  ).length\n\n  console.log(\n    'Linter tasks',\n    pruneUndefined({\n      numFiles: files.length,\n      numRules: rules.length,\n      numTasks: outstandingLintTasks.length,\n      numTasksCached: numTasksCached || undefined,\n      numTasksFilteredPrecheck: numTasksFilteredPrecheck || undefined,\n      numTasksFilteredGrit: numTasksFilteredGrit || undefined,\n      numTasksEmpty: numTasksEmpty || undefined,\n      numTasksDisabled: numTasksDisabled || undefined\n    })\n  )\n\n  if (config.linterOptions.debug) {\n    console.log(\n      outstandingLintTasks.map((task) =>\n        pruneUndefined({\n          file: task.file?.fileRelativePath,\n          rule: task.rule.name\n        })\n      )\n    )\n  }\n\n  if (config.linterOptions.earlyExit && lintResult.lintErrors.length > 0) {\n    earlyExitTripped = true\n  }\n\n  if (onProgressInit) {\n    await Promise.resolve(\n      onProgressInit({ numTasks: outstandingLintTasks.length })\n    )\n  }\n\n  const lintTaskGroups: Record<string, types.LintTaskGroup> = {}\n\n  for (const lintTask of outstandingLintTasks) {\n    const { group } = lintTask\n\n    if (!lintTaskGroups[group]) {\n      const lintTaskGroupName = config.linterOptions.dryRun\n        ? `Dry run ${group}`\n        : `Linting ${group}`\n\n      const lintTaskP = createPromiseWithResolvers()\n\n      lintTaskGroups[group] = {\n        ...lintTaskP,\n\n        lintTasks: [],\n        lintResults: [],\n\n        taskP: undefined,\n        innerTask: undefined,\n\n        async init() {\n          if (!this.taskP) {\n            await new Promise<void>((resolve) => {\n              this.taskP = task(lintTaskGroupName, async (innerTask) => {\n                this.innerTask = innerTask\n                resolve()\n                return lintTaskP\n              })\n            })\n          }\n        }\n      }\n    }\n\n    const lintTaskGroup = lintTaskGroups[group]!\n    lintTaskGroup.lintTasks.push(lintTask)\n  }\n\n  let sortedLintTasks: types.LintTask[] = []\n  for (const lintTaskGroup of Object.values(lintTaskGroups)) {\n    sortedLintTasks = sortedLintTasks.concat(lintTaskGroup.lintTasks)\n\n    lintTaskGroup.promise = Promise.all(\n      lintTaskGroup.lintTasks.map((t) => t.promise)\n    )\n\n    lintTaskGroup.promise.then((value) => {\n      lintTaskGroup.resolve(value)\n      const hasLintErrors = lintTaskGroup.lintResults.some(\n        (result) => result.lintErrors.length > 0\n      )\n\n      if (!hasLintErrors) {\n        lintTaskGroup.taskP!.then((task) => {\n          task.clear()\n        })\n      }\n    }, lintTaskGroup.reject)\n  }\n\n  // Loop over each non-cached file / rule task and lint them with the LLM\n  // linting engine.\n  await pMap(\n    sortedLintTasks,\n    async (lintTask, index) => {\n      if (earlyExitTripped) {\n        return\n      }\n\n      const {\n        group,\n        scope,\n        file,\n        rule,\n        cacheKey,\n        config,\n        lintResult: preProcessedTaskLintResult\n      } = lintTask\n\n      const lintTaskGroup = lintTaskGroups[group]!\n      assert(lintTaskGroup)\n      await lintTaskGroup.init()\n      const lintTaskGroupInnerTask = lintTaskGroup.innerTask!\n\n      let taskLintResult: types.LintResult | undefined\n      let taskLintError: Error | undefined\n\n      const nestedTask = await lintTaskGroupInnerTask.task(\n        rule.name,\n        async (task) => {\n          try {\n            const processProjectFnParams: types.RuleProcessProjectFnParams = {\n              rule,\n              lintResult: preProcessedTaskLintResult,\n              chatModel,\n              cache,\n              config,\n              cwd,\n              retryOptions: {\n                ...retryOptions,\n                onFailedAttempt: (err) => {\n                  task.setOutput(`Retrying: ${err.message}`)\n                  return retryOptions.onFailedAttempt?.(err)\n                }\n              }\n            }\n\n            if (scope === 'file') {\n              // Allow rules to override the default linting process with their\n              // own, custom linting logic.\n              const processFileFn: types.RuleProcessFileFn =\n                rule.processFile ?? lintFile\n\n              const processFileFnParams: types.RuleProcessFileFnParams = {\n                ...processProjectFnParams,\n                file\n              }\n\n              const partialTaskLintResult =\n                await processFileFn(processFileFnParams)\n\n              taskLintResult = resolvePartialLintResult(partialTaskLintResult, {\n                rule,\n                file\n              })\n\n              if (rule.postProcessFile) {\n                const partialPostTaskLintResult = await Promise.resolve(\n                  rule.postProcessFile({\n                    ...processFileFnParams,\n                    lintResult: taskLintResult\n                  })\n                )\n\n                if (partialPostTaskLintResult) {\n                  taskLintResult = resolvePartialLintResult(\n                    partialPostTaskLintResult,\n                    {\n                      rule,\n                      file\n                    }\n                  )\n                }\n              }\n            } else {\n              if (rule.processProject) {\n                const partialTaskLintResult = await rule.processProject(\n                  processProjectFnParams\n                )\n\n                taskLintResult = resolvePartialLintResult(\n                  partialTaskLintResult,\n                  {\n                    rule,\n                    file\n                  }\n                )\n              }\n\n              if (rule.postProcessProject) {\n                const partialPostTaskLintResult = await Promise.resolve(\n                  rule.postProcessProject({\n                    ...processProjectFnParams,\n                    lintResult: taskLintResult\n                  })\n                )\n\n                if (partialPostTaskLintResult) {\n                  taskLintResult = resolvePartialLintResult(\n                    partialPostTaskLintResult,\n                    {\n                      rule,\n                      file\n                    }\n                  )\n                }\n              }\n            }\n\n            if (!taskLintResult) {\n              return\n            }\n\n            if (cacheKey) {\n              await cache.set(cacheKey, taskLintResult)\n            }\n\n            lintResult = mergeLintResults(lintResult, taskLintResult)\n            const { lintErrors } = taskLintResult\n\n            if (config.linterOptions.earlyExit && lintErrors.length > 0) {\n              earlyExitTripped = true\n            }\n\n            if (onProgress) {\n              await Promise.resolve(\n                onProgress({\n                  progress: index / sortedLintTasks.length,\n                  message: stringifyLintTask(lintTask),\n                  result: lintResult\n                })\n              )\n            }\n\n            if (lintErrors.length > 0) {\n              const lintErrorPrefixDesc = `found ${lintErrors.length} lint ${plur(\n                'error',\n                lintErrors.length\n              )}`\n              const lintErrorShortDesc =\n                lintErrors.length === 1\n                  ? `\\`${trimMessage(\n                      lintErrors[0]?.codeSnippet ?? lintErrors[0]?.message,\n                      { maxLength: 60 }\n                    )}\\``\n                  : ''\n              const lintErrorDesc = [lintErrorPrefixDesc, lintErrorShortDesc]\n                .filter(Boolean)\n                .join(' ')\n\n              task.setError(lintErrorDesc)\n            }\n          } catch (err: any) {\n            const error = new Error(\n              `${stringifyLintTask(lintTask)} unexpected error: ${err.message}`,\n              { cause: err }\n            )\n            console.warn(error)\n            taskLintError = error\n            warnings.push(error)\n            task.setError(err.message)\n          }\n        }\n      )\n\n      if (taskLintResult) {\n        if (!taskLintResult!.lintErrors.length) {\n          nestedTask.clear()\n        }\n\n        lintTaskGroup.lintResults.push(taskLintResult!)\n      } else if (!taskLintError) {\n        nestedTask.clear()\n      }\n\n      lintTask.resolve(undefined)\n    },\n    {\n      concurrency: config.linterOptions.concurrency\n    }\n  )\n\n  lintResult.endedAtMs = Date.now()\n  return lintResult\n}\n","import type * as types from './types.js'\nimport { createCacheKey } from './cache.js'\nimport {\n  assert,\n  createPromiseWithResolvers,\n  fileMatchesIncludeExclude\n} from './utils.js'\n\nexport function createLintTask({\n  rule,\n  file,\n  config\n}: {\n  rule: types.Rule\n  file?: types.SourceFile\n  config: types.ResolvedLinterConfig\n}): types.LintTask | null {\n  const { scope } = rule\n\n  if (scope === 'file') {\n    assert(file)\n\n    if (!fileMatchesIncludeExclude(file, rule)) {\n      return null\n    }\n\n    const fileRuleSettings = config.getRuleSettingsForFile(file)\n\n    if (fileRuleSettings[rule.name] === 'off') {\n      return null\n    }\n  }\n\n  const lintTaskP = createPromiseWithResolvers()\n  const lintTask = {\n    ...lintTaskP,\n    scope,\n    group: scope === 'file' ? file!.fileRelativePath : scope,\n    rule,\n    file,\n    config,\n    cacheKey: createCacheKey({ file, rule, config })\n  } as types.LintTask\n\n  return lintTask\n}\n\nexport function stringifyLintTask(lintTask: types.LintTask): string {\n  return [\n    `rule \"${lintTask.rule.name}\"`,\n    lintTask.file ? `file \"${lintTask.file.fileRelativePath}\"` : undefined\n  ]\n    .filter(Boolean)\n    .join(' ')\n}\n","import type * as types from './types.js'\nimport { isValidRuleName, isValidRuleSetting } from './rule-utils.js'\nimport { assert } from './utils.js'\n\n/**\n * Parse inline config directives.\n *\n * TODO: support non-C-style-block-comments (e.g., for python)\n */\nexport function parseInlineConfig({\n  file\n}: {\n  file: Pick<types.SourceFile, 'content' | 'fileRelativePath'>\n}): types.LinterConfig | undefined {\n  const rules: types.LinterConfig['rules'] = {}\n\n  const inlineDisableRe = /^\\s*\\/\\*+\\s*gptlint-disable\\s*\\*+\\//gim\n  const inlineEnableRe = /^\\s*\\/\\*+\\s*gptlint-enable\\s*\\*+\\//gim\n  let lastDisableIndex = -1\n  let lastEnableIndex = -1\n\n  for (const match of file.content.matchAll(inlineDisableRe)) {\n    lastDisableIndex = Math.max(lastDisableIndex, match.index)\n  }\n\n  for (const match of file.content.matchAll(inlineEnableRe)) {\n    lastEnableIndex = Math.max(lastEnableIndex, match.index)\n  }\n\n  if (lastDisableIndex >= 0 && lastDisableIndex > lastEnableIndex) {\n    // Linting has been disabled for this file\n    return {\n      linterOptions: {\n        disabled: true\n      }\n    }\n  }\n\n  const inlineConfigRe = /^\\s*\\/\\*+\\s*gptlint\\s+([^*]+)\\s*\\*+\\//gim\n  for (const match of file.content.matchAll(inlineConfigRe)) {\n    const inlineConfig = match[1]?.trim()\n    if (!inlineConfig) continue\n\n    const inlineConfigParts = inlineConfig.split(',').map((c) => c.trim())\n    for (const inlineConfigPart of inlineConfigParts) {\n      const inlineConfigRuleSettingParts = inlineConfigPart\n        .split(':')\n        .map((c) => c.trim().toLowerCase())\n\n      assert(\n        inlineConfigRuleSettingParts.length === 2,\n        `Invalid inline config setting \"${inlineConfig}\" (${file.fileRelativePath})`\n      )\n\n      const [ruleName, ruleSetting] = inlineConfigRuleSettingParts\n\n      assert(\n        isValidRuleName(ruleName!),\n        `Invalid inline config setting \"${inlineConfig}\"; invalid rule name \"${ruleName}\" (${file.fileRelativePath})`\n      )\n\n      assert(\n        isValidRuleSetting(ruleSetting!),\n        `Invalid inline config setting \"${inlineConfig}\"; invalid rule setting \"${ruleSetting}\" (${file.fileRelativePath})`\n      )\n\n      rules[ruleName] = ruleSetting\n    }\n  }\n\n  if (Object.keys(rules).length > 0) {\n    return { rules }\n  }\n}\n","import type { LinterCache } from './cache.js'\nimport type * as types from './types.js'\nimport { mergeLinterConfigs } from './config.js'\nimport { createLintResult } from './lint-result.js'\nimport { parseInlineConfig } from './parse-inline-config.js'\nimport { assert } from './utils.js'\n\n/**\n * If the result contains a `lintResult`, then that is the cached result which\n * should be used.\n *\n * If the result does not contain a `lintResult`, then the file / rule is not\n * cached and needs to be processed.\n */\nexport async function preProcessTask(\n  lintTask: types.LintTask,\n  { cache }: { cache: LinterCache }\n): Promise<types.LintTask> {\n  const lintResult = createLintResult()\n  const { scope, rule, file, config } = lintTask\n\n  if (scope === 'file') {\n    assert(file)\n    const content = file.partialContent || file.content\n\n    if (!content.trim()) {\n      // Ignore empty files\n      return {\n        ...lintTask,\n        lintResult: { ...lintResult, skipped: true, skipReason: 'empty' }\n      }\n    }\n\n    if (rule.cacheable || rule.cacheable === undefined) {\n      const cachedResult = await cache.get(lintTask.cacheKey)\n\n      if (cachedResult) {\n        lintResult.lintErrors = cachedResult.lintErrors\n        lintResult.message = cachedResult.message\n        lintResult.numModelCallsCached++\n        lintResult.skipped = true\n        lintResult.skipReason = 'cached'\n\n        // if (config.linterOptions.debug) {\n        //   const { lintErrors } = lintResult\n\n        //   if (lintErrors.length) {\n        //     console.log(\n        //       `\\nFAIL CACHE HIT Rule \"${rule.name}\" file \"${\n        //         file.fileRelativePath\n        //       }\": ${lintErrors.length} ${plur('error', lintErrors.length)} found:`,\n        //       lintErrors\n        //     )\n        //   } else {\n        //     console.log(\n        //       `\\nPASS CACHE HIT Rule \"${rule.name}\" file \"${\n        //         file.fileRelativePath\n        //       }\": ${lintErrors.length} ${plur('error', lintErrors.length)} found`\n        //     )\n        //   }\n        // }\n\n        return { ...lintTask, lintResult }\n      }\n    }\n\n    // TODO: This should probably be moved to run a single time per file instead\n    // of per lint task\n    if (!config.linterOptions.noInlineConfig) {\n      const configFileOverride = parseInlineConfig({ file })\n\n      if (configFileOverride) {\n        if (configFileOverride.linterOptions?.disabled) {\n          // Inline config disabled linting for this file\n          // TODO: this result should probably be cached in `lintFile` instead of here\n          await cache.set(lintTask.cacheKey, lintResult)\n          return {\n            ...lintTask,\n            lintResult: {\n              ...lintResult,\n              skipped: true,\n              skipReason: 'inline-linter-disabled'\n            }\n          }\n        } else {\n          // Inline config overrides for this file\n          lintTask.config = mergeLinterConfigs(\n            lintTask.config,\n            configFileOverride\n          ) as types.ResolvedLinterConfig\n        }\n      }\n    }\n  }\n\n  if (lintTask.config.rules[rule.name] === 'off') {\n    // Config has this rule disabled for this file\n    return {\n      ...lintTask,\n      lintResult: { ...lintResult, skipped: true, skipReason: 'rule-disabled' }\n    }\n  }\n\n  // No cached result\n  return lintTask\n}\n","import fs from 'node:fs/promises'\nimport path from 'node:path'\n\nimport { parseDocument as parseYAMLDocument } from 'yaml'\n\nimport type * as types from './types.js'\nimport {\n  convertASTToPlaintext,\n  findAllBetween,\n  findAllCodeBlockNodes,\n  findAllHeadingNodes,\n  findAllYAMLNodes,\n  parseMarkdownAST,\n  parseRuleNode\n} from './markdown-utils.js'\nimport { RuleDefinitionSchema } from './rule.js'\nimport { validateRule } from './rule-utils.js'\nimport { assert, omit } from './utils.js'\n\n/**\n * Parses a rule definition markdown file and returns the result.\n */\nexport async function parseRuleFile({\n  content,\n  filePath\n}: {\n  content: string\n  filePath: string\n}): Promise<types.Rule> {\n  const ast = parseMarkdownAST(content)\n  const h1RuleNodes = findAllHeadingNodes(ast, { depth: 1 })\n\n  assert(\n    h1RuleNodes.length === 1,\n    `Rule file must contain a single h1 header: ${filePath}`\n  )\n\n  const yamlNodes = findAllYAMLNodes(ast)\n  assert(\n    h1RuleNodes.length <= 1,\n    `Rule must not contain more than 1 yaml frontmatter nodes: ${filePath}`\n  )\n\n  const maybePartialRule =\n    yamlNodes.length === 1\n      ? parseRuleFrontmatter(yamlNodes[0]?.value)\n      : undefined\n\n  const headingRuleNode = h1RuleNodes[0]!\n  let bodyRuleNodes = findAllBetween(ast, headingRuleNode)\n  const gritCodeBlockNodes = findAllCodeBlockNodes(ast).filter(\n    (codeNode) => codeNode.lang === 'grit' || codeNode.lang === 'gritql'\n  )\n  assert(\n    gritCodeBlockNodes.length <= 1,\n    `Rule must not contain more than 1 \"grit\" code blocks: ${filePath}`\n  )\n\n  const codeBlockNode = gritCodeBlockNodes[0]\n  let gritql: string | undefined\n  if (codeBlockNode) {\n    gritql = convertASTToPlaintext(codeBlockNode)?.trim()\n    bodyRuleNodes = bodyRuleNodes.filter((node) => node !== codeBlockNode)\n  }\n\n  const rule = parseRuleNode({\n    headingRuleNode,\n    bodyRuleNodes,\n    filePath,\n    partialRule: {\n      ...maybePartialRule,\n      gritql\n    }\n  })\n\n  return validateRule(rule)\n}\n\nexport async function parseRuleFilePath(\n  filePath: string,\n  {\n    cwd = process.cwd()\n  }: {\n    cwd?: string\n  } = {}\n): Promise<types.Rule> {\n  const filePathResolved = cwd ? path.resolve(cwd, filePath) : filePath\n  const content = await fs.readFile(filePathResolved, { encoding: 'utf8' })\n\n  return parseRuleFile({\n    content,\n    filePath\n  })\n}\n\nexport function parseRuleFrontmatter(\n  yaml: string | undefined\n): Partial<types.RuleDefinition> | undefined {\n  if (!yaml) {\n    return\n  }\n\n  try {\n    // TODO: more friendly error messages\n    // TODO: relax string[] to handle single strings\n    const yamlData: Record<string, unknown> = parseYAMLDocument(yaml).toJSON()\n\n    const parsedRule = RuleDefinitionSchema.strict().safeParse({\n      name: 'dummy-rule-title',\n      title: 'dummy rule title',\n      ...yamlData\n    })\n\n    if (!parsedRule.success) {\n      throw new Error(\n        `Rule contains invalid frontmatter metadata: ${parsedRule.error}`\n      )\n    }\n\n    const rule = parsedRule.data\n    return omit(rule, 'name', 'title')\n  } catch (err: any) {\n    throw new Error(`Error parsing rule frontmatter: ${err.message}`, {\n      cause: err\n    })\n  }\n}\n","import fs from 'node:fs/promises'\nimport path from 'node:path'\n\nimport pMap from 'p-map'\nimport plur from 'plur'\n\nimport type * as types from './types.js'\nimport { maxSourceFileLineLength, maxSourceFileNumLines } from './constants.js'\nimport { isValidSourceFile } from './is-valid-source-file.js'\nimport { resolveGlobFilePatterns } from './utils.js'\n\nexport async function resolveFiles({\n  config,\n  cwd = process.cwd()\n}: {\n  config: types.ResolvedLinterConfig\n  cwd?: string\n}) {\n  // console.log('resolveFiles', config.files, config.ignores, { cwd })\n\n  const sourceFilePaths = await resolveGlobFilePatterns(config.files, {\n    gitignore: true,\n    ignore: config.ignores,\n    cwd\n  })\n\n  // console.log({ sourceFilePaths })\n\n  const sourceFiles = await readSourceFiles(sourceFilePaths, {\n    concurrency: config.linterOptions.concurrency\n  })\n\n  return sourceFiles\n}\n\nexport async function resolveEvalFiles({\n  config,\n  cwd = process.cwd()\n}: {\n  config: types.ResolvedLinterConfig\n  cwd?: string\n}) {\n  const sourceFiles = await resolveGlobFilePatterns(config.files, {\n    gitignore: false,\n    ignore: config.ignores\n      .filter((pattern) => !/fixtures/.test(pattern))\n      .concat(['node_modules', 'dist', 'docs', '.env', '.next']),\n    cwd\n  })\n\n  return readSourceFiles(sourceFiles, {\n    concurrency: config.linterOptions.concurrency\n  })\n}\n\nexport async function readSourceFiles(\n  filePaths: string[],\n  {\n    concurrency = 32,\n    cwd = process.cwd(),\n    minFileSizeBytes,\n    maxFileSizeBytes,\n    maxFileNumLines = maxSourceFileNumLines,\n    maxFileLineLength = maxSourceFileLineLength\n  }: {\n    concurrency?: number\n    cwd?: string\n    minFileSizeBytes?: number\n    maxFileSizeBytes?: number\n    maxFileNumLines?: number\n    maxFileLineLength?: number\n  } = {}\n): Promise<types.SourceFile[]> {\n  // Ensure that we always resolve files in a deterministic order\n  filePaths.sort((a, b) => b.localeCompare(a))\n\n  return (\n    await pMap(\n      filePaths,\n      async (filePath) => {\n        filePath = path.resolve(cwd, filePath)\n\n        if (\n          !(await isValidSourceFile(filePath, {\n            minFileSizeBytes,\n            maxFileSizeBytes\n          }))\n        ) {\n          // Ignore invalid source files (e.g. binary files, empty files, etc.)\n          console.warn(`Ignoring invalid source file: ${filePath}`)\n          return\n        }\n\n        let content = await fs.readFile(filePath, { encoding: 'utf8' })\n        if (!content.trim()) {\n          // Ignore empty files\n          console.warn(`Ignoring empty source file: ${filePath}`)\n          return\n        }\n\n        let lines = content.split(/\\r?\\n/)\n\n        if (lines.length > maxFileNumLines) {\n          // Ignore files with too many lines of code\n          console.warn(\n            `Ignoring source file with too many lines: ${filePath} (${lines.length} is more than the configured limit ${maxFileNumLines})`\n          )\n          return\n        }\n\n        let numLongLines = 0\n        lines = lines.map((line) => {\n          if (line.length > maxFileLineLength) {\n            ++numLongLines\n\n            // Truncate lines which are too long\n            return line.slice(0, maxFileLineLength)\n          } else {\n            return line\n          }\n        })\n\n        if (numLongLines > 1) {\n          // Ignore files with too many long lines of code\n          console.warn(\n            `Ignoring source file with ${numLongLines} long ${plur('line', numLongLines)}: ${filePath} (a long line has at least ${maxFileLineLength} characters, and a file can have at most 1 long line which will be truncated)`\n          )\n          return\n        }\n\n        if (numLongLines > 0) {\n          content = lines.join('\\n')\n        }\n\n        const fileRelativePath = path.relative(cwd, filePath)\n        const fileName = path.basename(filePath)\n        const ext = fileName.split('.').at(-1)?.toLowerCase() ?? ''\n        const jsExtensions = new Set(['js', 'jsx', 'cjs', 'mjs'])\n        const tsExtensions = new Set(['ts', 'tsx'])\n\n        // TODO: improve filePath => language detection\n        const language = jsExtensions.has(ext)\n          ? 'javascript'\n          : tsExtensions.has(ext)\n            ? 'typescript'\n            : 'unknown'\n\n        return {\n          filePath,\n          fileRelativePath,\n          fileName,\n          language,\n          content\n        }\n      },\n      {\n        concurrency\n      }\n    )\n  ).filter(Boolean)\n}\n","import fs from 'node:fs/promises'\nimport path from 'node:path'\n\nimport { maxSourceFileSizeBytes, minSourceFileSizeBytes } from './constants.js'\nimport { isBinaryFile } from './is-binary-file.js'\n\nconst knownGeneratedFileNames = new Set([\n  'package-lock.json',\n  'pnpm-lock.yaml',\n  'yarn.lock',\n  'bun.lockb'\n])\n\nexport async function isValidSourceFile(\n  filePath: string,\n  {\n    minFileSizeBytes = minSourceFileSizeBytes,\n    maxFileSizeBytes = maxSourceFileSizeBytes\n  }: {\n    minFileSizeBytes?: number\n    maxFileSizeBytes?: number\n  } = {}\n): Promise<boolean> {\n  try {\n    if (!filePath) {\n      // Ignore invalid file paths\n      return false\n    }\n\n    const fileName = path.basename(filePath)\n    if (!fileName) {\n      // Ignore invalid file paths\n      return false\n    }\n\n    if (knownGeneratedFileNames.has(fileName)) {\n      // Ignore known generated files\n      return false\n    }\n\n    const stats = await fs.stat(filePath)\n\n    if (!stats.isFile()) {\n      // Ignore non-files\n      return false\n    }\n\n    if (stats.size <= minFileSizeBytes) {\n      // Ignore empty files\n      return false\n    }\n\n    if (stats.size > maxFileSizeBytes) {\n      // Ignore large files\n      return false\n    }\n\n    if (await isBinaryFile(filePath)) {\n      // Ignore binary files\n      return false\n    }\n\n    // File is valid\n    return true\n  } catch (err: any) {\n    throw new Error(`Error reading file: ${filePath}: ${err.message}`, {\n      cause: err\n    })\n  }\n}\n","import { fileTypeFromFile } from 'file-type'\n\nconst textFileMimeTypePrefixes = [\n  'text/',\n  'application/json',\n  'application/xml',\n  'application/javascript'\n]\n\nexport async function isBinaryFile(filePath: string): Promise<boolean> {\n  try {\n    const fileType = await fileTypeFromFile(filePath)\n\n    if (!fileType) {\n      // Unknown file type; assume it's a text file\n      return false\n    }\n\n    for (const mimeTypePrefix of textFileMimeTypePrefixes) {\n      if (fileType.mime.startsWith(mimeTypePrefix)) {\n        // The file is a known text file\n        return false\n      }\n    }\n\n    // Binary file type\n    return true\n  } catch (err: any) {\n    throw new Error(`Error reading file: ${filePath}: ${err.message}`, {\n      cause: err\n    })\n  }\n}\n","import fs from 'node:fs/promises'\nimport path from 'node:path'\n\nimport pMap from 'p-map'\n\nimport type * as types from './types.js'\nimport { parseRuleFile } from './parse-rule-file.js'\nimport { isValidRuleName, validateRule } from './rule-utils.js'\nimport { assert, resolveGlobFilePatterns } from './utils.js'\n\nexport async function resolveRules({\n  config,\n  cwd = process.cwd()\n}: {\n  config: types.ResolvedLinterConfig\n  cwd?: string\n}): Promise<types.Rule[]> {\n  const ruleFilePaths = await resolveGlobFilePatterns(config.ruleFiles ?? [], {\n    gitignore: true,\n    cwd\n  })\n  // console.log({ ruleFilePaths })\n\n  const processedRuleFilePaths = new Set<string>()\n\n  // Parse any project-specific rule files\n  let rules = (\n    await pMap(\n      ruleFilePaths,\n      async (ruleFilePath) => {\n        try {\n          if (processedRuleFilePaths.has(ruleFilePath)) {\n            return\n          }\n          processedRuleFilePaths.add(ruleFilePath)\n\n          const ruleFilePathAbsolute = path.join(cwd, ruleFilePath)\n          const ruleFileContent = await fs.readFile(\n            ruleFilePathAbsolute,\n            'utf8'\n          )\n          const rule = await parseRuleFile({\n            content: ruleFileContent,\n            filePath: ruleFilePath\n          })\n\n          return rule\n        } catch (err: any) {\n          throw new Error(\n            `Error parsing rule file \"${ruleFilePath}\": ${err.message}`,\n            { cause: err }\n          )\n        }\n      },\n      {\n        concurrency: config.linterOptions.concurrency\n      }\n    )\n  ).filter(Boolean)\n\n  const customRules: types.Rule[] = (config.ruleDefinitions ?? []).map(\n    (ruleDefinition) => {\n      const rule: types.Rule = {\n        source: 'custom',\n        cacheable: true,\n        ...ruleDefinition,\n        metadata: {}\n      }\n\n      assert(isValidRuleName(rule.name), `Invalid rule name \"${rule.name}\"`)\n      return rule\n    }\n  )\n\n  // Custom rules should always go first because they may import other rule\n  // markdown files, and we want the custom rules to take precedence\n  rules = customRules.concat(rules)\n\n  const processedRules = new Set<string>()\n\n  rules = rules.filter((rule) => {\n    rule = validateRule(rule)\n\n    if (processedRules.has(rule.name)) {\n      return false\n    }\n\n    processedRules.add(rule.name)\n    return true\n  })\n\n  if (config.rules) {\n    // Remove rules which have been disabled in the config\n    // TODO: should this happen here or in `lintFiles`?\n    rules = rules.filter((rule) => config.rules[rule.name] !== 'off')\n  }\n\n  return rules\n}\n"],"mappings":";;;;;;;AAIA,SAAS,qBAAqB;AAC9B,OAAO,qBAAqB;AAC5B,OAAO,gBAAgB;AACvB,SAAS,kBAAkB;;;ACP3B,OAAO,UAAU;AACjB,SAAS,qBAAqB;AAE9B,OAAO,WAAW;AAClB,SAAS,oBAAoB;AAC7B,SAAS,cAA6C;AACtD,OAAO,gBAAgB;;;ACHhB,SAAS,iBACd,mBACkB;AAClB,SAAO;AAAA,IACL,YAAY,CAAC;AAAA,IACb,SAAS;AAAA,IACT,eAAe;AAAA,IACf,qBAAqB;AAAA,IACrB,iBAAiB;AAAA,IACjB,qBAAqB;AAAA,IACrB,gBAAgB;AAAA,IAChB,WAAW;AAAA,IACX,aAAa,KAAK,IAAI;AAAA,IACtB,GAAG;AAAA,EACL;AACF;AAEO,SAAS,iBACd,aACA,aACkB;AAClB,SAAO;AAAA,IACL,YAAY,YAAY,WAAW,OAAO,YAAY,UAAU;AAAA,IAChE,SAAS,YAAY,WAAW,YAAY;AAAA,IAC5C,YAAY,YAAY,cAAc,YAAY;AAAA,IAClD,YAAY,YAAY,cAAc,YAAY;AAAA,IAClD,SAAS,YAAY,WAAW,YAAY;AAAA,IAC5C,eAAe,YAAY,gBAAgB,YAAY;AAAA,IACvD,qBACE,YAAY,sBAAsB,YAAY;AAAA,IAChD,iBAAiB,YAAY,kBAAkB,YAAY;AAAA,IAC3D,qBACE,YAAY,sBAAsB,YAAY;AAAA,IAChD,gBAAgB,YAAY,iBAAiB,YAAY;AAAA,IACzD,WAAW,YAAY,YAAY,YAAY;AAAA,IAC/C,aAAa,KAAK,IAAI,YAAY,aAAa,YAAY,WAAW;AAAA,IACtE,WACE,YAAY,cAAc,UAAa,YAAY,cAAc,SAC7D,KAAK,IAAI,YAAY,WAAW,YAAY,SAAS,IACrD,YAAY,aAAa,YAAY;AAAA,EAC7C;AACF;AAEO,SAAS,kBACd,YACoB;AACpB,MAAI,WAAW,cAAc,OAAW,QAAO;AAC/C,SAAO,KAAK,IAAI,GAAG,WAAW,YAAY,WAAW,WAAW;AAClE;AAEO,SAAS,yBACd,mBACA;AAAA,EACE;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF,GAkBkB;AA/EpB;AAgFE,SAAO,iBAAiB;AAAA,IACtB,GAAG;AAAA,IACH,cACE,4DAAmB,eAAnB,mBAA+B;AAAA,MAC7B,CAAC,sBACE;AAAA,QACC;AAAA,QACA,OAAO,KAAK;AAAA,QACZ;AAAA,QACA;AAAA,QACA,GAAG;AAAA,QACH,UAAU,KAAK;AAAA,QACf,GAAI,OACA,eAAe;AAAA,UACb,UAAU,KAAK;AAAA,UACf,UAAU,KAAK;AAAA,QACjB,CAAC,IACD,CAAC;AAAA,MACP;AAAA,UACC,CAAC;AAAA,EACV,CAAC;AACH;AAEO,SAAS,iBACd,YACmB;AACnB,QAAM,gBAAgB,oBAAI,IAA6B;AAEvD,SAAO,WAAW,OAAO,CAAC,cAAc;AACtC,UAAM,MAAM,KAAK;AAAA,MACf,eAAe;AAAA,QACb,UAAU,UAAU;AAAA,QACpB,UAAU,UAAU;AAAA,QACpB,aAAa,UAAU;AAAA,QACvB,SAAS,UAAU;AAAA,MACrB,CAAC;AAAA,IACH;AAEA,QAAI,cAAc,IAAI,GAAG,GAAG;AAC1B,aAAO;AAAA,IACT;AAEA,kBAAc,IAAI,KAAK,SAAS;AAChC,WAAO;AAAA,EACT,CAAC;AACH;;;ADlHA,SAAoB,WAAXA,gBAA0B;AACnC,SAAoB,WAAXA,gBAAyB;AAClC,SAAoB,WAAXA,gBAAyB;AAU3B,IAAM,OAAO,CAIlB,aACG,SACY;AACf,QAAM,UAAU,IAAI,IAAI,IAAI;AAC5B,SAAO,OAAO;AAAA,IACZ,OAAO,QAAQ,QAAQ,EAAE,OAAO,CAAC,CAAC,CAAC,MAAM,CAAC,QAAQ,IAAI,CAAQ,CAAC;AAAA,EACjE;AACF;AAUO,IAAM,OAAO,CAIlB,aACG,SACY;AACf,QAAM,UAAU,IAAI,IAAI,IAAI;AAC5B,SAAO,OAAO;AAAA,IACZ,OAAO,QAAQ,QAAQ,EAAE,OAAO,CAAC,CAAC,CAAC,MAAM,QAAQ,IAAI,CAAQ,CAAC;AAAA,EAChE;AACF;AAEO,SAAS,eACd,KACgB;AAChB,SAAO,OAAO;AAAA,IACZ,OAAO,QAAQ,GAAG,EAAE,OAAO,CAAC,CAAC,EAAE,KAAK,MAAM,UAAU,MAAS;AAAA,EAC/D;AACF;AAGO,SAAS,YACd,SACA,EAAE,YAAY,GAAG,IAA4B,CAAC,GACtC;AACR,MAAI,CAAC,QAAS,QAAO;AAErB,YAAU,QAAQ,KAAK,EAAE,MAAM,IAAI,EAAE,CAAC,EAAG,KAAK;AAC9C,MAAI,QAAQ,SAAS,UAAW,QAAO;AACvC,YAAU,GAAG,QAAQ,MAAM,GAAG,YAAY,CAAC,CAAC;AAE5C,SAAO;AACT;AAEO,SAAS,kBAAmC;AACjD,SAAO;AAAA,IACL,UAAU;AAAA,IACV,UAAU;AAAA,IACV,qBAAqB;AAAA,IACrB,mBAAmB;AAAA,IACnB,mBAAmB;AAAA,IACnB,kBAAkB;AAAA,IAClB,kBAAkB;AAAA,EACpB;AACF;AAEO,SAAS,eACd,YACA,YACiB;AACjB,SAAO;AAAA,IACL,UAAU,WAAW,WAAW,WAAW;AAAA,IAC3C,UAAU,WAAW,WAAW,WAAW;AAAA,IAC3C,qBACE,WAAW,sBAAsB,WAAW;AAAA,IAC9C,mBACE,WAAW,oBAAoB,WAAW;AAAA,IAC5C,mBACE,WAAW,oBAAoB,WAAW;AAAA,IAC5C,kBAAkB,WAAW,mBAAmB,WAAW;AAAA,IAC3D,kBAAkB,WAAW,mBAAmB,WAAW;AAAA,EAC7D;AACF;AAEA,IAAM,mCAAmC,oBAAI,IAAI;AAAA,EAC/C;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF,CAAC;AAED,IAAM,wBAAgD;AAAA,EACpD,YAAY;AAAA,EACZ,YAAY;AAAA,EACZ,UAAU;AAAA,EACV,QAAQ;AAAA,EACR,MAAM;AACR;AAEO,SAAS,mCACd,MACA,EAAE,UAAU,IAA8B,CAAC,GACvB;AACpB,WAAS,kBAAkB;AACzB,QAAI,WAAW;AACb,iBAAW,YAAY,WAAW;AAChC,cAAMC,SAAQ,mCAAmC,QAAQ;AACzD,YAAIA,OAAO,QAAOA;AAAA,MACpB;AAAA,IACF;AAGA,WAAO;AAAA,EACT;AAEA,SAAO,6BAAM,OAAO;AAEpB,MAAI,CAAC,KAAM,QAAO,gBAAgB;AAElC,MAAI,iCAAiC,IAAI,IAAI,EAAG,QAAO;AAEvD,QAAM,QAAQ,sBAAsB,IAAI;AACxC,MAAI,MAAO,QAAO;AAElB,SAAO,gBAAgB;AACzB;AAEO,SAAS,OACd,MACA,cACoB;AA1LtB;AA2LE,MAAI;AACF,YACG,OAAO,YAAY;AAAA;AAAA,OAEhB,aAAQ,QAAR,mBAAc;AAAA,QACd,WAAc;AAAA,EAEtB,QAAQ;AACN,WAAO;AAAA,EACT;AACF;AAEO,SAAS,eAAe;AAAA,EAC7B;AAAA,EACA;AAAA,EACA;AACF,GAIG;AACD,UAAQ;AAAA,IACN;AAAA,EAAK,MAAM,OAAO,2EAA2E,CAAC;AAAA,EAChG;AAEA,QAAM,kBAAkB,OAAO,wBAAwB;AACvD,UAAQ;AAAA,IACN;AAAA,EAAK,MAAM,KAAK,QAAQ,CAAC;AAAA,IACzB,KAAK,UAAU,iBAAiB,QAAW,CAAC;AAAA,EAC9C;AAEA,MAAI,OAAO;AACT,QAAI,MAAM,QAAQ;AAChB,cAAQ;AAAA,QACN;AAAA,EAAK,MAAM,KAAK,OAAO,CAAC;AAAA,QACxB,KAAK;AAAA,UACH,MAAM,IAAI,CAAC,UAAU;AAAA,YACnB,GAAG;AAAA,YACH,OAAO,KAAK,QAAQ,YAAY,KAAK,KAAK,IAAI;AAAA,YAC9C,aAAa,KAAK,cACd,YAAY,KAAK,WAAW,IAC5B;AAAA,YACJ,QAAQ,KAAK,SAAS,YAAY,KAAK,MAAM,IAAI;AAAA,YACjD,kBAAkB,KAAK,mBACnB,KAAK,iBAAiB,IAAI,CAAC,OAAO;AAAA,cAChC,GAAG;AAAA,cACH,MAAM,YAAY,EAAE,IAAI;AAAA,YAC1B,EAAE,IACF;AAAA,YACJ,kBAAkB,KAAK,mBACnB,KAAK,iBAAiB,IAAI,CAAC,OAAO;AAAA,cAChC,GAAG;AAAA,cACH,MAAM,YAAY,EAAE,IAAI;AAAA,YAC1B,EAAE,IACF;AAAA,UACN,EAAE;AAAA,UACF;AAAA,UACA;AAAA,QACF;AAAA,MACF;AAAA,IACF,OAAO;AACL,cAAQ,KAAK;AAAA,EAAK,MAAM,KAAK,yBAAyB,CAAC,EAAE;AAAA,IAC3D;AAAA,EACF;AAEA,MAAI,OAAO;AACT,QAAI,MAAM,QAAQ;AAChB,cAAQ;AAAA,QACN;AAAA,EAAK,MAAM,KAAK,aAAa,CAAC;AAAA,QAC9B,KAAK;AAAA,UACH,MAAM,IAAI,CAAC,SAAS,KAAK,gBAAgB;AAAA,UACzC;AAAA,UACA;AAAA,QACF;AAAA,MACF;AAAA,IACF,OAAO;AACL,cAAQ,KAAK;AAAA,EAAK,MAAM,KAAK,sCAAsC,CAAC,EAAE;AAAA,IACxE;AAAA,EACF;AACF;AAEO,SAAS,mBAAmB;AAAA,EACjC;AAAA,EACA;AAAA,EACA;AACF,GAIG;AACD,QAAM,iBAAiB,kBAAkB,UAAU;AACnD,QAAM,eAAe,iBACjB,GAAG,KAAK,KAAK,iBAAiB,GAAI,CAAC,MACnC;AAEJ,UAAQ;AAAA,IACN,GAAG,UAAU,EAAE,iBAAiB,OAAO,cAAc,SAAS,2BAA2B,YAAY,MACnG,WAAW,YAAY,KACvB,QAAQ,CAAC,CAAC;AAAA,IACZ,eAAe;AAAA,MACb,GAAG,KAAK,OAAO,YAAY,SAAS,WAAW;AAAA,MAC/C,GAAG;AAAA,QACD;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACF;AAAA,MACA;AAAA,IACF,CAAC;AAAA,EACH;AACF;AAEO,SAAS,aAAa;AAAA,EAC3B;AACF,GAIG;AACD,QAAM,YACJ,UAAU,oBACT,UAAU,mBAAmB,UAAU;AAC1C,QAAM,SACJ,UAAU,oBACT,UAAU,mBAAmB,UAAU;AAC1C,QAAM,UAAW,IAAI,YAAY,UAAW,YAAY;AACxD,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,UAAQ,IAAI;AAAA,eAAkB,EAAE,GAAG,WAAW,GAAG,cAAc,CAAC;AAChE,SAAO;AACT;AAGO,SAAS,6BAEa;AAC3B,MAAI;AACJ,MAAI;AAEJ,QAAM,UAAU,IAAI,QAAW,CAAC,KAAK,QAAQ;AAC3C,cAAU;AACV,aAAS;AAAA,EACX,CAAC;AAED,SAAO,EAAE,SAAS,SAAmB,OAAgB;AACvD;AAMA,eAAsB,wBACpB,mBACA,SACmB;AACnB,QAAM,WAAW,MAAM,QAAQ,iBAAiB,IAC3C,oBACD,CAAC,iBAA2B;AAEhC,QAAM,kBAAkB,SAAS,OAAO,CAAC,YAAY,CAAC,OAAO;AAC7D,MAAI,gBAAgB,QAAQ;AAC1B,UAAM,IAAI;AAAA,MACR,qCAAqC,gBAAgB,KAAK,IAAI,CAAC;AAAA,IACjE;AAAA,EACF;AAEA,YAAU;AAAA,IACR,qBAAqB;AAAA,IACrB,GAAG;AAAA,EACL;AAEA,QAAM,OAAO,mCAAS,QAAkB,QAAQ,IAAI;AACpD,QAAM,mBAAmB,SACtB,OAAO,CAAC,YAAY,KAAK,WAAW,OAAO,KAAK,QAAQ,WAAW,IAAI,CAAC,EACxE,IAAI,CAAC,YAAY,KAAK,SAAS,KAAK,OAAO,CAAC;AAC/C,QAAM,mBAAmB,SACtB;AAAA,IACC,CAAC,YAAY,EAAE,KAAK,WAAW,OAAO,KAAK,QAAQ,WAAW,IAAI;AAAA,EACpE,EACC,IAAI,CAAC,YAAY,KAAK,SAAS,KAAK,OAAO,CAAC;AAK/C,aAAW,WAAW,kBAAkB;AACtC,QAAI,KAAK,KAAK,OAAO,GAAG;AACtB,YAAM,IAAI;AAAA,QACR,+DAA+D,OAAO;AAAA,MACxE;AAAA,IACF;AAAA,EACF;AAEA,MAAI;AAMF,UAAM,uBAAuB,MAAM,OAAO,kBAAkB,OAAO;AAEnE,WAAO,iBAAiB,OAAO,oBAAoB;AAAA,EACrD,SAAS,KAAU;AACjB,YAAQ,MAAM,kCAAkC,IAAI,OAAO;AAC3D,UAAM;AAAA,EACR;AACF;AAEO,SAAS,QAAQ,OAAO,aAAa;AAC1C,SAAO,KAAK,WAAW,KAAK,QAAQ,cAAc,KAAK,GAAG,CAAC;AAC7D;AAEO,SAAS,0BACd,MACA;AAAA,EACE;AAAA,EACA;AACF,GAIA;AACA,MAAI,SAAS;AACX,UAAM,UAAU,WAAW,KAAK,kBAAkB,OAAO;AACzD,QAAI,CAAC,QAAQ,QAAQ;AACnB,aAAO;AAAA,IACT;AAAA,EACF;AAEA,MAAI,mCAAS,QAAQ;AACnB,UAAM,UAAU,WAAW,KAAK,kBAAkB,OAAO;AACzD,QAAI,QAAQ,QAAQ;AAClB,aAAO;AAAA,IACT;AAAA,EACF;AAEA,SAAO;AACT;AAEO,SAAS,qBAAqB;AAAA,EACnC;AAAA,EACA;AAAA,EACA;AACF,GAIY;AACV,MAAI,OAAO,cAAc,aAAa;AACpC,mBAAe,EAAE,OAAO,OAAO,OAAO,CAAC;AACvC,iBAAa,CAAC;AACd,WAAO;AAAA,EACT;AAEA,MAAI,SAAS,CAAC,MAAM,QAAQ;AAC1B,YAAQ;AAAA,MACN;AAAA,EAAK,MAAM,KAAK,8BAA8B,CAAC,KAAK,MAAM,OAAO,kCAAkC,CAAC;AAAA;AAAA,IACtG;AACA,iBAAa,CAAC;AACd,WAAO;AAAA,EACT;AAEA,MAAI,SAAS,CAAC,MAAM,QAAQ;AAC1B,YAAQ;AAAA,MACN;AAAA,EAAK,MAAM,KAAK,yBAAyB,CAAC,KAAK,MAAM,OAAO,kCAAkC,CAAC;AAAA;AAAA,IACjG;AACA,YAAQ;AAAA,MACN;AAAA,IACF;AACA,iBAAa,CAAC;AACd,WAAO;AAAA,EACT;AAEA,SAAO;AACT;;;ADjUO,SAAS,eAAe;AAAA,EAC7B;AAAA,EACA;AAAA,EACA;AAAA,EACA,GAAG;AACL,GAIqC;AAEnC,QAAM,iBAAiB,eAAe;AAAA,IACpC,GAAG;AAAA,IAEH,MAAM;AAAA;AAAA,MAEF,eAAe,KAAK,MAAM,oBAAoB,WAAW,UAAU,CAAC;AAAA,QACpE;AAAA;AAAA,IAGJ,MAAM;AAAA,MACJ;AAAA,QACE;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA;AAAA,MAEF;AAAA,IACF;AAAA;AAAA,IAGA,YAAY;AAAA,MACV;AAAA,QACE,OAAO,cAAc,CAAC;AAAA,QACtB;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACF;AAAA,IACF;AAAA,IAEA,eAAe,eAAe,KAAK,OAAO,iBAAiB,CAAC,GAAG,QAAQ,CAAC;AAAA,EAC1E,CAAC;AAED,SAAO,WAAW,cAAc;AAClC;;;AGtMA,OAAOC,WAAU;AAGjB,OAAO,wBAAwB;AAC/B,SAAS,KAAAC,UAAS;;;ACJX,IAAM,yBAAyB;AAC/B,IAAM,yBAAyB,MAAM;AAErC,IAAM,wBAAwB;AAC9B,IAAM,0BAA0B;AAEhC,IAAM,sBAAsB;AAE5B,IAAM,eAAe,CAAC,8BAA8B;;;ACR3D,SAAS,SAAS;;;ACIX,SAAS,sBAAsB,MAA0B;AAJhE;AAKE,SAAO,SAAS,KAAK,IAAI;AAAA;AAAA,IAEvB,KAAK,KAAK;AAAA;AAAA,EAEZ,KAAK,eAAe,EAAE;AAAA;AAAA,IAGtB,UAAK,qBAAL,mBAAuB,UACnB,oIACA,EACN;AAAA,EACE,kBAAkB,KAAK,gBAAgB,CAAC;AAAA,IACxC,UAAK,qBAAL,mBAAuB,UAAS,0BAA0B,EAAE;AAAA;AAAA,IAG5D,UAAK,qBAAL,mBAAuB,UACnB,uIACA,EACN;AAAA,EACE,kBAAkB,KAAK,gBAAgB,CAAC;AAAA,IACxC,UAAK,qBAAL,mBAAuB,UAAS,wBAAwB,EAAE;AAAA;AAAA,SAEnD,KAAK,IAAI;AAAA;AAElB;AAEO,SAAS,kBAAkB,UAAwC;AACxE,SAAO,WACH,SACG;AAAA,IACC,CAAC,YACC,SAAS,QAAQ,YAAY,EAAE;AAAA,EAAK,QAAQ,IAAI;AAAA;AAAA,EACpD,EACC,KAAK,MAAM,IACd;AACN;AAEO,SAAS,aACd,gBACY;AA5Cd;AA6CE,QAAM,QAAO,iDAAgB,SAAQ;AACrC,QAAM,aACJ,qBAAqB,YAAY,EAAE,UAAU,cAAc;AAC7D,EAAAC;AAAA,IACE,WAAW;AAAA,IACX,iBAAiB,IAAI,OAAM,gBAAW,UAAX,mBAAkB,OAAO;AAAA,EACtD;AAEA,QAAM,OAAmB;AAAA,IACvB,QAAQ;AAAA,IACR,WAAW;AAAA,IACX,UAAU,CAAC;AAAA,IACX,GAAG,WAAW;AAAA,EAChB;AACA,EAAAA,SAAO,gBAAgB,KAAK,IAAI,GAAG,sBAAsB,IAAI,GAAG;AAChE,EAAAA;AAAA,IACE,iBAAiB,KAAK,KAAK;AAAA,IAC3B,uBAAuB,KAAK,KAAK,eAAe,KAAK,IAAI;AAAA,EAC3D;AACA,EAAAA;AAAA,IACE,mBAAmB,KAAK,KAAK;AAAA,IAC7B,uBAAuB,KAAK,KAAK,eAAe,KAAK,IAAI;AAAA,EAC3D;AAEA,MAAI,KAAK,UAAU,QAAQ;AACzB,IAAAA;AAAA,MACE,KAAK,WAAW;AAAA,MAChB,SAAS,KAAK,IAAI,iBAAiB,KAAK,KAAK;AAAA,IAC/C;AAAA,EACF;AAEA,SAAO;AACT;AAEO,SAAS,gBAAgB,MAA2C;AACzE,MAAI,CAAC,KAAM,QAAO;AAClB,MAAI,KAAK,YAAY,MAAM,KAAM,QAAO;AAExC,QAAM,QAAQ,KAAK,MAAM,GAAG;AAC5B,MAAI,MAAM,WAAW,GAAG;AACtB,QAAI,CAAC,kBAAkB,KAAK,MAAM,CAAC,CAAE,EAAG,QAAO;AAC/C,QAAI,CAAC,iBAAiB,KAAK,MAAM,CAAC,CAAE,EAAG,QAAO;AAAA,EAChD,WAAW,CAAC,iBAAiB,KAAK,IAAI,EAAG,QAAO;AAEhD,SAAO;AACT;AAEO,SAAS,mBACd,OACwC;AACxC,MAAI,CAAC,MAAO,QAAO;AACnB,MAAI,MAAM,YAAY,MAAM,MAAO,QAAO;AAE1C,SAAO,UAAU,SAAS,UAAU,UAAU,UAAU;AAC1D;AAEO,SAAS,iBACd,OACwC;AACxC,MAAI,CAAC,MAAO,QAAO;AACnB,MAAI,MAAM,YAAY,MAAM,MAAO,QAAO;AAE1C,SAAO,UAAU,UAAU,UAAU,aAAa,UAAU;AAC9D;;;AD1DO,IAAM,8BAA8B,EACxC,OAAO;AAAA,EACN,MAAM,EAAE,OAAO,EAAE,SAAS,eAAe;AAAA,EAEzC,UAAU,EACP,OAAO,EACP,SAAS,EACT,SAAS,uCAAuC;AACrD,CAAC,EACA,OAAO;AAEH,IAAM,uBAAuB,EACjC,OAAO;AAAA,EACN,MAAM,EACH,OAAO,EACP,OAAO,CAAC,SAAS,gBAAgB,IAAI,CAAC,EACtC;AAAA,IACC;AAAA,EACF;AAAA,EAEF,OAAO,EACJ,OAAO,EACP;AAAA,IACC;AAAA,EACF;AAAA,EAEF,aAAa,EACV,OAAO,EACP,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,kBAAkB,EACf,MAAM,2BAA2B,EACjC,SAAS,EACT,SAAS,4DAA4D;AAAA,EAExE,kBAAkB,EACf,MAAM,2BAA2B,EACjC,SAAS,EACT,SAAS,kDAAkD;AAAA,EAE9D,SAAS,EACN,QAAQ,EACR,SAAS,EACT,SAAS,2CAA2C;AAAA,EAEvD,WAAW,EACR,QAAQ,EACR,SAAS,EACT,SAAS,4CAA4C;AAAA,EAExD,OAAO,EACJ,KAAK,CAAC,OAAO,QAAQ,OAAO,CAAC,EAC7B,SAAS,EACT,QAAQ,OAAO,EACf,SAAS,wBAAwB;AAAA,EAEpC,OAAO,EACJ,KAAK,CAAC,QAAQ,WAAW,MAAM,CAAC,EAChC,SAAS,EACT,QAAQ,MAAM,EACd,SAAS,4CAA4C;AAAA,EAExD,WAAW,EACR,MAAM,EAAE,OAAO,CAAC,EAChB,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,MAAM,EACH,MAAM,EAAE,OAAO,CAAC,EAChB,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,QAAQ,EACL,MAAM,EAAE,OAAO,CAAC,EAChB,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,WAAW,EACR,MAAM,EAAE,OAAO,CAAC,EAChB,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,OAAO,EACJ,OAAO,EACP,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,SAAS,EACN,MAAM,EAAE,OAAO,CAAC,EAChB,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,SAAS,EACN,MAAM,EAAE,OAAO,CAAC,EAChB,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,QAAQ,EACL,OAAO,EACP,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,uBAAuB,EACpB,OAAO,EACP,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,gBAAgB,EACb,SAAS,EAAE,MAAM,CAAC,EAAE,IAAI,CAAC,CAAC,GAAG,EAAE,IAAI,CAAC,EACpC,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,aAAa,EACV,SAAS,EAAE,MAAM,CAAC,EAAE,IAAI,CAAC,CAAC,GAAG,EAAE,IAAI,CAAC,EACpC,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,iBAAiB,EACd,SAAS,EAAE,MAAM,CAAC,EAAE,IAAI,CAAC,CAAC,GAAG,EAAE,IAAI,CAAC,EACpC,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,mBAAmB,EAChB,SAAS,EAAE,MAAM,CAAC,EAAE,IAAI,CAAC,CAAC,GAAG,EAAE,IAAI,CAAC,EACpC,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,gBAAgB,EACb,SAAS,EAAE,MAAM,CAAC,EAAE,IAAI,CAAC,CAAC,GAAG,EAAE,IAAI,CAAC,EACpC,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,oBAAoB,EACjB,SAAS,EAAE,MAAM,CAAC,EAAE,IAAI,CAAC,CAAC,GAAG,EAAE,IAAI,CAAC,EACpC,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,QAAQ,EAAE,OAAO,EAAE,SAAS;AAC9B,CAAC,EAIA,YAAY;;;AFjNR,IAAM,gCAAgCC,GAAE,KAAK,CAAC,OAAO,QAAQ,OAAO,CAAC;AAKrE,IAAM,iCAAiCA,GAAE;AAAA,EAC9CA,GAAE,OAAO;AAAA,EACT;AACF;AAKO,IAAM,kBACX,mBAAmB,EAAE,MAAM,UAAU,CAAC,KAAKC,MAAK,KAAK,YAAY,OAAO;AAEnE,IAAM,mBAAmBD,GAC7B,OAAO;AAAA,EACN,OAAOA,GACJ,OAAO,EACP,SAAS,EACT,SAAS,kDAAkD;AAAA,EAE9D,WAAWA,GACR,OAAO,EACP,SAAS,EACT,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,aAAaA,GACV,OAAO,EACP,IAAI,CAAG,EACP,IAAI,CAAG,EACP,SAAS,EACT,SAAS,4BAA4B;AAAA,EAExC,iCAAiCA,GAC9B,QAAQ,EACR,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,QAAQA,GACL,OAAO,EACP,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,mBAAmBA,GAChB,OAAO,EACP,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,YAAYA,GACT,OAAO,EACP,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,WAAWA,GACR,OAAOA,GAAE,IAAI,CAAC,EACd,SAAS,EACT;AAAA,IACC;AAAA,EACF;AACJ,CAAC,EACA,OAAO;AAGH,IAAM,sBAAsBA,GAChC,OAAO;AAAA,EACN,gBAAgBA,GACb,QAAQ,EACR,SAAS,EACT,SAAS,8DAA8D;AAAA,EAE1E,WAAWA,GACR,QAAQ,EACR,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,OAAOA,GAAE,QAAQ,EAAE,SAAS,EAAE,SAAS,wBAAwB;AAAA,EAC/D,aAAaA,GACV,QAAQ,EACR,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EACF,YAAYA,GAAE,QAAQ,EAAE,SAAS,EAAE,SAAS,8BAA8B;AAAA,EAC1E,WAAWA,GAAE,QAAQ,EAAE,SAAS,EAAE,SAAS,+BAA+B;AAAA,EAC1E,YAAYA,GACT,QAAQ,EACR,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,SAASA,GAAE,QAAQ,EAAE,SAAS,EAAE,SAAS,8BAA8B;AAAA,EACvE,QAAQA,GAAE,QAAQ,EAAE,SAAS,EAAE,SAAS,gBAAgB;AAAA,EACxD,UAAUA,GAAE,QAAQ,EAAE,SAAS,EAAE,SAAS,4BAA4B;AAAA,EAEtE,QAAQA,GACL,QAAQ,EACR,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,UAAUA,GACP,OAAO,EACP,SAAS,EACT,SAAS,8CAA8C;AAAA,EAE1D,aAAaA,GACV,OAAO,EACP,IAAI,EACJ,YAAY,EACZ,SAAS,EACT,SAAS,gDAAgD;AAC9D,CAAC,EACA,OAAO;AAGH,IAAM,6BAA6BA,GACvC,OAAO;AAAA,EACN,SAASA,GACN,MAAMA,GAAE,OAAO,CAAC,EAChB,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,SAASA,GACN,MAAMA,GAAE,OAAO,CAAC,EAChB,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,OAAO,+BAA+B,SAAS,EAAE;AAAA,IAC/C;AAAA,EACF;AACF,CAAC,EACA,OAAO;AAGH,IAAM,8BAA8BA,GAAE,MAAM,0BAA0B;AAGtE,IAAM,qBAAqBA,GAC/B,OAAO;AAAA,EACN,OAAOA,GACJ,MAAMA,GAAE,OAAO,CAAC,EAChB,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,SAASA,GACN,MAAMA,GAAE,OAAO,CAAC,EAChB,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,WAAWA,GACR,MAAMA,GAAE,OAAO,CAAC,EAChB,SAAS,EACT,SAAS,8DAA8D;AAAA,EAE1E,iBAAiBA,GACd,MAAM,oBAAoB,EAC1B,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,OAAO,+BAA+B,SAAS,EAAE;AAAA,IAC/C;AAAA,EACF;AAAA,EAEA,eAAe,oBAAoB,SAAS,EAAE;AAAA,IAC5C;AAAA,EACF;AAAA,EAEA,YAAY,iBAAiB,SAAS,EAAE,SAAS,EAAE;AAAA,EAEnD,WAAW,4BAA4B,SAAS,EAAE;AAAA,IAChD;AAAA,EACF;AACF,CAAC,EACA,OAAO;AAmBH,IAAM,uBAAgD;AAAA,EAC3D,gBAAgB;AAAA,EAChB,WAAW;AAAA,EACX,aAAa;AAAA,EACb,OAAO;AAAA,EACP,aAAa;AAAA,EACb,YAAY;AAAA,EACZ,WAAW;AAAA,EACX,YAAY;AAAA,EACZ,UAAU;AAAA,EACV,SAAS;AAAA,EACT,QAAQ;AAAA,EACR,QAAQ;AAAA,EACR,UAAU;AACZ;AAEO,IAAM,oBAA0C;AAAA,EACrD,QAAQ,OAAO,gBAAgB;AAAA,EAC/B,YAAY;AAAA,EACZ,OAAO;AAAA,EACP,WAAW;AAAA,EACX,aAAa;AACf;AAEO,IAAM,sBAET;AAAA,EACF,WAAW,CAAC,oBAAoB,uBAAuB,qBAAqB;AAAA,EAC5E,eAAe;AAAA,EACf,YAAY;AACd;AAEO,SAAS,kBAAkB,QAA6C;AAC7E,SAAO,mBAAmB,MAAM,MAAM;AACxC;AAEO,SAAS,aACd,OAC8B;AAC9B,SAAO,CAAC,CAAC,SAAS,UAAU;AAC9B;AAEA,SAAS,sBAAsBE,kBAAyC;AACtE,QAAM,OAAO,oBAAI,IAAY;AAC7B,SAAOA,iBAAgB,OAAO,CAAC,mBAAmB;AAChD,QAAI,CAAC,KAAK,IAAI,eAAe,IAAI,GAAG;AAClC,WAAK,IAAI,eAAe,IAAI;AAC5B,aAAO;AAAA,IACT;AAEA,WAAO;AAAA,EACT,CAAC;AACH;AAGO,SAAS,mBAId,SACA,SACmD;AACnD,SAAO,eAAe;AAAA,IACpB,GAAG,eAAe,OAAO;AAAA,IACzB,GAAG,eAAe,OAAO;AAAA,IACzB,OACE,QAAQ,SAAS,QAAQ,QACrBC;AAAA,MACE,CAAC,GAAI,QAAQ,SAAS,CAAC,GAAI,GAAI,QAAQ,SAAS,CAAC,CAAE,EAAE,OAAO,OAAO;AAAA,IACrE,IACA;AAAA,IACN,SACE,QAAQ,WAAW,QAAQ,UACvBA;AAAA,MACE,CAAC,GAAI,QAAQ,WAAW,CAAC,GAAI,GAAI,QAAQ,WAAW,CAAC,CAAE,EAAE;AAAA,QACvD;AAAA,MACF;AAAA,IACF,IACA;AAAA,IACN,WACE,QAAQ,aAAa,QAAQ,YACzBA;AAAA,MACE,CAAC,GAAI,QAAQ,aAAa,CAAC,GAAI,GAAI,QAAQ,aAAa,CAAC,CAAE,EAAE;AAAA,QAC3D;AAAA,MACF;AAAA,IACF,IACA;AAAA,IACN,iBACE,QAAQ,mBAAmB,QAAQ,kBAC/B,sBAAsB;AAAA,MACpB,GAAI,QAAQ,mBAAmB,CAAC;AAAA,MAChC,GAAI,QAAQ,mBAAmB,CAAC;AAAA,IAClC,CAAC,IACD;AAAA,IACN,OACE,QAAQ,SAAS,QAAQ,QACrB;AAAA,MACE,GAAG,eAAe,QAAQ,SAAS,CAAC,CAAC;AAAA,MACrC,GAAG,eAAe,QAAQ,SAAS,CAAC,CAAC;AAAA,IACvC,IACA;AAAA,IACN,eACE,QAAQ,iBAAiB,QAAQ,gBAC7B;AAAA,MACE,GAAG,eAAe,QAAQ,iBAAiB,CAAC,CAAC;AAAA,MAC7C,GAAG,eAAe,QAAQ,iBAAiB,CAAC,CAAC;AAAA,IAC/C,IACA;AAAA,IACN,YACE,QAAQ,cAAc,QAAQ,aAC1B;AAAA,MACE,GAAG,eAAe,QAAQ,cAAc,CAAC,CAAC;AAAA,MAC1C,GAAG,eAAe,QAAQ,cAAc,CAAC,CAAC;AAAA,IAC5C,IACA;AAAA,IACN,WACE,QAAQ,aAAa,QAAQ,YACzB,CAAC,GAAI,QAAQ,aAAa,CAAC,GAAI,GAAI,QAAQ,aAAa,CAAC,CAAE,EAAE;AAAA,MAC3D;AAAA,IACF,IACA;AAAA,EACR,CAAC;AACH;AASO,SAAS,2BAId,SACA,SACmD;AACnD,SAAO,eAAe;AAAA,IACpB,GAAG,eAAe,OAAO;AAAA,IACzB,GAAG,eAAe,OAAO;AAAA,IACzB,WACE,QAAQ,aAAa,QAAQ,kBACzB,QAAQ,aAAa,CAAC,IACtB,QAAQ;AAAA,IACd,iBACE,QAAQ,aAAa,QAAQ,kBACzB,QAAQ,mBAAmB,CAAC,IAC5B,QAAQ;AAAA,IACd,eACE,QAAQ,iBAAiB,QAAQ,gBAC7B;AAAA,MACE,GAAG,eAAe,QAAQ,iBAAiB,CAAC,CAAC;AAAA,MAC7C,GAAG,eAAe,QAAQ,iBAAiB,CAAC,CAAC;AAAA,IAC/C,IACA;AAAA,IACN,YACE,QAAQ,cAAc,QAAQ,aAC1B;AAAA,MACE,GAAG,eAAe,QAAQ,cAAc,CAAC,CAAC;AAAA,MAC1C,GAAG,eAAe,QAAQ,cAAc,CAAC,CAAC;AAAA,IAC5C,IACA;AAAA,IACN,WACE,QAAQ,aAAa,QAAQ,YACzB,CAAC,GAAI,QAAQ,aAAa,CAAC,GAAI,GAAI,QAAQ,aAAa,CAAC,CAAE,EAAE;AAAA,MAC3D;AAAA,IACF,IACA;AAAA,EACR,CAAC;AACH;AAEO,SAAS,8BACd,QACA,QAC0B;AAC1B,SAAO;AAAA,IACL,GAAG,eAAe,UAAU,CAAC,CAAC;AAAA,IAC9B,GAAG,eAAe,UAAU,CAAC,CAAC;AAAA,EAChC;AACF;AAEO,SAAS,oBACd,QAC2B;AAC3B,SAAO;AAAA,IACL;AAAA,MACE,OAAO,CAAC;AAAA,MACR,SAAS,CAAC;AAAA,MACV,WAAW,CAAC;AAAA,MACZ,iBAAiB,CAAC;AAAA,MAClB,OAAO,CAAC;AAAA,MACR,eAAe;AAAA,MACf,YAAY;AAAA,MACZ,WAAW,CAAC;AAAA,IACd;AAAA,IACA;AAAA,EACF;AACF;AAEO,IAAM,uBAAN,MAYP;AAAA,EACW;AAAA,EACA,wBAAwB,oBAAI,IAGnC;AAAA,EAEF,YAAY;AAAA,IACV;AAAA,IACA;AAAA,EACF,GAGG;AACD,QAAI,eAAmC,CAAC;AAExC,eAAW,UAAU,SAAS;AAC5B,qBAAe,mBAAmB,cAAc,MAAM;AAAA,IACxD;AAEA,mBAAe,2BAA2B,cAAc,iBAAiB;AACzE,SAAK,SAAS,oBAAoB,YAAY;AAE9C,QAAI,KAAK,OAAO,MAAM,WAAW,KAAK,CAAC,kBAAkB,OAAO;AAC9D,WAAK,OAAO,QAAQ;AAAA,IACtB;AAAA,EAcF;AAAA,EAEA,IAAI,QAAkB;AACpB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAEA,IAAI,UAAoB;AACtB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAEA,IAAI,YAAsB;AACxB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAEA,IAAI,QAAkC;AACpC,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAEA,IAAI,kBAA0C;AAC5C,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAEA,IAAI,gBAAuC;AACzC,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAEA,IAAI,aAAiC;AACnC,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAEA,uBACE,MACgC;AAChC,QAAI,KAAK,sBAAsB,IAAI,KAAK,gBAAgB,GAAG;AACzD,aAAO,KAAK,sBAAsB,IAAI,KAAK,gBAAgB;AAAA,IAC7D;AAEA,UAAM,WACJ,KAAK,OAAO,aACZ,CAAC,EAAE,OAAO,CAAC,aAAa,0BAA0B,MAAM,QAAQ,CAAC;AAEnE,QAAI,QAAkC,CAAC;AACvC,eAAW,WAAW,UAAU;AAC9B,cAAQ,8BAA8B,OAAO,QAAQ,KAAK;AAAA,IAC5D;AAEA,SAAK,sBAAsB,IAAI,KAAK,kBAAkB,KAAK;AAC3D,WAAO;AAAA,EACT;AAAA,EAEA,0BAA0B;AACxB,WAAO,eAAe,KAAK,MAAM;AAAA,EACnC;AACF;AAEO,SAAS,eACd,QACwE;AA/hB1E;AAgiBE,SAAO,eAAe;AAAA,IACpB,GAAG;AAAA,IACH,kBAAiB,YAAO,oBAAP,mBAAwB;AAAA,MACvC,CAAC,mBAAmB,GAAG,eAAe,IAAI;AAAA;AAAA,IAE5C,YAAY,eAAe;AAAA,MACzB,GAAG,OAAO;AAAA,MACV,UAAQ,YAAO,eAAP,mBAAmB,UAAS,eAAe;AAAA,IACrD,CAAC;AAAA,EACH,CAAC;AACH;;;AI1iBA;AAAA;AAAA;AAAA;AAAA;;;ACAA,SAAS,mBAAmB;AAQ5B,IAAM,gBAAgB,oBAAI,IAAiB;AAEpC,IAAM,oBAA8C;AAAA,EACzD,MAAM;AAAA,EACN,OAAO;AAAA,EACP,OAAO;AAAA,EACP,OAAO;AAAA,EACP,WAAW;AAAA,IACT;AAAA,IACA;AAAA,EACF;AAAA,EAEA,mBAAmB,OAAO,EAAE,MAAM,OAAO,QAAQ,IAAI,MAAM;AApB7D;AAqBI,UAAM,iBAAiB,YAAY,KAAK,iBAAiB,aAAa;AAEtE,QAAI,CAAC,gBAAgB;AACnB,aAAO;AAAA,QACL,YAAY;AAAA,UACV;AAAA,YACE,SAAS;AAAA,UACX;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,UAAM,EAAE,QAAQ,UAAU,MAAM,SAAS,IAAI;AAC7C,UAAM,aAAiC,CAAC;AAGxC,UAAM,WAAW,eAAe,EAAE,MAAM,QAAQ,UAAU,SAAS,CAAC;AACpE,UAAM,eAAe,MAAM,MAAM,IAAI,QAAQ;AAC7C,QAAI,cAAc;AAChB,aAAO;AAAA,IACT;AAMA,QAAI,GAAC,cAAS,oBAAT,mBAA0B,SAAQ;AACrC,iBAAW,KAAK;AAAA,QACd,SAAS;AAAA,QACT,OAAO;AAAA,QACP;AAAA,MACF,CAAC;AAAA,IACH;AAEA,QAAI,GAAC,cAAS,oBAAT,mBAA0B,mCAAkC;AAC/D,iBAAW,KAAK;AAAA,QACd,SACE;AAAA,QACF,OAAO;AAAA,QACP;AAAA,MACF,CAAC;AAAA,IACH;AAEA,QAAI,GAAC,cAAS,oBAAT,mBAA0B,2BAA0B;AACvD,iBAAW,KAAK;AAAA,QACd,SAAS;AAAA,QACT,OAAO;AAAA,QACP;AAAA,MACF,CAAC;AAAA,IACH;AAEA,UAAM,MAAM,IAAI,UAAU,EAAE,WAAW,CAAQ;AAC/C,WAAO,EAAE,WAAW;AAAA,EACtB;AACF;;;ACzEO,IAAM,uBAAiD;AAAA,EAC5D,MAAM;AAAA,EACN,OAAO;AAAA,EACP,OAAO;AAAA,EACP,OAAO;AAAA,EACP,aAAa;AAAA;AAAA;AAAA;AAAA;AAAA,EAMb,MAAM,CAAC,gBAAgB;AAAA,EACvB,QAAQ,CAAC,uBAAuB;AAAA,EAEhC,gBAAgB,OAAO,QAAQ;AAC7B,QAAI,CAAC,iBAAiB,KAAK,IAAI,KAAK,OAAO,GAAG;AAE5C,aAAO;AAAA,QACL,YAAY,CAAC;AAAA,MACf;AAAA,IACF,OAAO;AAAA,IAEP;AAAA,EACF;AACF;;;AC1BA;AAAA,EACE;AAAA,IACE,QAAU;AAAA,IACV,WAAa;AAAA,IACb,UAAY,CAAC;AAAA,IACb,MAAQ;AAAA,IACR,OAAS;AAAA,IACT,aAAe;AAAA,IACf,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,SAAW;AAAA,IACX,OAAS;AAAA,IACT,OAAS;AAAA,IACT,WAAa;AAAA,MACX;AAAA,MACA;AAAA,IACF;AAAA,IACA,MAAQ;AAAA,MACN;AAAA,IACF;AAAA,EACF;AAAA,EACA;AAAA,IACE,QAAU;AAAA,IACV,WAAa;AAAA,IACb,UAAY,CAAC;AAAA,IACb,MAAQ;AAAA,IACR,OAAS;AAAA,IACT,aAAe;AAAA,IACf,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,kBAAoB,CAAC;AAAA,IACrB,SAAW;AAAA,IACX,OAAS;AAAA,IACT,OAAS;AAAA,IACT,WAAa;AAAA,MACX;AAAA,IACF;AAAA,IACA,MAAQ;AAAA,MACN;AAAA,IACF;AAAA,IACA,WAAa;AAAA,MACX;AAAA,IACF;AAAA,IACA,SAAW;AAAA,MACT;AAAA,IACF;AAAA,IACA,QAAU;AAAA,IACV,uBAAyB;AAAA,EAC3B;AAAA,EACA;AAAA,IACE,QAAU;AAAA,IACV,WAAa;AAAA,IACb,UAAY,CAAC;AAAA,IACb,MAAQ;AAAA,IACR,OAAS;AAAA,IACT,aAAe;AAAA,IACf,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,SAAW;AAAA,IACX,OAAS;AAAA,IACT,OAAS;AAAA,IACT,WAAa;AAAA,MACX;AAAA,MACA;AAAA,IACF;AAAA,IACA,MAAQ;AAAA,MACN;AAAA,IACF;AAAA,IACA,QAAU;AAAA,MACR;AAAA,MACA;AAAA,IACF;AAAA,IACA,QAAU;AAAA,EACZ;AAAA,EACA;AAAA,IACE,QAAU;AAAA,IACV,WAAa;AAAA,IACb,UAAY,CAAC;AAAA,IACb,MAAQ;AAAA,IACR,OAAS;AAAA,IACT,aAAe;AAAA,IACf,kBAAoB,CAAC;AAAA,IACrB,kBAAoB,CAAC;AAAA,IACrB,SAAW;AAAA,IACX,OAAS;AAAA,IACT,OAAS;AAAA,IACT,WAAa;AAAA,MACX;AAAA,IACF;AAAA,IACA,MAAQ;AAAA,MACN;AAAA,IACF;AAAA,IACA,WAAa;AAAA,MACX;AAAA,IACF;AAAA,IACA,SAAW;AAAA,MACT;AAAA,IACF;AAAA,IACA,QAAU;AAAA,IACV,uBAAyB;AAAA,EAC3B;AAAA,EACA;AAAA,IACE,QAAU;AAAA,IACV,WAAa;AAAA,IACb,UAAY,CAAC;AAAA,IACb,MAAQ;AAAA,IACR,OAAS;AAAA,IACT,aAAe;AAAA,IACf,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,SAAW;AAAA,IACX,OAAS;AAAA,IACT,OAAS;AAAA,IACT,WAAa;AAAA,MACX;AAAA,IACF;AAAA,IACA,MAAQ;AAAA,MACN;AAAA,IACF;AAAA,IACA,QAAU;AAAA,IACV,uBAAyB;AAAA,EAC3B;AAAA,EACA;AAAA,IACE,QAAU;AAAA,IACV,WAAa;AAAA,IACb,UAAY,CAAC;AAAA,IACb,MAAQ;AAAA,IACR,OAAS;AAAA,IACT,aAAe;AAAA,IACf,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,SAAW;AAAA,IACX,OAAS;AAAA,IACT,OAAS;AAAA,IACT,WAAa;AAAA,MACX;AAAA,MACA;AAAA,IACF;AAAA,IACA,MAAQ;AAAA,MACN;AAAA,IACF;AAAA,IACA,QAAU;AAAA,MACR;AAAA,IACF;AAAA,IACA,WAAa;AAAA,MACX;AAAA,IACF;AAAA,IACA,QAAU;AAAA,IACV,uBAAyB;AAAA,EAC3B;AAAA,EACA;AAAA,IACE,QAAU;AAAA,IACV,WAAa;AAAA,IACb,UAAY,CAAC;AAAA,IACb,MAAQ;AAAA,IACR,OAAS;AAAA,IACT,aAAe;AAAA,IACf,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,SAAW;AAAA,IACX,OAAS;AAAA,IACT,OAAS;AAAA,IACT,WAAa;AAAA,MACX;AAAA,MACA;AAAA,IACF;AAAA,IACA,MAAQ;AAAA,MACN;AAAA,IACF;AAAA,IACA,SAAW;AAAA,MACT;AAAA,IACF;AAAA,IACA,QAAU;AAAA,EACZ;AAAA,EACA;AAAA,IACE,QAAU;AAAA,IACV,WAAa;AAAA,IACb,UAAY,CAAC;AAAA,IACb,MAAQ;AAAA,IACR,OAAS;AAAA,IACT,aAAe;AAAA,IACf,kBAAoB,CAAC;AAAA,IACrB,kBAAoB,CAAC;AAAA,IACrB,SAAW;AAAA,IACX,OAAS;AAAA,IACT,OAAS;AAAA,IACT,WAAa;AAAA,MACX;AAAA,IACF;AAAA,IACA,MAAQ;AAAA,MACN;AAAA,IACF;AAAA,IACA,WAAa;AAAA,MACX;AAAA,IACF;AAAA,IACA,SAAW;AAAA,MACT;AAAA,MACA;AAAA,IACF;AAAA,IACA,QAAU;AAAA,IACV,uBAAyB;AAAA,EAC3B;AAAA,EACA;AAAA,IACE,QAAU;AAAA,IACV,WAAa;AAAA,IACb,UAAY,CAAC;AAAA,IACb,MAAQ;AAAA,IACR,OAAS;AAAA,IACT,aAAe;AAAA,IACf,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,SAAW;AAAA,IACX,OAAS;AAAA,IACT,OAAS;AAAA,IACT,WAAa;AAAA,MACX;AAAA,MACA;AAAA,IACF;AAAA,IACA,MAAQ;AAAA,MACN;AAAA,IACF;AAAA,IACA,QAAU;AAAA,MACR;AAAA,IACF;AAAA,IACA,SAAW;AAAA,MACT;AAAA,IACF;AAAA,IACA,QAAU;AAAA,EACZ;AAAA,EACA;AAAA,IACE,QAAU;AAAA,IACV,WAAa;AAAA,IACb,UAAY,CAAC;AAAA,IACb,MAAQ;AAAA,IACR,OAAS;AAAA,IACT,aAAe;AAAA,IACf,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,SAAW;AAAA,IACX,OAAS;AAAA,IACT,OAAS;AAAA,IACT,WAAa;AAAA,MACX;AAAA,MACA;AAAA,IACF;AAAA,IACA,MAAQ;AAAA,MACN;AAAA,IACF;AAAA,IACA,SAAW;AAAA,MACT;AAAA,IACF;AAAA,IACA,QAAU;AAAA,IACV,uBAAyB;AAAA,EAC3B;AAAA,EACA;AAAA,IACE,QAAU;AAAA,IACV,WAAa;AAAA,IACb,UAAY,CAAC;AAAA,IACb,MAAQ;AAAA,IACR,OAAS;AAAA,IACT,aAAe;AAAA,IACf,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,SAAW;AAAA,IACX,OAAS;AAAA,IACT,OAAS;AAAA,IACT,WAAa;AAAA,MACX;AAAA,MACA;AAAA,IACF;AAAA,IACA,MAAQ;AAAA,MACN;AAAA,IACF;AAAA,IACA,QAAU;AAAA,IACV,uBAAyB;AAAA,EAC3B;AAAA,EACA;AAAA,IACE,QAAU;AAAA,IACV,WAAa;AAAA,IACb,UAAY,CAAC;AAAA,IACb,MAAQ;AAAA,IACR,OAAS;AAAA,IACT,aAAe;AAAA,IACf,kBAAoB,CAAC;AAAA,IACrB,kBAAoB;AAAA,MAClB;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,MACA;AAAA,QACE,MAAQ;AAAA,QACR,UAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,SAAW;AAAA,IACX,OAAS;AAAA,IACT,OAAS;AAAA,IACT,MAAQ;AAAA,MACN;AAAA,IACF;AAAA,IACA,QAAU;AAAA,EACZ;AACF;;;AC7fA,IAAM,kBAA0C;AAAA,EAC9C,GAAI;AAAA,EACJ,GAAG,OAAO,OAAO,cAAqB;AACxC;AAEA,IAAM,eAA+C,OAAO;AAAA,EAC1D,gBAAgB,IAAI,CAAC,SAAS,CAAC,KAAK,MAAM,OAAO,CAAC;AACpD;AAEO,IAAM,oBAAyC;AAAA,EACpD;AAAA,IACE,OAAO;AAAA,IACP;AAAA,IACA,OAAO;AAAA,EACT;AACF;;;ACpBA,SAAS,WAAwB;AACjC,OAAOC,WAAU;;;ACDjB,SAAS,kBAA2C;AAE7C,IAAM,iBAAN,cAA6B,MAAM;AAAC;AAEpC,IAAM,aAAN,cAAyB,eAAe;AAAC;;;ACJhD,OAAO,QAAQ;AACf,OAAOC,WAAU;AAEjB,SAAS,aAAa;AACtB,SAAS,wBAAwB;AACjC,OAAO,UAAU;AACjB,OAAO,WAAW;AAuElB,eAAsB,qBACpB,SACA;AAAA,EACE;AAAA,EACA,kBAA4B;AAC9B,GAK+C;AAC/C,MAAI,CAAE,MAAM,QAAQ,GAAI;AACtB,WAAO,oBAAI,IAAI;AAAA,EACjB;AAEA,QAAM,UAAU,MAAM,mBAAmB,SAAS,EAAE,MAAM,CAAC;AAC3D,SAAO,qBAAqB,SAAS,EAAE,OAAO,gBAAgB,CAAC;AACjE;AAOA,eAAsB,mBACpB,SACA;AAAA,EACE;AACF,GAGuB;AACvB,QAAM,aAAa,MAAM,gBAAgB;AACzC,MAAI,CAAC,YAAY;AACf,UAAM,IAAI,MAAM,uCAAuC;AAAA,EACzD;AAEA,QAAM,QAAQ,MAAM,IAAI,CAAC,SAAS,KAAK,QAAQ;AAE/C,QAAM,MAAM,MAAM,MAAM,YAAY;AAAA,IAClC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA,GAAG;AAAA,EACL,CAAC;AAGD,QAAM,QAAQ,IAAI,OACf,MAAM,IAAI,EACV,IAAI,CAAC,SAAS,KAAK,KAAK,CAAC,EACzB,OAAO,OAAO;AACjB,QAAM,cAAc,MACjB,IAAI,CAAC,SAAS;AACb,QAAI;AACF,YAAM,iBAAiB,KAAK,MAAM,IAAI;AACtC,WAAI,iDAAgB,gBAAe,SAAS;AAC1C,eAAO;AAAA,MACT;AAEA,YAAM,EAAE,OAAO,GAAG,GAAG,MAAM,IAAI;AAC/B,aAAO;AAAA,IACT,QAAQ;AACN,aAAO;AAAA,IACT;AAAA,EACF,CAAC,EACA,OAAO,OAAO;AAEjB,SAAO;AACT;AAEA,eAAsB,UAA4B;AAChD,QAAM,aAAa,MAAM,gBAAgB;AACzC,SAAO,CAAC,CAAC;AACX;AAEA,eAAsB,kBAA0C;AAC9D,QAAM,aAAa,MAAM,MAAM,QAAQ,EAAE,SAAS,KAAK,CAAC;AACxD,MAAI,WAAY,QAAO;AAGvB,QAAM,SAAS,MAAM,iBAAiB;AAAA,IACpC,KAAK,QAAQ;AAAA,EACf,CAAC;AACD,MAAI,CAAC,OAAQ,QAAO;AAEpB,QAAM,uBAAuBC,MAAK;AAAA,IAChC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,MAAI;AACF,UAAM,GAAG,OAAO,sBAAsB,GAAG,UAAU,OAAO,GAAG,UAAU,IAAI;AAC3E,WAAO;AAAA,EACT,QAAQ;AACN,WAAO;AAAA,EACT;AACF;AAOO,SAAS,qBACd,SACA;AAAA,EACE;AAAA,EACA,kBAA4B;AAC9B,GAKsC;AACtC,QAAM,oBAAoB,oBAAI,IAA0B;AAGxD,aAAW,SAAS,SAAS;AAE3B,QAAI,CAAC,kBAAkB,IAAI,MAAM,UAAU,GAAG;AAC5C,wBAAkB,IAAI,MAAM,YAAY,CAAC,CAAC;AAAA,IAC5C;AACA,sBAAkB,IAAI,MAAM,UAAU,EAAG,KAAK,KAAK;AAAA,EACrD;AAEA,QAAM,yBAAyB,oBAAI,IAAqC;AAGxE,aAAW,QAAQ,OAAO;AACxB,UAAM,EAAE,SAAS,IAAI;AAErB,QAAI,CAAC,uBAAuB,IAAI,QAAQ,GAAG;AACzC,6BAAuB,IAAI,UAAU;AAAA,QACnC,GAAG;AAAA,QACH,QAAQ,CAAC;AAAA,QACT,gBAAgB;AAAA,MAClB,CAAC;AAAA,IACH;AAAA,EACF;AAGA,aAAW,CAAC,UAAUC,QAAO,KAAK,kBAAkB,QAAQ,GAAG;AAC7D,UAAM,cAAc,uBAAuB,IAAI,QAAQ;AACvD,IAAAC,SAAO,WAAW;AAElB,UAAM,cAAcD,SAAQ;AAAA,MAC1B,CAAC,MAAG;AAlOV;AAkOa,wBAAE,UAAU,KAAK,CAAC,MAAM,EAAE,SAAS,QAAQ,MAA3C,mBAA8C,WAAU,EAAE;AAAA;AAAA,IACnE;AAEA,gBAAY,SAAS,YAAY,OAC9B,OAAO,WAAW,EAClB,KAAK,CAAC,GAAG,MAAM,EAAE,MAAM,OAAO,EAAE,MAAM,IAAI;AAAA,EAC/C;AAGA,aAAW,eAAe,uBAAuB,OAAO,GAAG;AACzD,UAAM,QAAQ,YAAY,QAAQ,MAAM,IAAI;AAC5C,UAAM,EAAE,OAAO,IAAI;AAEnB,QAAI,sBAAgC,CAAC;AACrC,QAAI,UAAU;AAEd,eAAW,SAAS,QAAQ;AAC1B,YAAM,YAAY,KAAK;AAAA,QACrB,KAAK,IAAI,GAAG,OAAO;AAAA,QACnB,MAAM,MAAM,OAAO,IAAI;AAAA,MACzB;AACA,YAAM,UAAU,MAAM,IAAI,OAAO;AACjC,UAAI,aAAa,QAAS;AAE1B,gBAAU,KAAK,IAAI,SAAS,OAAO;AACnC,YAAM,eAAe,MAAM,MAAM,WAAW,OAAO;AACnD,4BAAsB,oBAAoB,OAAO,YAAY;AAAA,IAC/D;AAEA,gBAAY,iBAAiB,oBAE1B,KAAK,IAAI,EACT,KAAK;AAAA,EACV;AAEA,SAAO;AACT;AAEA,eAAsB,uBAAuB;AAAA,EAC3C;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF,GAS0C;AACxC,MAAI,CAAC,KAAK,UAAU,OAAO,cAAc,QAAQ;AAC/C;AAAA,EACF;AAEA,MAAI,CAAC,+BAA+B,IAAI,KAAK,IAAI,GAAG;AAElD,UAAM,wBAAwB,qBAAqB,KAAK,QAAQ;AAAA,MAC9D,OAAO,SAAS,CAAC,IAAI;AAAA,MACrB,iBAAiB,KAAK;AAAA,IACxB,CAAC;AACD,mCAA+B,IAAI,KAAK,MAAM,qBAAqB;AAEnE,UAAME,wBAAuB,MAAM;AACnC,QAAI,OAAO,cAAc,WAAW;AAClC,cAAQ;AAAA,QACN,QAAQ,KAAK,IAAI;AAAA;AAAA,EAAuB;AAAA,UACtC,GAAGA,sBAAqB,OAAO;AAAA,QACjC,EACG;AAAA,UACC,CAAC,MAAG;AA3ShB;AA4Sc,wBAAK,EAAE,gBAAgB,YAAU,OAAE,WAAF,mBAAU,WAAU,CAAC,IAAI,KAAK,WAAS,OAAE,WAAF,mBAAU,WAAU,CAAC,CAAC;AAAA;AAAA,QAClG,EACC,KAAK,MAAM,CAAC;AAAA;AAAA;AAAA,MACjB;AAAA,IACF;AAAA,EACF;AAEA,QAAM,uBAAuB,MAAM,+BAA+B;AAAA,IAChE,KAAK;AAAA,EACP;AAEA,QAAM,oBAAoB,qBAAqB,IAAI,KAAK,QAAQ;AAChE,MAAI,CAAC,mBAAmB;AACtB;AAAA,EACF;AAEA,OAAK,SAAS,kBAAkB;AAChC,OAAK,iBAAiB,kBAAkB,eAAe,KAAK;AAE5D,MAAI,CAAC,KAAK,OAAO,UAAU,CAAC,KAAK,gBAAgB;AAC/C,WAAO,iBAAiB;AAAA,MACtB,SAAS;AAAA,MACT,YAAY;AAAA,MACZ,YAAY;AAAA,IACd,CAAC;AAAA,EACH;AACF;;;ACrUA,SAAS,YAAAC,iBAAgB;AACzB,SAAS,KAAAC,UAAS;;;ACFlB,OAAOC,WAAU;AAGjB,SAAS,qBAAqB;AAC9B,SAAS,kBAAkB;AAC3B,SAAS,gBAAgB;AACzB,OAAO,uBAAuB;AAC9B,OAAO,eAAe;AACtB,OAAO,iBAAiB;AACxB,SAAS,eAAe;AACxB,SAAS,UAAqB;AAc9B,SAAyB,oBAAmB;AARrC,SAAS,iBAAiB,SAAiB;AAChD,SAAO,QAAQ,EACZ,IAAI,WAAW,EACf,IAAI,iBAAiB,EACrB,IAAI,SAAS,EACb,MAAM,OAAO;AAClB;AAIO,SAAS,qBAAqB,OAAc;AACjD,SAAO,WAAW,OAAO;AAAA,IACvB,QAAQ;AAAA,IACR,MAAM;AAAA,IACN,YAAY,CAAC,cAAc,CAAC;AAAA,EAC9B,CAAC;AACH;AAEO,SAAS,sBAAsB,MAAa;AACjD,SAAO,SAAS,IAAI;AACtB;AAEO,SAAS,cAAc;AAAA,EAC5B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF,GAKe;AACb,QAAM,4BAA4B,cAAc;AAAA,IAC9C,CAAC,SAAS,KAAK,SAAS,aAAc,KAAiB,SAAS;AAAA,EAClE;AAEA,MAAI,mBAA2B,CAAC;AAEhC,MAAI,6BAA6B,GAAG;AAClC,uBAAmB,cAAc,MAAM,yBAAyB;AAChE,oBAAgB,cAAc,MAAM,GAAG,yBAAyB;AAAA,EAClE;AAEA,QAAM,eAAqB;AAAA,IACzB,MAAM;AAAA,IACN,UAAU;AAAA,EACZ;AAEA,QAAM,QAAQ,sBAAsB,eAAe;AACnD,EAAAC,SAAO,OAAO,8BAA8B;AAE5C,QAAM,mBAAmBC,MAAK,SAAS,QAAQ,EAAE,QAAQ,UAAU,EAAE;AACrE,QAAM,kBAAkB,gBAAgB,gBAAgB,IACpD,mBACAD,SAAQ,KAAK,EAAE,KAAK;AAExB,QAAM,cAAc,qBAAqB,YAAY;AAErD,QAAM,OAAmB,eAAe;AAAA,IACtC,MAAM;AAAA,IACN;AAAA,IACA;AAAA,IACA,kBAAkB,CAAC;AAAA,IACnB,kBAAkB,CAAC;AAAA,IACnB,WAAW;AAAA,IACX,OAAO;AAAA,IACP,OAAO;AAAA,IACP,QAAQ;AAAA,IACR,UAAU,CAAC;AAAA,IACX,GAAG;AAAA,EACL,CAAC;AACD,EAAAA,SAAO,KAAK,MAAM,gCAAgC,KAAK,EAAE;AAEzD,EAAAA;AAAA,IACE,gBAAgB,KAAK,IAAI;AAAA,IACzB,yBAAyB,KAAK,IAAI,MAAM,KAAK;AAAA,EAC/C;AAEA,QAAM,kBAAwB;AAAA,IAC5B,MAAM;AAAA,IACN,UAAU;AAAA,EACZ;AAEA,QAAM,UAAU,iBAAiB;AAAA,IAC/B,CAAC,SAAS,KAAK,SAAS,aAAc,KAAiB,SAAS;AAAA,EAClE;AAEA,EAAAA;AAAA,IACE,QAAQ,UAAU;AAAA,IAClB,wDAAwD,KAAK,IAAI,KAAK,QAAQ;AAAA,EAChF;AAEA,MAAI,sBAAsB;AAC1B,MAAI,sBAAsB;AAE1B,WAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,EAAE,GAAG;AACvC,UAAM,SAAS,QAAQ,CAAC;AACxB,UAAM,eAAe,eAAe,iBAAiB,QAAQ,QAAQ,IAAI,CAAC,CAAC;AAE3E,UAAM,eAAe,sBAAsB,MAAM,EAAE,YAAY,EAAE,KAAK;AACtE,UAAM,aACJ,YAAY,KAAK,YAAY,KAC7B,cAAc,KAAK,YAAY,KAC/B,WAAW,KAAK,YAAY;AAC9B,UAAM,aACJ,WAAW,KAAK,YAAY,KAC5B,gBAAgB,KAAK,YAAY,KACjC,WAAW,KAAK,YAAY;AAE9B,IAAAA;AAAA,MACE,cAAc;AAAA,MACd,wCAAwC,YAAY,+GAA+G,KAAK,IAAI,KAAK,QAAQ;AAAA,IAC3L;AAEA,UAAM,iBAAiB,aAAa;AAAA,MAClC,CAAC,SAAS,KAAK,SAAS;AAAA,IAC1B;AAEA,QAAI,YAAY;AACd;AAAA,IACF,WAAW,YAAY;AACrB;AAAA,IACF;AAgBA,eAAW,iBAAiB,gBAAgB;AAC1C,YAAM,OAAO,sBAAsB,aAAa;AAChD,YAAM,WAAW,cAAc,QAAQ;AAEvC,UAAI,YAAY;AACd,aAAK,iBAAkB,KAAK,EAAE,MAAM,SAAS,CAAC;AAAA,MAChD,WAAW,YAAY;AACrB,aAAK,iBAAkB,KAAK,EAAE,MAAM,SAAS,CAAC;AAAA,MAChD;AAAA,IACF;AAAA,EACF;AAEA,EAAAA;AAAA,IACE,uBAAuB;AAAA,IACvB,gEAAgE,KAAK,IAAI,KAAK,QAAQ;AAAA,EACxF;AAEA,EAAAA;AAAA,IACE,uBAAuB;AAAA,IACvB,gEAAgE,KAAK,IAAI,KAAK,QAAQ;AAAA,EACxF;AAYA,SAAO;AACT;AAcO,SAAS,eACd,QACA,OACA,KACA,MACQ;AACR,MAAI,CAAC,UAAU,CAAC,OAAO,QAAQ,CAAC,OAAO,UAAU;AAC/C,UAAM,IAAI,MAAM,sBAAsB;AAAA,EACxC;AAEA,QAAM,EAAE,SAAS,IAAI;AACrB,QAAM,UAAkB,CAAC;AACzB,QAAM,aAAa,MAAM,KAAK;AAC9B,QAAM,WAAW,MAAM,GAAG;AAC1B,MAAI;AACJ,MAAI,QAAQ;AAEZ,SAAO,EAAE,QAAQ,UAAU;AACzB,YAAQ,SAAS,KAAK;AAEtB,QAAI,GAAG,OAAO,MAAM,OAAO,MAAM,GAAG;AAClC,cAAQ,KAAK,KAAK;AAAA,IACpB;AAAA,EACF;AAGA,SAAO;AAEP,WAAS,MAAM,aAAwC;AACrD,QAAIE,SAAQ;AAEZ,QAAI,gBAAgB,QAAW;AAC7B,aAAO,SAAS;AAAA,IAClB,WAAW,OAAO,gBAAgB,UAAU;AAC1C,MAAAA,SAAQ;AAER,UAAIA,SAAQ,GAAG;AACb,QAAAA,SAAQ,SAAS;AAAA,MACnB;AAAA,IACF,WAAY,YAAoB,MAAM;AACpC,MAAAA,SAAQ,OAAO,SAAS,QAAQ,WAAkB;AAAA,IACpD;AAEA,QACE,OAAO,MAAMA,MAAK,KAClBA,SAAQ,KACRA,WAAU,OAAO,mBACjB;AACA,YAAM,IAAI,MAAM,8CAA8C;AAAA,IAChE;AAEA,QAAIA,SAAQ,SAAS,QAAQ;AAC3B,MAAAA,SAAQ,SAAS;AAAA,IACnB;AAEA,WAAOA;AAAA,EACT;AACF;AAEO,SAAS,sBAAsB,MAAY;AAChD,SAAO,KAAK,SAAS,OAAO,CAAC,SAAS,KAAK,SAAS,MAAM;AAC5D;AAEO,SAAS,oBACd,MACA,EAAE,MAAM,IAAwB,CAAC,GACjC;AACA,SAAO,KAAK,SAAS;AAAA,IACnB,CAAC,SACC,KAAK,SAAS,cAAc,UAAU,UAAa,KAAK,UAAU;AAAA,EACtE;AACF;AAEO,SAAS,iBAAiB,MAAY;AAC3C,SAAO,KAAK,SAAS,OAAO,CAAC,SAAS,KAAK,SAAS,MAAM;AAC5D;;;ACpRA,SAAS,YAAY,uBAAuB;AAC5C,SAAS,KAAAC,UAAuB;AA8BzB,SAAS,sBACd,QACA,cACG;AACH,MAAI;AACJ,MAAI,wBAAwBC,GAAE,UAAU;AACtC,aAAS,iBAAiB,MAAM;AAAA,EAClC,WAAW,wBAAwBA,GAAE,WAAW;AAC9C,aAAS,kBAAkB,MAAM;AAAA,EACnC,WAAW,wBAAwBA,GAAE,YAAY;AAC/C,aAAS,mBAAmB,MAAM;AAAA,EACpC,WAAW,wBAAwBA,GAAE,WAAW;AAC9C,aAAS,kBAAkB,QAAQ,YAAY;AAAA,EACjD,OAAO;AAEL,aAAS;AAAA,EACX;AAGA,QAAM,aAAc,aAAa,UAAkB,MAAM;AAEzD,MAAI,CAAC,WAAW,SAAS;AACvB,UAAM,IAAI,WAAW,WAAW,KAAK;AAAA,EACvC;AAEA,SAAO,WAAW;AACpB;AAEO,SAAS,0BACd,QACA,cACoB;AACpB,MAAI;AACF,UAAM,OAAO,sBAAyB,QAAQ,YAAY;AAC1D,WAAO;AAAA,MACL,SAAS;AAAA,MACT;AAAA,IACF;AAAA,EACF,SAAS,KAAU;AACjB,WAAO;AAAA,MACL,SAAS;AAAA,MACT,OAAO,IAAI;AAAA,IACb;AAAA,EACF;AACF;AASA,SAAS,UAAU,KAAa,GAAoB;AAClD,SAAO,IAAI,KAAK,IAAI,IAAI,CAAC,MAAM,QAAQ,EAAE,IAAI,KAAK,IAAI,IAAI,CAAC,MAAM;AACnE;AASO,SAAS,sBACd,OACA,mBACA;AACA,QAAM,YAAY,sBAAsB,WAAW,MAAM;AACzD,QAAM,UAAU,sBAAsB,WAAW,MAAM;AACvD,QAAM,sBAAmC,CAAC;AAC1C,MAAI,eAAe;AACnB,MAAI,aAAa;AACjB,QAAM,iBAAiB,EAAE,KAAK,OAAO,KAAK,MAAM;AAEhD,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,UAAM,KAAK,MAAM,OAAO,CAAC;AACzB,YAAQ,IAAI;AAAA,MACV,KAAK;AAAA,MACL,KAAK;AACH,YAAI,CAAC,eAAe,OAAO,MAAM,MAAM,GAAG,KAAK,CAAC,UAAU,OAAO,CAAC,GAAG;AACnE,yBAAe,EAAE,IAAI,CAAC,eAAe,EAAE;AAAA,QACzC;AAEA;AAAA,MAEF;AACE,YAAI,CAAC,eAAe,GAAG,KAAK,CAAC,eAAe,GAAG,GAAG;AAChD,kBAAQ,IAAI;AAAA,YACV,KAAK;AACH,kBAAI,iBAAiB,GAAG;AACtB,6BAAa;AAAA,cACf;AAEA,8BAAgB;AAEhB;AAAA,YAEF,KAAK;AACH,8BAAgB;AAChB,kBAAI,iBAAiB,GAAG;AACtB,sBAAM,YAAY,MAAM,MAAM,YAAY,IAAI,CAAC;AAC/C,sBAAM,SAAS,KAAK,MAAM,WAAW,SAAS,CAAC;AAC/C,oBAAI,UAAU,OAAO,WAAW,UAAU;AACxC,sCAAoB,KAAK,MAAmB;AAAA,gBAC9C;AAAA,cACF,WAAW,eAAe,GAAG;AAC3B,sBAAM,IAAI;AAAA,kBACR,mCAAmC,OAAO,gBAAgB,CAAC;AAAA,gBAC7D;AAAA,cACF;AAAA,UACJ;AAAA,QACF;AAAA,IACJ;AAAA,EACF;AAEA,MAAI,iBAAiB,GAAG;AACtB,UAAM,IAAI;AAAA,MACR,oCAAoC,YAAY,SAAS;AAAA,IAC3D;AAAA,EACF;AAEA,SAAO;AACT;AAEA,IAAM,kBAA2C;AAAA,EAC/C,MAAM;AAAA,EACN,OAAO;AAAA,EACP,GAAG;AAAA,EACH,GAAG;AAAA,EACH,KAAK;AAAA,EACL,IAAI;AAAA,EACJ,GAAG;AAAA,EACH,GAAG;AAAA,EACH,KAAK;AAAA,EACL,KAAK;AACP;AAQO,SAAS,iBAAiB,QAA4B;AAC3D,MAAI;AACF,UAAM,cAAc,sBAAsB,QAAQ,OAAO;AACzD,QAAI,YAAY,WAAW,GAAG;AAC5B,YAAM,IAAI,WAAW,uBAAuB,MAAM,EAAE;AAAA,IACtD;AAEA,UAAM,eAAe,YAAY,CAAC;AAClC,QAAI,CAAC,MAAM,QAAQ,YAAY,GAAG;AAChC,YAAM,IAAI;AAAA,QACR,uBAAuB,KAAK,UAAU,YAAY,CAAC;AAAA,MACrD;AAAA,IACF;AAEA,WAAO;AAAA,EACT,SAAS,KAAU;AACjB,QAAI,eAAe,iBAAiB;AAClC,YAAM,IAAI,WAAW,IAAI,SAAS,EAAE,OAAO,IAAI,CAAC;AAAA,IAClD,WAAW,eAAe,aAAa;AACrC,YAAM,IAAI,WAAW,uBAAuB,IAAI,OAAO,IAAI,EAAE,OAAO,IAAI,CAAC;AAAA,IAC3E,OAAO;AACL,YAAM;AAAA,IACR;AAAA,EACF;AACF;AAQO,SAAS,kBAAkB,QAAgB;AAChD,MAAI;AACF,UAAM,cAAc,sBAAsB,QAAQ,QAAQ;AAC1D,QAAI,YAAY,WAAW,GAAG;AAC5B,YAAM,IAAI,WAAW,wBAAwB,MAAM,EAAE;AAAA,IACvD;AAEA,QAAI,eAAe,YAAY,CAAC;AAChC,QAAI,MAAM,QAAQ,YAAY,GAAG;AAE/B,qBAAe,aAAa,CAAC;AAAA,IAC/B,WAAW,OAAO,iBAAiB,UAAU;AAC3C,YAAM,IAAI;AAAA,QACR,wBAAwB,KAAK,UAAU,YAAY,CAAC;AAAA,MACtD;AAAA,IACF;AAEA,WAAO;AAAA,EACT,SAAS,KAAU;AACjB,QAAI,eAAe,iBAAiB;AAClC,YAAM,IAAI,WAAW,IAAI,SAAS,EAAE,OAAO,IAAI,CAAC;AAAA,IAClD,WAAW,eAAe,aAAa;AACrC,YAAM,IAAI,WAAW,wBAAwB,IAAI,OAAO,IAAI;AAAA,QAC1D,OAAO;AAAA,MACT,CAAC;AAAA,IACH,OAAO;AACL,YAAM;AAAA,IACR;AAAA,EACF;AACF;AAQO,SAAS,mBAAmB,QAAyB;AAC1D,WAAS,OACN,YAAY,EACZ,KAAK,EACL,QAAQ,WAAW,EAAE;AAExB,QAAM,gBAAgB,gBAAgB,MAAM;AAE5C,MAAI,kBAAkB,QAAW;AAC/B,UAAM,IAAI,WAAW,2BAA2B,MAAM,EAAE;AAAA,EAC1D,OAAO;AACL,WAAO;AAAA,EACT;AACF;AASO,SAAS,kBACd,QACA,cACQ;AACR,WAAS,OAAO,KAAK;AAErB,QAAM,eAAe,aAAa,QAC9B,OAAO,SAAS,MAAM,IACtB,OAAO,WAAW,MAAM;AAE5B,MAAI,OAAO,MAAM,YAAY,GAAG;AAC9B,UAAM,IAAI,WAAW,0BAA0B,MAAM,EAAE;AAAA,EACzD;AAEA,SAAO;AACT;;;AFlQO,IAAM,sBAAsBC,GAAE,OAAO;AAAA,EAC1C,UAAUA,GACP,OAAO,EACP,SAAS,EACT,SAAS,yDAAyD;AAAA,EAErE,aAAaA,GACV,OAAO,EACP;AAAA,IACC;AAAA,EACF;AAAA,EAEF,mBAAmBA,GAChB,KAAK,CAAC,YAAY,UAAU,SAAS,CAAC,EACtC,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,WAAWA,GACR,OAAO,EACP,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EAEF,WAAWA,GACR,QAAQ,EACR;AAAA,IACC;AAAA,EACF;AAAA,EAEF,YAAYA,GACT,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAC9B,SAAS,2DAA2D;AACzE,CAAC;AAGM,IAAM,6BAA6BA,GAAE,MAAM,mBAAmB;AAG9D,IAAM,sCAAsCA,GAAE,OAAO;AAAA,EAC1D,gBAAgB;AAClB,CAAC;AAKM,SAAS,yCACd,UACiB;AACjB,QAAM,4BAA4B;AAAA,IAChC;AAAA,IACA;AAAA,EACF;AACA,MAAI,CAAC,0BAA0B,SAAS;AACtC,UAAM,IAAI;AAAA,MACR,+GAA+G,0BAA0B,KAAK;AAAA,IAChJ;AAAA,EACF;AAEA,SAAO,0BAA0B,KAAK;AACxC;AASO,SAAS,6CACd,UACA;AAAA,EACE,8BAA8B;AAChC,IAEI,CAAC,GACY;AACjB,QAAM,MAAM,iBAAiB,QAAQ;AACrC,QAAM,kBAAkB,sBAAsB,GAAG;AACjD,MAAI;AAEJ,MAAI,gBAAgB,WAAW,GAAG;AAChC,UAAM,UAAU,oBAAoB,KAAK,EAAE,OAAO,EAAE,CAAC;AAErD,QAAI,QAAQ,UAAU,6BAA6B;AAEjD,aAAO,CAAC;AAAA,IACV;AAEA,UAAM,IAAI;AAAA,MACR;AAAA,IACF;AAAA,EACF,WAAW,gBAAgB,SAAS,GAAG;AACrC,UAAM,UAAU,oBAAoB,KAAK,EAAE,OAAO,EAAE,CAAC;AAErD,QAAI,QAAQ,WAAW,GAAG;AACxB,YAAM,IAAI,eAAe,4CAA4C;AAAA,IACvE,OAAO;AACL,YAAM,UAAU,QAAQ,IAAI,CAAC,SAASC,UAAS,IAAI,EAAE,YAAY,EAAE,KAAK,CAAC;AACzE,YAAM,wBAAwB,QAAQ;AAAA,QAAc,CAAC,WACnD,aAAa,KAAK,MAAM;AAAA,MAC1B;AAEA,UAAI,wBAAwB,GAAG;AAC7B,cAAM,IAAI;AAAA,UACR;AAAA,QACF;AAAA,MACF;AAEA,YAAM,iBAAiB,QAAQ,qBAAqB;AACpD,YAAM,sBAAsB,eAAe,KAAK,cAAc;AAC9D,UAAI,4BAA4B,sBAAsB;AAAA,QACpD,MAAM;AAAA,QACN,UAAU;AAAA,MACZ,CAAC;AAED,UAAI,0BAA0B,SAAS,GAAG;AACxC,cAAM,8BAA8B,0BAA0B;AAAA,UAC5D,CAAC,SAAS,KAAK,SAAS;AAAA,QAC1B;AAEA,YAAI,4BAA4B,WAAW,GAAG;AAC5C,gBAAM,0BAA0B,0BAA0B;AAAA,YACxD,CAAC,SACC,0BAA0B,KAAK,OAAO,0BAA0B,EAC7D;AAAA,UACP;AAEA,cAAI,wBAAwB,WAAW,GAAG;AAAA,UAE1C,WAAW,wBAAwB,UAAU,GAAG;AAC9C,wCAA4B;AAAA,UAC9B;AAAA,QACF,WAAW,4BAA4B,WAAW,GAAG;AACnD,sCAA4B;AAAA,QAC9B;AAAA,MACF;AAEA,UAAI,CAAC,0BAA0B,QAAQ;AACrC,cAAM,IAAI;AAAA,UACR;AAAA,QACF;AAAA,MACF,WAAW,0BAA0B,SAAS,GAAG;AAC/C,cAAM,IAAI;AAAA,UACR;AAAA,QACF;AAAA,MACF,OAAO;AACL,wBAAgB,0BAA0B,CAAC;AAAA,MAC7C;AAAA,IACF;AAAA,EACF,OAAO;AACL,oBAAgB,gBAAgB,CAAC;AAAA,EACnC;AAEA,MAAI,CAAC,eAAe;AAClB,UAAM,IAAI;AAAA,MACR;AAAA,IACF;AAAA,EACF;AAEA,QAAM,6BAA6B;AAAA,IACjC,cAAe;AAAA,IACf;AAAA,EACF;AAEA,MAAI,CAAC,2BAA2B,SAAS;AACvC,UAAM,IAAI;AAAA,MACR,yMAAyM,2BAA2B,KAAK;AAAA,IAC3O;AAAA,EACF;AAEA,QAAM,iBAAiB,2BAA2B;AAClD,SAAO;AACT;AAEO,SAAS,qCACd,MACA,MACQ;AAIR,SAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yFAQgF,KAAK,IAAI,qEAAqE,KAAK,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAa5L;AAEO,SAAS,mDACd,MACQ;AACR,SAAO;AAAA;AAAA;AAAA;AAAA,qBAIY,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAU9B;AAEO,SAAS,kDACd,MACQ;AACR,SAAO;AAAA;AAAA;AAAA,mBAGU,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAS5B;AAEO,SAAS,+BACd,gBACQ;AACR,SAAO;AAAA;AAAA,oBAEW,KAAK,UAAU,gBAAgB,MAAM,CAAC,CAAC;AAAA;AAAA;AAG3D;AAEO,SAAS,mCAAmC;AAAA,EACjD;AAAA,EACA;AAAA,EACA;AACF,GAOY;AAhSZ;AAiSE,QAAM,EAAE,WAAW,WAAW,IAAI;AAClC,MAAI,CAAC,WAAW;AACd,WAAO;AAAA,EACT;AAEA,MAAI,eAAe,UAAU,eAAe,UAAU;AACpD,WAAO;AAAA,EACT;AAEA,QAAM,YAAW,mBAAc,aAAd,mBAAwB,cAAc;AACvD,MAAI,YAAY,KAAK,SAAS,UAAU;AACtC,WAAO;AAAA,EACT;AAEA,MACE,+CAA+C;AAAA,IAC7C;AAAA,IACA;AAAA,IACA;AAAA,EACF,CAAC,GACD;AACA,WAAO;AAAA,EACT;AAEA,SAAO;AACT;AAEO,SAAS,+CAA+C;AAAA,EAC7D;AAAA,EACA;AAAA,EACA;AACF,GAOY;AACV,MAAI,cAAc,sBAAsB,UAAU;AAChD,WAAO;AAAA,EACT;AAEA,MAAI,CAAC,KAAK,kBAAkB;AAC1B,WAAO;AAAA,EACT;AAEA,QAAM,qBAAqB,KAAK,iBAAiB;AAAA,IAAK,CAAC,YACrD,oBAAoB,QAAQ,MAAM,cAAc,WAAW;AAAA,EAC7D;AAKA,MAAI,CAAC,oBAAoB;AACvB,WAAO;AAAA,EACT;AAMA,QAAM,cAAc,KAAK,kBAAkB,KAAK;AAChD,MAAI,oBAAoB,aAAa,cAAc,WAAW,GAAG;AAC/D,WAAO;AAAA,EACT;AAEA,SAAO;AACT;AAEA,SAAS,oBAAoB,GAAW,GAAoB;AAC1D,MAAI,EAAE,YAAY,EAAE,KAAK;AACzB,MAAI,EAAE,YAAY,EAAE,KAAK;AAEzB,MAAI,EAAE,SAAS,EAAE,QAAQ;AACvB,WAAO,EAAE,SAAS,CAAC;AAAA,EACrB,WAAW,EAAE,SAAS,EAAE,QAAQ;AAC9B,WAAO,EAAE,SAAS,CAAC;AAAA,EACrB,OAAO;AACL,WAAO,MAAM;AAAA,EACf;AACF;;;AHlVA,eAAsB,SAAS;AAAA,EAC7B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,eAAe;AAAA,IACb,SAAS;AAAA,EACX;AAAA,EACA,aAAa;AACf,GAE8B;AA9C9B;AA+CE,eAAa,iBAAiB,UAAU;AAExC,QAAM,0BAA0B,aAAa,OAAO,WAAW,SAAS;AACxE,QAAM,QACJ,KAAK,SAAS,0BACV,OAAO,WAAW,YAClB,OAAO,WAAW;AAIxB,MAAI,cAAc,KAAK,QAAQ;AAC7B,UAAM,iCAAiC,oBAAI,IAGzC;AAEF,UAAM,kBAAkB,MAAM,uBAAuB;AAAA,MACnD;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF,CAAC;AAED,QAAI,iBAAiB;AACnB,aAAO;AAAA,IACT;AAAA,EACF;AAEA,MAAI,OAAO,cAAc,OAAO;AAC9B,YAAQ;AAAA,MACN,qBAAqB,KAAK,IAAI,WAAW,KAAK,gBAAgB,iBAAiB,KAAK;AAAA,IACtF;AAAA,EACF;AAEA,QAAM,WAAyB;AAAA,IAC7B,IAAI,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUb,sBAAsB,IAAI,CAAC;AAAA;AAAA;AAAA;AAAA,UAInB,KAAK,QAAQ;AAAA;AAAA,EAErB,KAAK,kBAAkB,KAAK,OAAO;AAAA;AAAA,WAE1B,KAAK,QAAQ;AAAA,CACvB;AAAA,IAEG,IAAI,KAAK,sDACP,KAAK,QACP,kCAAkC,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAU7C,qCAAqC,MAAM,IAAI,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAchD,kDAAkD,IAAI,CAAC;AAAA,CACxD;AAAA,EACC;AAEA,MAAI,UAAU,aAAa;AAE3B,KAAG;AACD,QAAI;AAmBF,YAAM,MAAM,MAAM,UAAU,IAAI;AAAA,QAC9B;AAAA,QACA;AAAA,MACF,CAAC;AAED,YAAM,WAAW,IAAI,QAAQ;AAC7B,iBAAW,UAAU;AAErB,UAAI,OAAO,cAAc,OAAO;AAC9B,gBAAQ;AAAA,UACN;AAAA,QAAW,KAAK,IAAI,WAAW,KAAK,gBAAgB,0BAA0B,KAAK;AAAA;AAAA,EAAS,QAAQ;AAAA;AAAA;AAAA,QACtG;AAAA,MACF;AAEA,eAAS,KAAK,IAAI,UAAU,QAAQ,CAAC;AAErC,UAAI,IAAI,QAAQ;AACd,mBAAW;AAAA,MACb,OAAO;AACL,mBAAW;AAAA,MACb;AAEA,UAAI,IAAI,MAAM;AACZ,mBAAW,aAAa,IAAI;AAAA,MAC9B,YAAY,SAAI,UAAJ,mBAAmB,YAAY;AACzC,mBAAW,aAAa,MAAO,IAAI,MAAc;AAAA,MACnD;AAEA,UAAI,IAAI,OAAO;AACb,mBAAW,mBAAmB,IAAI,MAAM;AACxC,mBAAW,uBAAuB,IAAI,MAAM;AAC5C,mBAAW,kBAAkB,IAAI,MAAM;AAAA,MACzC;AAEA,YAAM,iBACJ,6CAA6C,QAAQ;AAEvD,iBAAW,iBAAiB,gBAAgB;AAC1C,YAAI,mCAAmC,EAAE,eAAe,MAAM,KAAK,CAAC,GAAG;AAErE;AAAA,QACF;AAEA,cAAM,EAAE,YAAY,aAAa,UAAU,IAAI;AAE/C,mBAAW,WAAW,KAAK;AAAA,UACzB,SAAS,KAAK;AAAA,UACd,UAAU,KAAK;AAAA,UACf,UAAU,KAAK;AAAA,UACf,UAAU,KAAK;AAAA,UACf,OAAO,KAAK;AAAA,UACZ;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF,CAAC;AAAA,MACH;AAIA;AAAA,IACF,SAAS,KAAU;AACjB,UAAI,eAAe,cAAc,IAAI,SAAS,cAAc;AAC1D,cAAM;AAAA,MACR;AAEA,UAAI,aAAa,GAAG;AAClB,cAAM;AAAA,MACR;AAEA,UAAI,eAAe,gBAAgB;AACjC,YAAI,OAAO,cAAc,OAAO;AAC9B,kBAAQ;AAAA,YACN;AAAA,kCAAqC,KAAK,IAAI,WAAW,KAAK,gBAAgB,MAAM,IAAI,OAAO;AAAA;AAAA;AAAA,UACjG;AAAA,QACF;AAEA,YAAI,6CAAc,iBAAiB;AACjC,cAAI,6CAAc,iBAAiB;AACjC;AAAC,YAAC,IAAY,gBAAgB,KAAK;AAAA,cACjC;AAAA,cACA,aAAa,UAAU,UAAU;AAAA,YACnC;AACC,YAAC,IAAY,cAAc;AAE5B,kBAAM,QAAQ;AAAA,cACZ,aAAa,gBAAgB,GAAyB;AAAA,YACxD;AAAA,UACF;AAAA,QACF;AAGA,cAAM,aAAa,IAAI;AACvB,iBAAS;AAAA,UACP,IAAI;AAAA,YACF;AAAA;AAAA,EAAsG,UAAU;AAAA,UAClH;AAAA,QACF;AAAA,MACF,OAAO;AACL,YAAI,OAAO,cAAc,OAAO;AAC9B,kBAAQ;AAAA,YACN,qCAAqC,KAAK,IAAI,WAAW,KAAK,gBAAgB;AAAA,YAC9E,YAAY,IAAI,SAAS,EAAE,WAAW,IAAI,CAAC;AAAA,UAC7C;AAAA,QACF;AAEA,cAAM,IAAI;AAAA,UACR,qCAAqC,KAAK,IAAI,WAAW,KAAK,gBAAgB,MAAM,YAAY,IAAI,OAAO,CAAC;AAAA,UAC5G,EAAE,OAAO,IAAI;AAAA,QACf;AAAA,MACF;AAAA,IACF;AAAA,EACF,SAAS;AAET,aAAW,aAAa,iBAAiB,WAAW,UAAU;AAE9D,MAAI,WAAW,WAAW,SAAS,KAAK,yBAAyB;AAC/D,UAAM,EAAE,YAAY,mBAAmB,IAAI;AAC3C,QAAI,OAAO,cAAc,OAAO;AAC9B,cAAQ;AAAA,QACN;AAAA,iBAAoB,mBAAmB,MAAM,IAAIC;AAAA,UAC/C;AAAA,UACA,mBAAmB;AAAA,QACrB,CAAC,cAAc,KAAK,IAAI,WAAW,KAAK,gBAAgB;AAAA,QACxD;AAAA,MACF;AAAA,IACF;AAEA,iBAAa,MAAM,uBAAuB;AAAA,MACxC;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF,CAAC;AAED,QAAI,OAAO,cAAc,OAAO;AAC9B,YAAM,EAAE,WAAW,IAAI;AAEvB,cAAQ;AAAA,QACN;AAAA,sBAAyB,mBAAmB,MAAM,IAAIA;AAAA,UACpD;AAAA,UACA,mBAAmB;AAAA,QACrB,CAAC,WAAM,WAAW,MAAM,IAAIA;AAAA,UAC1B;AAAA,UACA,WAAW;AAAA,QACb,CAAC,cAAc,KAAK,IAAI,WAAW,KAAK,gBAAgB;AAAA,QACxD;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAEA,MAAI,OAAO,cAAc,OAAO;AAC9B,UAAM,EAAE,WAAW,IAAI;AAEvB,QAAI,WAAW,SAAS,GAAG;AACzB,cAAQ;AAAA,QACN;AAAA,iBAAoB,KAAK,IAAI,WAAW,KAAK,gBAAgB,MAC3D,WAAW,MACb,IAAIA,MAAK,SAAS,WAAW,MAAM,CAAC;AAAA,QACpC;AAAA,MACF;AAAA,IACF,OAAO;AACL,cAAQ;AAAA,QACN;AAAA,iBAAoB,KAAK,IAAI,WAAW,KAAK,gBAAgB;AAAA,MAC/D;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;AASA,eAAsB,uBAAuB;AAAA,EAC3C;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,eAAe;AAAA,IACb,SAAS;AAAA,EACX;AACF,GAAiE;AA1VjE;AA2VE,QAAM,QAAQ,KAAK,SAAS,OAAO,WAAW;AAC9C,eAAa,iBAAiB,UAAU;AAUxC,QAAM,kCACJ,OAAO,WAAW,oCAChB,OAAO,WAAW,eAClB,oBAAoB,WAAW,cAC/B,UAAU,WACV,OAAO,WAAW,eAAe;AAErC,QAAM,0BACJ,WAAW,WAAW,IAAI,CAAC,WAAW;AAAA,IACpC,UAAU,KAAK;AAAA,IACf,aAAa,MAAM;AAAA,IACnB,mBAAmB;AAAA;AAAA;AAAA,EAGrB,EAAE;AAEJ,QAAM,WAAyB;AAAA,IAC7B,IAAI,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUb,sBAAsB,IAAI,CAAC;AAAA;AAAA;AAAA;AAAA,UAInB,KAAK,QAAQ;AAAA;AAAA,EAErB,KAAK,kBAAkB,KAAK,OAAO;AAAA;AAAA,WAE1B,KAAK,QAAQ;AAAA,CACvB;AAAA,IAEG,IAAI,KAAK,mEACP,KAAK,QACP;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQF,qCAAqC,MAAM,IAAI,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQhD,+BAA+B,uBAAuB,CAAC;AAAA;AAAA;AAAA;AAAA,UAI/C,kCAAkC,SAAS,UAAU;AAAA;AAAA,EAG7D,kCACI,mDAAmD,IAAI,IACvD;AAAA;AAAA,EAEJ,kDAAkD,IAAI,CAAC,EACzD;AAAA,CACC;AAAA,EACC;AAEA,MAAI,UAAU,aAAa;AAE3B,KAAG;AACD,QAAI;AACF,YAAM,MAAM,MAAM,UAAU;AAAA,QAC1B,eAAe;AAAA,UACb;AAAA,UACA;AAAA,UACA,iBAAiB,kCACb,EAAE,MAAM,cAAc,IACtB;AAAA,QACN,CAAC;AAAA,MACH;AAEA,YAAM,WAAW,IAAI,QAAQ;AAC7B,iBAAW,UAAU;AAErB,UAAI,OAAO,cAAc,OAAO;AAC9B,gBAAQ;AAAA,UACN;AAAA,QAAW,KAAK,IAAI,WAAW,KAAK,gBAAgB,0BAA0B,KAAK;AAAA;AAAA,EAAS,QAAQ;AAAA;AAAA;AAAA,QACtG;AAAA,MACF;AAEA,eAAS,KAAK,IAAI,UAAU,QAAQ,CAAC;AAErC,UAAI,IAAI,QAAQ;AACd,mBAAW;AAAA,MACb,OAAO;AACL,mBAAW;AAAA,MACb;AAEA,UAAI,IAAI,MAAM;AACZ,mBAAW,aAAa,IAAI;AAAA,MAC9B,YAAY,SAAI,UAAJ,mBAAmB,YAAY;AACzC,mBAAW,aAAa,MAAO,IAAI,MAAc;AAAA,MACnD;AAEA,UAAI,IAAI,OAAO;AACb,mBAAW,mBAAmB,IAAI,MAAM;AACxC,mBAAW,uBAAuB,IAAI,MAAM;AAC5C,mBAAW,kBAAkB,IAAI,MAAM;AAAA,MACzC;AAEA,YAAM,iBAAiB,kCACnB,yCAAyC,QAAQ,IACjD,6CAA6C,UAAU;AAAA,QACrD,6BAA6B;AAAA,MAC/B,CAAC;AAKL,iBAAW,aAAa,CAAC;AAEzB,iBAAW,iBAAiB,gBAAgB;AAC1C,YAAI,mCAAmC,EAAE,eAAe,MAAM,KAAK,CAAC,GAAG;AAErE;AAAA,QACF;AAEA,cAAM,EAAE,YAAY,aAAa,UAAU,IAAI;AAE/C,mBAAW,WAAW,KAAK;AAAA,UACzB,SAAS,KAAK;AAAA,UACd,UAAU,KAAK;AAAA,UACf,UAAU,KAAK;AAAA,UACf,UAAU,KAAK;AAAA,UACf,OAAO,KAAK;AAAA,UACZ;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF,CAAC;AAAA,MACH;AAIA;AAAA,IACF,SAAS,KAAU;AACjB,UAAI,eAAe,cAAc,IAAI,SAAS,cAAc;AAC1D,cAAM;AAAA,MACR;AAEA,UAAI,aAAa,GAAG;AAClB,cAAM;AAAA,MACR;AAEA,UAAI,eAAe,gBAAgB;AACjC,YAAI,OAAO,cAAc,OAAO;AAC9B,kBAAQ;AAAA,YACN;AAAA,kCAAqC,KAAK,IAAI,WAAW,KAAK,gBAAgB,MAAM,IAAI,OAAO;AAAA;AAAA;AAAA,UACjG;AAAA,QACF;AAEA,YAAI,6CAAc,iBAAiB;AACjC;AAAC,UAAC,IAAY,gBAAgB,KAAK;AAAA,YACjC;AAAA,YACA,aAAa,UAAU,UAAU;AAAA,UACnC;AACC,UAAC,IAAY,cAAc;AAE5B,gBAAM,QAAQ;AAAA,YACZ,aAAa,gBAAgB,GAAyB;AAAA,UACxD;AAAA,QACF;AAGA,cAAM,aAAa,IAAI;AACvB,iBAAS;AAAA,UACP,IAAI;AAAA,YACF;AAAA;AAAA,EAAsG,UAAU;AAAA,UAClH;AAAA,QACF;AAAA,MACF,OAAO;AACL,YAAI,OAAO,cAAc,OAAO;AAC9B,kBAAQ;AAAA,YACN,qCAAqC,KAAK,IAAI,WAAW,KAAK,gBAAgB;AAAA,YAC9E,YAAY,IAAI,SAAS,EAAE,WAAW,IAAI,CAAC;AAAA,UAC7C;AAAA,QACF;AAEA,cAAM,IAAI;AAAA,UACR,qCAAqC,KAAK,IAAI,WAAW,KAAK,gBAAgB,MAAM,YAAY,IAAI,OAAO,CAAC;AAAA,UAC5G,EAAE,OAAO,IAAI;AAAA,QACf;AAAA,MACF;AAAA,IACF;AAAA,EACF,SAAS;AAET,aAAW,aAAa,iBAAiB,WAAW,UAAU;AAC9D,SAAO;AACT;;;AMhjBA,OAAO,UAAU;AACjB,OAAOC,WAAU;AACjB,OAAO,UAAU;;;ACKV,SAAS,eAAe;AAAA,EAC7B;AAAA,EACA;AAAA,EACA;AACF,GAI0B;AACxB,QAAM,EAAE,MAAM,IAAI;AAElB,MAAI,UAAU,QAAQ;AACpB,IAAAC,SAAO,IAAI;AAEX,QAAI,CAAC,0BAA0B,MAAM,IAAI,GAAG;AAC1C,aAAO;AAAA,IACT;AAEA,UAAM,mBAAmB,OAAO,uBAAuB,IAAI;AAE3D,QAAI,iBAAiB,KAAK,IAAI,MAAM,OAAO;AACzC,aAAO;AAAA,IACT;AAAA,EACF;AAEA,QAAM,YAAY,2BAA2B;AAC7C,QAAM,WAAW;AAAA,IACf,GAAG;AAAA,IACH;AAAA,IACA,OAAO,UAAU,SAAS,KAAM,mBAAmB;AAAA,IACnD;AAAA,IACA;AAAA,IACA;AAAA,IACA,UAAU,eAAe,EAAE,MAAM,MAAM,OAAO,CAAC;AAAA,EACjD;AAEA,SAAO;AACT;AAEO,SAAS,kBAAkB,UAAkC;AAClE,SAAO;AAAA,IACL,SAAS,SAAS,KAAK,IAAI;AAAA,IAC3B,SAAS,OAAO,SAAS,SAAS,KAAK,gBAAgB,MAAM;AAAA,EAC/D,EACG,OAAO,OAAO,EACd,KAAK,GAAG;AACb;;;AC7CO,SAAS,kBAAkB;AAAA,EAChC;AACF,GAEmC;AAbnC;AAcE,QAAM,QAAqC,CAAC;AAE5C,QAAM,kBAAkB;AACxB,QAAM,iBAAiB;AACvB,MAAI,mBAAmB;AACvB,MAAI,kBAAkB;AAEtB,aAAW,SAAS,KAAK,QAAQ,SAAS,eAAe,GAAG;AAC1D,uBAAmB,KAAK,IAAI,kBAAkB,MAAM,KAAK;AAAA,EAC3D;AAEA,aAAW,SAAS,KAAK,QAAQ,SAAS,cAAc,GAAG;AACzD,sBAAkB,KAAK,IAAI,iBAAiB,MAAM,KAAK;AAAA,EACzD;AAEA,MAAI,oBAAoB,KAAK,mBAAmB,iBAAiB;AAE/D,WAAO;AAAA,MACL,eAAe;AAAA,QACb,UAAU;AAAA,MACZ;AAAA,IACF;AAAA,EACF;AAEA,QAAM,iBAAiB;AACvB,aAAW,SAAS,KAAK,QAAQ,SAAS,cAAc,GAAG;AACzD,UAAM,gBAAe,WAAM,CAAC,MAAP,mBAAU;AAC/B,QAAI,CAAC,aAAc;AAEnB,UAAM,oBAAoB,aAAa,MAAM,GAAG,EAAE,IAAI,CAAC,MAAM,EAAE,KAAK,CAAC;AACrE,eAAW,oBAAoB,mBAAmB;AAChD,YAAM,+BAA+B,iBAClC,MAAM,GAAG,EACT,IAAI,CAAC,MAAM,EAAE,KAAK,EAAE,YAAY,CAAC;AAEpC,MAAAC;AAAA,QACE,6BAA6B,WAAW;AAAA,QACxC,kCAAkC,YAAY,MAAM,KAAK,gBAAgB;AAAA,MAC3E;AAEA,YAAM,CAAC,UAAU,WAAW,IAAI;AAEhC,MAAAA;AAAA,QACE,gBAAgB,QAAS;AAAA,QACzB,kCAAkC,YAAY,yBAAyB,QAAQ,MAAM,KAAK,gBAAgB;AAAA,MAC5G;AAEA,MAAAA;AAAA,QACE,mBAAmB,WAAY;AAAA,QAC/B,kCAAkC,YAAY,4BAA4B,WAAW,MAAM,KAAK,gBAAgB;AAAA,MAClH;AAEA,YAAM,QAAQ,IAAI;AAAA,IACpB;AAAA,EACF;AAEA,MAAI,OAAO,KAAK,KAAK,EAAE,SAAS,GAAG;AACjC,WAAO,EAAE,MAAM;AAAA,EACjB;AACF;;;AC3DA,eAAsB,eACpB,UACA,EAAE,MAAM,GACiB;AAjB3B;AAkBE,QAAM,aAAa,iBAAiB;AACpC,QAAM,EAAE,OAAO,MAAM,MAAM,OAAO,IAAI;AAEtC,MAAI,UAAU,QAAQ;AACpB,IAAAC,SAAO,IAAI;AACX,UAAM,UAAU,KAAK,kBAAkB,KAAK;AAE5C,QAAI,CAAC,QAAQ,KAAK,GAAG;AAEnB,aAAO;AAAA,QACL,GAAG;AAAA,QACH,YAAY,EAAE,GAAG,YAAY,SAAS,MAAM,YAAY,QAAQ;AAAA,MAClE;AAAA,IACF;AAEA,QAAI,KAAK,aAAa,KAAK,cAAc,QAAW;AAClD,YAAM,eAAe,MAAM,MAAM,IAAI,SAAS,QAAQ;AAEtD,UAAI,cAAc;AAChB,mBAAW,aAAa,aAAa;AACrC,mBAAW,UAAU,aAAa;AAClC,mBAAW;AACX,mBAAW,UAAU;AACrB,mBAAW,aAAa;AAqBxB,eAAO,EAAE,GAAG,UAAU,WAAW;AAAA,MACnC;AAAA,IACF;AAIA,QAAI,CAAC,OAAO,cAAc,gBAAgB;AACxC,YAAM,qBAAqB,kBAAkB,EAAE,KAAK,CAAC;AAErD,UAAI,oBAAoB;AACtB,aAAI,wBAAmB,kBAAnB,mBAAkC,UAAU;AAG9C,gBAAM,MAAM,IAAI,SAAS,UAAU,UAAU;AAC7C,iBAAO;AAAA,YACL,GAAG;AAAA,YACH,YAAY;AAAA,cACV,GAAG;AAAA,cACH,SAAS;AAAA,cACT,YAAY;AAAA,YACd;AAAA,UACF;AAAA,QACF,OAAO;AAEL,mBAAS,SAAS;AAAA,YAChB,SAAS;AAAA,YACT;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAEA,MAAI,SAAS,OAAO,MAAM,KAAK,IAAI,MAAM,OAAO;AAE9C,WAAO;AAAA,MACL,GAAG;AAAA,MACH,YAAY,EAAE,GAAG,YAAY,SAAS,MAAM,YAAY,gBAAgB;AAAA,IAC1E;AAAA,EACF;AAGA,SAAO;AACT;;;AH1EA,eAAsB,UAAU;AAAA,EAC9B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,MAAM,QAAQ,IAAI;AAAA,EAClB,eAAe;AAAA,IACb,SAAS;AAAA,EACX;AAAA,EACA;AAAA,EACA;AACF,GAU8B;AAC5B,QAAM;AAAA,IAAK;AAAA,IAAO,OAAO,SAAM;AAtDjC;AAyDI;AAAA;AAAA;AAAA,mBAAK,SAAL,8BAAY;AAAA,UACV;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAAA;AAAA;AAAA,EACF;AAEA,QAAM,iBAAiB,MAAM,OAAO,CAAC,SAAS,KAAK,UAAU,MAAM;AAEnE,QAAM,mBAAqC,MACxC,IAAI,CAAC,SAAS;AACb,QAAI,KAAK,UAAU,aAAa,KAAK,UAAU,QAAQ;AACrD,aAAO,eAAe,EAAE,MAAM,OAAO,CAAC;AAAA,IACxC,OAAO;AACL,aAAO;AAAA,IACT;AAAA,EACF,CAAC,EACA,OAAO,OAAO;AAEjB,QAAM,gBAAkC,eAAe;AAAA,IAAQ,CAAC,SAC9D,MAAM,IAAI,CAAC,SAAS,eAAe,EAAE,MAAM,MAAM,OAAO,CAAC,CAAC,EAAE,OAAO,OAAO;AAAA,EAC5E;AAEA,QAAM,mBAAmB,iBAAiB,OAAO,aAAa;AAE9D,MAAI,aAAa,iBAAiB;AAClC,MAAI,mBAAmB;AACvB,QAAM,WAAoB,CAAC;AAE3B,QAAM,iCAAiC,oBAAI,IAGzC;AAIF,QAAM,uBAAuB,MAAM;AAAA,IACjC,iBAAiB,MAAM,MAAM,cAAc,MAAM,MAAM;AAAA,IACvD,YACE;AAAA,MACE;AAAA,MACA,OAAO,aAAa;AAClB,YAAI,kBAAkB;AACpB;AAAA,QACF;AAEA,YAAI;AACF,gBAAM,EAAE,MAAM,MAAM,IAAI;AACxB,gBAAM,QACJ,KAAK,SACL,OAAO,WAAW,aAClB,OAAO,WAAW;AAEpB,cAAI,KAAK,mBAAmB;AAC1B,kBAAM,2BAA2B,MAAM,QAAQ;AAAA,cAC7C,KAAK,kBAAkB;AAAA,gBACrB,GAAG;AAAA,gBACH;AAAA,gBACA;AAAA,gBACA;AAAA,gBACA;AAAA,cACF,CAAC;AAAA,YACH;AAEA,gBAAI,0BAA0B;AAC5B,oBAAM,EAAE,YAAY,QAAQ,IAAI;AAEhC,uBAAS,aAAa;AAAA,gBACpB,cAAc,UACV;AAAA,kBACE,GAAG;AAAA,kBACH,SAAS;AAAA,kBACT,YAAY;AAAA,gBACd,IACA;AAAA,gBACJ;AAAA,kBACE;AAAA,kBACA;AAAA,kBACA,UAAU;AAAA,gBACZ;AAAA,cACF;AAAA,YACF;AAAA,UACF;AAEA,cAAI,SAAS,YAAY;AACvB,mBAAO;AAAA,UACT;AAKA,qBAAW,MAAM,eAAe,UAAU,EAAE,MAAM,CAAC;AAEnD,cAAI,SAAS,YAAY;AACvB,mBAAO;AAAA,UACT;AAEA,cAAI,UAAU,QAAQ;AACpB,kBAAM,OAAO,SAAS;AACtB,YAAAC,SAAO,IAAI;AAEX,gBAAI,KAAK,QAAQ;AACf,oBAAM,sBAAsB,MAAM,uBAAuB;AAAA,gBACvD;AAAA,gBACA;AAAA,gBACA;AAAA,gBACA;AAAA,gBACA;AAAA,cACF,CAAC;AAED,kBAAI,qBAAqB;AACvB,yBAAS,aAAa;AACtB,uBAAO;AAAA,cACT;AAAA,YACF;AAEA,gBAAI,KAAK,gBAAgB;AACvB,oBAAM,wBAAwB,MAAM,QAAQ;AAAA,gBAC1C,KAAK,eAAe;AAAA,kBAClB,GAAG;AAAA,kBACH;AAAA,kBACA;AAAA,kBACA;AAAA,kBACA;AAAA,kBACA;AAAA,gBACF,CAAC;AAAA,cACH;AAEA,kBAAI,uBAAuB;AACzB,sBAAM,EAAE,YAAY,QAAQ,IAAI;AAEhC,yBAAS,aAAa;AAAA,kBACpB,cAAc,UACV;AAAA,oBACE,GAAG;AAAA,oBACH,SAAS;AAAA,oBACT,YAAY;AAAA,kBACd,IACA;AAAA,kBACJ;AAAA,oBACE;AAAA,oBACA;AAAA,oBACA;AAAA,kBACF;AAAA,gBACF;AAAA,cACF;AAAA,YACF;AAAA,UACF;AAEA,iBAAO;AAAA,QACT,SAAS,KAAU;AACjB,gBAAM,QAAQ,IAAI;AAAA,YAChB,GAAG,kBAAkB,QAAQ,CAAC,iCAAiC,IAAI,OAAO;AAAA,YAC1E,EAAE,OAAO,IAAI;AAAA,UACf;AACA,kBAAQ,KAAK,KAAK;AAClB,mBAAS,KAAK,KAAK;AAAA,QACrB,UAAE;AACA,cAAI,SAAS,YAAY;AACvB,yBAAa,iBAAiB,YAAY,SAAS,UAAU;AAAA,UAC/D;AAEA,cACE,OAAO,cAAc,aACrB,WAAW,WAAW,SAAS,GAC/B;AACA,+BAAmB;AAAA,UACrB;AAAA,QACF;AAAA,MACF;AAAA,MACA;AAAA,QACE,aAAa,OAAO,cAAc;AAAA,MACpC;AAAA,IACF;AAAA,EACJ;AAEA,QAAM,wBACJ,qBAAqB,OAAO,OAAO,OAAO;AAC5C,QAAM,uBAAuB,sBAAsB;AAAA,IACjD,CAAC,MAAG;AA/OR;AA+OW,gBAAC,OAAE,eAAF,mBAAc,YAAW,GAAC,OAAE,eAAF,mBAAc;AAAA;AAAA,EAClD;AACA,QAAM,mBAAmB,sBAAsB;AAAA,IAC7C,CAAC,MAAG;AAlPR;AAkPW,sBAAE,eAAF,mBAAc,cAAW,OAAE,eAAF,mBAAc;AAAA;AAAA,EAChD;AACA,QAAM,iBAAiB,iBAAiB;AAAA,IACtC,CAAC,MAAM,EAAE,WAAW,eAAe;AAAA,EACrC,EAAE;AACF,QAAM,gBAAgB,iBAAiB;AAAA,IACrC,CAAC,MAAM,EAAE,WAAW,eAAe;AAAA,EACrC,EAAE;AACF,QAAM,2BAA2B,iBAAiB;AAAA,IAChD,CAAC,MACC,EAAE,WAAW,eAAe,sBAC5B,EAAE,WAAW,eAAe;AAAA,EAChC,EAAE;AACF,QAAM,uBAAuB,iBAAiB;AAAA,IAC5C,CAAC,MAAM,EAAE,WAAW,eAAe;AAAA,EACrC,EAAE;AACF,QAAM,mBAAmB,iBAAiB;AAAA,IACxC,CAAC,MACC,EAAE,WAAW,eAAe,4BAC5B,EAAE,WAAW,eAAe;AAAA,EAChC,EAAE;AAEF,UAAQ;AAAA,IACN;AAAA,IACA,eAAe;AAAA,MACb,UAAU,MAAM;AAAA,MAChB,UAAU,MAAM;AAAA,MAChB,UAAU,qBAAqB;AAAA,MAC/B,gBAAgB,kBAAkB;AAAA,MAClC,0BAA0B,4BAA4B;AAAA,MACtD,sBAAsB,wBAAwB;AAAA,MAC9C,eAAe,iBAAiB;AAAA,MAChC,kBAAkB,oBAAoB;AAAA,IACxC,CAAC;AAAA,EACH;AAEA,MAAI,OAAO,cAAc,OAAO;AAC9B,YAAQ;AAAA,MACN,qBAAqB;AAAA,QAAI,CAACC,UAAM;AAxRtC;AAyRQ,gCAAe;AAAA,YACb,OAAM,KAAAA,MAAK,SAAL,mBAAW;AAAA,YACjB,MAAMA,MAAK,KAAK;AAAA,UAClB,CAAC;AAAA;AAAA,MACH;AAAA,IACF;AAAA,EACF;AAEA,MAAI,OAAO,cAAc,aAAa,WAAW,WAAW,SAAS,GAAG;AACtE,uBAAmB;AAAA,EACrB;AAEA,MAAI,gBAAgB;AAClB,UAAM,QAAQ;AAAA,MACZ,eAAe,EAAE,UAAU,qBAAqB,OAAO,CAAC;AAAA,IAC1D;AAAA,EACF;AAEA,QAAM,iBAAsD,CAAC;AAE7D,aAAW,YAAY,sBAAsB;AAC3C,UAAM,EAAE,MAAM,IAAI;AAElB,QAAI,CAAC,eAAe,KAAK,GAAG;AAC1B,YAAM,oBAAoB,OAAO,cAAc,SAC3C,WAAW,KAAK,KAChB,WAAW,KAAK;AAEpB,YAAM,YAAY,2BAA2B;AAE7C,qBAAe,KAAK,IAAI;AAAA,QACtB,GAAG;AAAA,QAEH,WAAW,CAAC;AAAA,QACZ,aAAa,CAAC;AAAA,QAEd,OAAO;AAAA,QACP,WAAW;AAAA,QAEX,MAAM,OAAO;AACX,cAAI,CAAC,KAAK,OAAO;AACf,kBAAM,IAAI,QAAc,CAAC,YAAY;AACnC,mBAAK,QAAQ,KAAK,mBAAmB,OAAO,cAAc;AACxD,qBAAK,YAAY;AACjB,wBAAQ;AACR,uBAAO;AAAA,cACT,CAAC;AAAA,YACH,CAAC;AAAA,UACH;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,UAAM,gBAAgB,eAAe,KAAK;AAC1C,kBAAc,UAAU,KAAK,QAAQ;AAAA,EACvC;AAEA,MAAI,kBAAoC,CAAC;AACzC,aAAW,iBAAiB,OAAO,OAAO,cAAc,GAAG;AACzD,sBAAkB,gBAAgB,OAAO,cAAc,SAAS;AAEhE,kBAAc,UAAU,QAAQ;AAAA,MAC9B,cAAc,UAAU,IAAI,CAAC,MAAM,EAAE,OAAO;AAAA,IAC9C;AAEA,kBAAc,QAAQ,KAAK,CAAC,UAAU;AACpC,oBAAc,QAAQ,KAAK;AAC3B,YAAM,gBAAgB,cAAc,YAAY;AAAA,QAC9C,CAAC,WAAW,OAAO,WAAW,SAAS;AAAA,MACzC;AAEA,UAAI,CAAC,eAAe;AAClB,sBAAc,MAAO,KAAK,CAACA,UAAS;AAClC,UAAAA,MAAK,MAAM;AAAA,QACb,CAAC;AAAA,MACH;AAAA,IACF,GAAG,cAAc,MAAM;AAAA,EACzB;AAIA,QAAM;AAAA,IACJ;AAAA,IACA,OAAO,UAAU,UAAU;AACzB,UAAI,kBAAkB;AACpB;AAAA,MACF;AAEA,YAAM;AAAA,QACJ;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA,QAAAC;AAAA,QACA,YAAY;AAAA,MACd,IAAI;AAEJ,YAAM,gBAAgB,eAAe,KAAK;AAC1C,MAAAF,SAAO,aAAa;AACpB,YAAM,cAAc,KAAK;AACzB,YAAM,yBAAyB,cAAc;AAE7C,UAAI;AACJ,UAAI;AAEJ,YAAM,aAAa,MAAM,uBAAuB;AAAA,QAC9C,KAAK;AAAA,QACL,OAAOC,UAAS;AArYxB;AAsYU,cAAI;AACF,kBAAM,yBAA2D;AAAA,cAC/D;AAAA,cACA,YAAY;AAAA,cACZ;AAAA,cACA;AAAA,cACA,QAAAC;AAAA,cACA;AAAA,cACA,cAAc;AAAA,gBACZ,GAAG;AAAA,gBACH,iBAAiB,CAAC,QAAQ;AAhZ1C,sBAAAC;AAiZkB,kBAAAF,MAAK,UAAU,aAAa,IAAI,OAAO,EAAE;AACzC,0BAAOE,MAAA,aAAa,oBAAb,gBAAAA,IAAA,mBAA+B;AAAA,gBACxC;AAAA,cACF;AAAA,YACF;AAEA,gBAAI,UAAU,QAAQ;AAGpB,oBAAM,gBACJ,KAAK,eAAe;AAEtB,oBAAM,sBAAqD;AAAA,gBACzD,GAAG;AAAA,gBACH;AAAA,cACF;AAEA,oBAAM,wBACJ,MAAM,cAAc,mBAAmB;AAEzC,+BAAiB,yBAAyB,uBAAuB;AAAA,gBAC/D;AAAA,gBACA;AAAA,cACF,CAAC;AAED,kBAAI,KAAK,iBAAiB;AACxB,sBAAM,4BAA4B,MAAM,QAAQ;AAAA,kBAC9C,KAAK,gBAAgB;AAAA,oBACnB,GAAG;AAAA,oBACH,YAAY;AAAA,kBACd,CAAC;AAAA,gBACH;AAEA,oBAAI,2BAA2B;AAC7B,mCAAiB;AAAA,oBACf;AAAA,oBACA;AAAA,sBACE;AAAA,sBACA;AAAA,oBACF;AAAA,kBACF;AAAA,gBACF;AAAA,cACF;AAAA,YACF,OAAO;AACL,kBAAI,KAAK,gBAAgB;AACvB,sBAAM,wBAAwB,MAAM,KAAK;AAAA,kBACvC;AAAA,gBACF;AAEA,iCAAiB;AAAA,kBACf;AAAA,kBACA;AAAA,oBACE;AAAA,oBACA;AAAA,kBACF;AAAA,gBACF;AAAA,cACF;AAEA,kBAAI,KAAK,oBAAoB;AAC3B,sBAAM,4BAA4B,MAAM,QAAQ;AAAA,kBAC9C,KAAK,mBAAmB;AAAA,oBACtB,GAAG;AAAA,oBACH,YAAY;AAAA,kBACd,CAAC;AAAA,gBACH;AAEA,oBAAI,2BAA2B;AAC7B,mCAAiB;AAAA,oBACf;AAAA,oBACA;AAAA,sBACE;AAAA,sBACA;AAAA,oBACF;AAAA,kBACF;AAAA,gBACF;AAAA,cACF;AAAA,YACF;AAEA,gBAAI,CAAC,gBAAgB;AACnB;AAAA,YACF;AAEA,gBAAI,UAAU;AACZ,oBAAM,MAAM,IAAI,UAAU,cAAc;AAAA,YAC1C;AAEA,yBAAa,iBAAiB,YAAY,cAAc;AACxD,kBAAM,EAAE,WAAW,IAAI;AAEvB,gBAAID,QAAO,cAAc,aAAa,WAAW,SAAS,GAAG;AAC3D,iCAAmB;AAAA,YACrB;AAEA,gBAAI,YAAY;AACd,oBAAM,QAAQ;AAAA,gBACZ,WAAW;AAAA,kBACT,UAAU,QAAQ,gBAAgB;AAAA,kBAClC,SAAS,kBAAkB,QAAQ;AAAA,kBACnC,QAAQ;AAAA,gBACV,CAAC;AAAA,cACH;AAAA,YACF;AAEA,gBAAI,WAAW,SAAS,GAAG;AACzB,oBAAM,sBAAsB,SAAS,WAAW,MAAM,SAASE;AAAA,gBAC7D;AAAA,gBACA,WAAW;AAAA,cACb,CAAC;AACD,oBAAM,qBACJ,WAAW,WAAW,IAClB,KAAK;AAAA,kBACH,gBAAW,CAAC,MAAZ,mBAAe,kBAAe,gBAAW,CAAC,MAAZ,mBAAe;AAAA,gBAC7C,EAAE,WAAW,GAAG;AAAA,cAClB,CAAC,OACD;AACN,oBAAM,gBAAgB,CAAC,qBAAqB,kBAAkB,EAC3D,OAAO,OAAO,EACd,KAAK,GAAG;AAEX,cAAAH,MAAK,SAAS,aAAa;AAAA,YAC7B;AAAA,UACF,SAAS,KAAU;AACjB,kBAAM,QAAQ,IAAI;AAAA,cAChB,GAAG,kBAAkB,QAAQ,CAAC,sBAAsB,IAAI,OAAO;AAAA,cAC/D,EAAE,OAAO,IAAI;AAAA,YACf;AACA,oBAAQ,KAAK,KAAK;AAClB,4BAAgB;AAChB,qBAAS,KAAK,KAAK;AACnB,YAAAA,MAAK,SAAS,IAAI,OAAO;AAAA,UAC3B;AAAA,QACF;AAAA,MACF;AAEA,UAAI,gBAAgB;AAClB,YAAI,CAAC,eAAgB,WAAW,QAAQ;AACtC,qBAAW,MAAM;AAAA,QACnB;AAEA,sBAAc,YAAY,KAAK,cAAe;AAAA,MAChD,WAAW,CAAC,eAAe;AACzB,mBAAW,MAAM;AAAA,MACnB;AAEA,eAAS,QAAQ,MAAS;AAAA,IAC5B;AAAA,IACA;AAAA,MACE,aAAa,OAAO,cAAc;AAAA,IACpC;AAAA,EACF;AAEA,aAAW,YAAY,KAAK,IAAI;AAChC,SAAO;AACT;;;AI1iBA,OAAOI,SAAQ;AACf,OAAOC,WAAU;AAEjB,SAAS,iBAAiB,yBAAyB;AAmBnD,eAAsB,cAAc;AAAA,EAClC;AAAA,EACA;AACF,GAGwB;AA5BxB;AA6BE,QAAM,MAAM,iBAAiB,OAAO;AACpC,QAAM,cAAc,oBAAoB,KAAK,EAAE,OAAO,EAAE,CAAC;AAEzD,EAAAC;AAAA,IACE,YAAY,WAAW;AAAA,IACvB,8CAA8C,QAAQ;AAAA,EACxD;AAEA,QAAM,YAAY,iBAAiB,GAAG;AACtC,EAAAA;AAAA,IACE,YAAY,UAAU;AAAA,IACtB,6DAA6D,QAAQ;AAAA,EACvE;AAEA,QAAM,mBACJ,UAAU,WAAW,IACjB,sBAAqB,eAAU,CAAC,MAAX,mBAAc,KAAK,IACxC;AAEN,QAAM,kBAAkB,YAAY,CAAC;AACrC,MAAI,gBAAgB,eAAe,KAAK,eAAe;AACvD,QAAM,qBAAqB,sBAAsB,GAAG,EAAE;AAAA,IACpD,CAAC,aAAa,SAAS,SAAS,UAAU,SAAS,SAAS;AAAA,EAC9D;AACA,EAAAA;AAAA,IACE,mBAAmB,UAAU;AAAA,IAC7B,yDAAyD,QAAQ;AAAA,EACnE;AAEA,QAAM,gBAAgB,mBAAmB,CAAC;AAC1C,MAAI;AACJ,MAAI,eAAe;AACjB,cAAS,2BAAsB,aAAa,MAAnC,mBAAsC;AAC/C,oBAAgB,cAAc,OAAO,CAAC,SAAS,SAAS,aAAa;AAAA,EACvE;AAEA,QAAM,OAAO,cAAc;AAAA,IACzB;AAAA,IACA;AAAA,IACA;AAAA,IACA,aAAa;AAAA,MACX,GAAG;AAAA,MACH;AAAA,IACF;AAAA,EACF,CAAC;AAED,SAAO,aAAa,IAAI;AAC1B;AAEA,eAAsB,kBACpB,UACA;AAAA,EACE,MAAM,QAAQ,IAAI;AACpB,IAEI,CAAC,GACgB;AACrB,QAAM,mBAAmB,MAAMC,MAAK,QAAQ,KAAK,QAAQ,IAAI;AAC7D,QAAM,UAAU,MAAMC,IAAG,SAAS,kBAAkB,EAAE,UAAU,OAAO,CAAC;AAExE,SAAO,cAAc;AAAA,IACnB;AAAA,IACA;AAAA,EACF,CAAC;AACH;AAEO,SAAS,qBACd,MAC2C;AAC3C,MAAI,CAAC,MAAM;AACT;AAAA,EACF;AAEA,MAAI;AAGF,UAAM,WAAoC,kBAAkB,IAAI,EAAE,OAAO;AAEzE,UAAM,aAAa,qBAAqB,OAAO,EAAE,UAAU;AAAA,MACzD,MAAM;AAAA,MACN,OAAO;AAAA,MACP,GAAG;AAAA,IACL,CAAC;AAED,QAAI,CAAC,WAAW,SAAS;AACvB,YAAM,IAAI;AAAA,QACR,+CAA+C,WAAW,KAAK;AAAA,MACjE;AAAA,IACF;AAEA,UAAM,OAAO,WAAW;AACxB,WAAO,KAAK,MAAM,QAAQ,OAAO;AAAA,EACnC,SAAS,KAAU;AACjB,UAAM,IAAI,MAAM,mCAAmC,IAAI,OAAO,IAAI;AAAA,MAChE,OAAO;AAAA,IACT,CAAC;AAAA,EACH;AACF;;;AC9HA,OAAOC,SAAQ;AACf,OAAOC,WAAU;AAEjB,OAAOC,WAAU;AACjB,OAAOC,WAAU;;;ACJjB,OAAOC,SAAQ;AACf,OAAOC,WAAU;;;ACDjB,SAAS,wBAAwB;AAEjC,IAAM,2BAA2B;AAAA,EAC/B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAEA,eAAsB,aAAa,UAAoC;AACrE,MAAI;AACF,UAAM,WAAW,MAAM,iBAAiB,QAAQ;AAEhD,QAAI,CAAC,UAAU;AAEb,aAAO;AAAA,IACT;AAEA,eAAW,kBAAkB,0BAA0B;AACrD,UAAI,SAAS,KAAK,WAAW,cAAc,GAAG;AAE5C,eAAO;AAAA,MACT;AAAA,IACF;AAGA,WAAO;AAAA,EACT,SAAS,KAAU;AACjB,UAAM,IAAI,MAAM,uBAAuB,QAAQ,KAAK,IAAI,OAAO,IAAI;AAAA,MACjE,OAAO;AAAA,IACT,CAAC;AAAA,EACH;AACF;;;AD1BA,IAAM,0BAA0B,oBAAI,IAAI;AAAA,EACtC;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF,CAAC;AAED,eAAsB,kBACpB,UACA;AAAA,EACE,mBAAmB;AAAA,EACnB,mBAAmB;AACrB,IAGI,CAAC,GACa;AAClB,MAAI;AACF,QAAI,CAAC,UAAU;AAEb,aAAO;AAAA,IACT;AAEA,UAAM,WAAWC,MAAK,SAAS,QAAQ;AACvC,QAAI,CAAC,UAAU;AAEb,aAAO;AAAA,IACT;AAEA,QAAI,wBAAwB,IAAI,QAAQ,GAAG;AAEzC,aAAO;AAAA,IACT;AAEA,UAAM,QAAQ,MAAMC,IAAG,KAAK,QAAQ;AAEpC,QAAI,CAAC,MAAM,OAAO,GAAG;AAEnB,aAAO;AAAA,IACT;AAEA,QAAI,MAAM,QAAQ,kBAAkB;AAElC,aAAO;AAAA,IACT;AAEA,QAAI,MAAM,OAAO,kBAAkB;AAEjC,aAAO;AAAA,IACT;AAEA,QAAI,MAAM,aAAa,QAAQ,GAAG;AAEhC,aAAO;AAAA,IACT;AAGA,WAAO;AAAA,EACT,SAAS,KAAU;AACjB,UAAM,IAAI,MAAM,uBAAuB,QAAQ,KAAK,IAAI,OAAO,IAAI;AAAA,MACjE,OAAO;AAAA,IACT,CAAC;AAAA,EACH;AACF;;;AD1DA,eAAsB,aAAa;AAAA,EACjC;AAAA,EACA,MAAM,QAAQ,IAAI;AACpB,GAGG;AAGD,QAAM,kBAAkB,MAAM,wBAAwB,OAAO,OAAO;AAAA,IAClE,WAAW;AAAA,IACX,QAAQ,OAAO;AAAA,IACf;AAAA,EACF,CAAC;AAID,QAAM,cAAc,MAAM,gBAAgB,iBAAiB;AAAA,IACzD,aAAa,OAAO,cAAc;AAAA,EACpC,CAAC;AAED,SAAO;AACT;AAEA,eAAsB,iBAAiB;AAAA,EACrC;AAAA,EACA,MAAM,QAAQ,IAAI;AACpB,GAGG;AACD,QAAM,cAAc,MAAM,wBAAwB,OAAO,OAAO;AAAA,IAC9D,WAAW;AAAA,IACX,QAAQ,OAAO,QACZ,OAAO,CAAC,YAAY,CAAC,WAAW,KAAK,OAAO,CAAC,EAC7C,OAAO,CAAC,gBAAgB,QAAQ,QAAQ,QAAQ,OAAO,CAAC;AAAA,IAC3D;AAAA,EACF,CAAC;AAED,SAAO,gBAAgB,aAAa;AAAA,IAClC,aAAa,OAAO,cAAc;AAAA,EACpC,CAAC;AACH;AAEA,eAAsB,gBACpB,WACA;AAAA,EACE,cAAc;AAAA,EACd,MAAM,QAAQ,IAAI;AAAA,EAClB;AAAA,EACA;AAAA,EACA,kBAAkB;AAAA,EAClB,oBAAoB;AACtB,IAOI,CAAC,GACwB;AAE7B,YAAU,KAAK,CAAC,GAAG,MAAM,EAAE,cAAc,CAAC,CAAC;AAE3C,UACE,MAAMC;AAAA,IACJ;AAAA,IACA,OAAO,aAAa;AA/E1B;AAgFQ,iBAAWC,MAAK,QAAQ,KAAK,QAAQ;AAErC,UACE,CAAE,MAAM,kBAAkB,UAAU;AAAA,QAClC;AAAA,QACA;AAAA,MACF,CAAC,GACD;AAEA,gBAAQ,KAAK,iCAAiC,QAAQ,EAAE;AACxD;AAAA,MACF;AAEA,UAAI,UAAU,MAAMC,IAAG,SAAS,UAAU,EAAE,UAAU,OAAO,CAAC;AAC9D,UAAI,CAAC,QAAQ,KAAK,GAAG;AAEnB,gBAAQ,KAAK,+BAA+B,QAAQ,EAAE;AACtD;AAAA,MACF;AAEA,UAAI,QAAQ,QAAQ,MAAM,OAAO;AAEjC,UAAI,MAAM,SAAS,iBAAiB;AAElC,gBAAQ;AAAA,UACN,6CAA6C,QAAQ,KAAK,MAAM,MAAM,sCAAsC,eAAe;AAAA,QAC7H;AACA;AAAA,MACF;AAEA,UAAI,eAAe;AACnB,cAAQ,MAAM,IAAI,CAAC,SAAS;AAC1B,YAAI,KAAK,SAAS,mBAAmB;AACnC,YAAE;AAGF,iBAAO,KAAK,MAAM,GAAG,iBAAiB;AAAA,QACxC,OAAO;AACL,iBAAO;AAAA,QACT;AAAA,MACF,CAAC;AAED,UAAI,eAAe,GAAG;AAEpB,gBAAQ;AAAA,UACN,6BAA6B,YAAY,SAASC,MAAK,QAAQ,YAAY,CAAC,KAAK,QAAQ,8BAA8B,iBAAiB;AAAA,QAC1I;AACA;AAAA,MACF;AAEA,UAAI,eAAe,GAAG;AACpB,kBAAU,MAAM,KAAK,IAAI;AAAA,MAC3B;AAEA,YAAM,mBAAmBF,MAAK,SAAS,KAAK,QAAQ;AACpD,YAAM,WAAWA,MAAK,SAAS,QAAQ;AACvC,YAAM,QAAM,cAAS,MAAM,GAAG,EAAE,GAAG,EAAE,MAAzB,mBAA4B,kBAAiB;AACzD,YAAM,eAAe,oBAAI,IAAI,CAAC,MAAM,OAAO,OAAO,KAAK,CAAC;AACxD,YAAM,eAAe,oBAAI,IAAI,CAAC,MAAM,KAAK,CAAC;AAG1C,YAAM,WAAW,aAAa,IAAI,GAAG,IACjC,eACA,aAAa,IAAI,GAAG,IAClB,eACA;AAEN,aAAO;AAAA,QACL;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACF;AAAA,IACF;AAAA,IACA;AAAA,MACE;AAAA,IACF;AAAA,EACF,GACA,OAAO,OAAO;AAClB;;;AGhKA,OAAOG,SAAQ;AACf,OAAOC,WAAU;AAEjB,OAAOC,WAAU;AAOjB,eAAsB,aAAa;AAAA,EACjC;AAAA,EACA,MAAM,QAAQ,IAAI;AACpB,GAG0B;AACxB,QAAM,gBAAgB,MAAM,wBAAwB,OAAO,aAAa,CAAC,GAAG;AAAA,IAC1E,WAAW;AAAA,IACX;AAAA,EACF,CAAC;AAGD,QAAM,yBAAyB,oBAAI,IAAY;AAG/C,MAAI,SACF,MAAMC;AAAA,IACJ;AAAA,IACA,OAAO,iBAAiB;AACtB,UAAI;AACF,YAAI,uBAAuB,IAAI,YAAY,GAAG;AAC5C;AAAA,QACF;AACA,+BAAuB,IAAI,YAAY;AAEvC,cAAM,uBAAuBC,MAAK,KAAK,KAAK,YAAY;AACxD,cAAM,kBAAkB,MAAMC,IAAG;AAAA,UAC/B;AAAA,UACA;AAAA,QACF;AACA,cAAM,OAAO,MAAM,cAAc;AAAA,UAC/B,SAAS;AAAA,UACT,UAAU;AAAA,QACZ,CAAC;AAED,eAAO;AAAA,MACT,SAAS,KAAU;AACjB,cAAM,IAAI;AAAA,UACR,4BAA4B,YAAY,MAAM,IAAI,OAAO;AAAA,UACzD,EAAE,OAAO,IAAI;AAAA,QACf;AAAA,MACF;AAAA,IACF;AAAA,IACA;AAAA,MACE,aAAa,OAAO,cAAc;AAAA,IACpC;AAAA,EACF,GACA,OAAO,OAAO;AAEhB,QAAM,eAA6B,OAAO,mBAAmB,CAAC,GAAG;AAAA,IAC/D,CAAC,mBAAmB;AAClB,YAAM,OAAmB;AAAA,QACvB,QAAQ;AAAA,QACR,WAAW;AAAA,QACX,GAAG;AAAA,QACH,UAAU,CAAC;AAAA,MACb;AAEA,MAAAC,SAAO,gBAAgB,KAAK,IAAI,GAAG,sBAAsB,KAAK,IAAI,GAAG;AACrE,aAAO;AAAA,IACT;AAAA,EACF;AAIA,UAAQ,YAAY,OAAO,KAAK;AAEhC,QAAM,iBAAiB,oBAAI,IAAY;AAEvC,UAAQ,MAAM,OAAO,CAAC,SAAS;AAC7B,WAAO,aAAa,IAAI;AAExB,QAAI,eAAe,IAAI,KAAK,IAAI,GAAG;AACjC,aAAO;AAAA,IACT;AAEA,mBAAe,IAAI,KAAK,IAAI;AAC5B,WAAO;AAAA,EACT,CAAC;AAED,MAAI,OAAO,OAAO;AAGhB,YAAQ,MAAM,OAAO,CAAC,SAAS,OAAO,MAAM,KAAK,IAAI,MAAM,KAAK;AAAA,EAClE;AAEA,SAAO;AACT;","names":["default","alias","path","z","default","z","path","ruleDefinitions","default","plur","path","path","matches","default","partialSourceFileMap","toString","z","path","default","path","index","z","z","z","toString","plur","plur","default","default","default","default","task","config","_a","plur","fs","path","default","path","fs","fs","path","pMap","plur","fs","path","path","fs","pMap","path","fs","plur","fs","path","pMap","pMap","path","fs","default"]}