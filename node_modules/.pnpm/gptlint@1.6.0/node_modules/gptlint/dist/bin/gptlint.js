#!/usr/bin/env node
var __defProp = Object.defineProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};

// bin/gptlint.ts
import "dotenv/config";
import chalk2 from "chalk";
import { gracefulExit as gracefulExit3 } from "exit-hook";
import plur6 from "plur";
import restoreCursor from "restore-cursor";

// src/cache.ts
import fsSync from "node:fs";
import fs from "node:fs/promises";
import path2 from "node:path";
import { asyncExitHook } from "exit-hook";
import stableStringify from "fast-json-stable-stringify";
import hashObject from "hash-object";
import { pathExists } from "path-exists";

// src/utils.ts
import path from "node:path";
import { fileURLToPath } from "node:url";
import chalk from "chalk";
import { gracefulExit } from "exit-hook";
import { globby } from "globby";
import multimatch from "multimatch";

// src/lint-result.ts
function createLintResult(partialLintResult) {
  return {
    lintErrors: [],
    skipped: false,
    numModelCalls: 0,
    numModelCallsCached: 0,
    numPromptTokens: 0,
    numCompletionTokens: 0,
    numTotalTokens: 0,
    totalCost: 0,
    startedAtMs: Date.now(),
    ...partialLintResult
  };
}
function mergeLintResults(lintResultA, lintResultB) {
  return {
    lintErrors: lintResultA.lintErrors.concat(lintResultB.lintErrors),
    skipped: lintResultA.skipped || lintResultB.skipped,
    skipReason: lintResultB.skipReason ?? lintResultA.skipReason,
    skipDetail: lintResultB.skipDetail ?? lintResultA.skipDetail,
    message: lintResultB.message ?? lintResultA.message,
    numModelCalls: lintResultA.numModelCalls + lintResultB.numModelCalls,
    numModelCallsCached: lintResultA.numModelCallsCached + lintResultB.numModelCallsCached,
    numPromptTokens: lintResultA.numPromptTokens + lintResultB.numPromptTokens,
    numCompletionTokens: lintResultA.numCompletionTokens + lintResultB.numCompletionTokens,
    numTotalTokens: lintResultA.numTotalTokens + lintResultB.numTotalTokens,
    totalCost: lintResultA.totalCost + lintResultB.totalCost,
    startedAtMs: Math.min(lintResultA.startedAtMs, lintResultB.startedAtMs),
    endedAtMs: lintResultA.endedAtMs !== void 0 && lintResultB.endedAtMs !== void 0 ? Math.max(lintResultA.endedAtMs, lintResultB.endedAtMs) : lintResultB.endedAtMs ?? lintResultB.endedAtMs
  };
}
function getLintDurationMs(lintResult) {
  if (lintResult.endedAtMs === void 0) return void 0;
  return Math.max(0, lintResult.endedAtMs - lintResult.startedAtMs);
}
function resolvePartialLintResult(partialLintResult, {
  rule,
  file,
  filePath,
  language,
  model
}) {
  var _a;
  return createLintResult({
    ...partialLintResult,
    lintErrors: ((_a = partialLintResult == null ? void 0 : partialLintResult.lintErrors) == null ? void 0 : _a.map(
      (partialLintError) => ({
        model,
        level: rule.level,
        filePath,
        language,
        ...partialLintError,
        ruleName: rule.name,
        ...file ? pruneUndefined({
          filePath: file.fileRelativePath,
          language: file.language
        }) : {}
      })
    )) ?? []
  });
}
function dedupeLintErrors(lintErrors) {
  const lintErrorsMap = /* @__PURE__ */ new Map();
  return lintErrors.filter((lintError) => {
    const key = JSON.stringify(
      pruneUndefined({
        ruleName: lintError.ruleName,
        filePath: lintError.filePath,
        codeSnippet: lintError.codeSnippet,
        message: lintError.message
      })
    );
    if (lintErrorsMap.has(key)) {
      return false;
    }
    lintErrorsMap.set(key, lintError);
    return true;
  });
}

// src/utils.ts
import { default as default2 } from "@sindresorhus/slugify";
import { default as default3 } from "array-uniq";
import { default as default4 } from "tiny-invariant";
var omit = (inputObj, ...keys) => {
  const keysSet = new Set(keys);
  return Object.fromEntries(
    Object.entries(inputObj).filter(([k]) => !keysSet.has(k))
  );
};
var pick = (inputObj, ...keys) => {
  const keysSet = new Set(keys);
  return Object.fromEntries(
    Object.entries(inputObj).filter(([k]) => keysSet.has(k))
  );
};
function pruneUndefined(obj) {
  return Object.fromEntries(
    Object.entries(obj).filter(([, value]) => value !== void 0)
  );
}
function trimMessage(message, { maxLength = 80 } = {}) {
  if (!message) return "";
  message = message.trim().split("\n")[0].trim();
  if (message.length < maxLength) return message;
  message = `${message.slice(0, maxLength - 3)}...`;
  return message;
}
function getEnv(name, defaultValue) {
  var _a;
  try {
    return (typeof process !== "undefined" ? (
      // eslint-disable-next-line no-process-env
      (_a = process.env) == null ? void 0 : _a[name]
    ) : void 0) ?? defaultValue;
  } catch {
    return defaultValue;
  }
}
function logDebugConfig({
  files,
  rules,
  config
}) {
  console.log(
    `
${chalk.italic("logging resolved config and then exiting because `printConfig` is enabled")}`
  );
  const sanitizedConfig = config.getSanitizedDebugConfig();
  console.log(
    `
${chalk.bold("config")}`,
    JSON.stringify(sanitizedConfig, void 0, 2)
  );
  if (rules) {
    if (rules.length) {
      console.log(
        `
${chalk.bold("rules")}`,
        JSON.stringify(
          rules.map((rule) => ({
            ...rule,
            title: rule.title ? trimMessage(rule.title) : void 0,
            description: rule.description ? trimMessage(rule.description) : void 0,
            gritql: rule.gritql ? trimMessage(rule.gritql) : void 0,
            negativeExamples: rule.negativeExamples ? rule.negativeExamples.map((e) => ({
              ...e,
              code: trimMessage(e.code)
            })) : void 0,
            positiveExamples: rule.positiveExamples ? rule.positiveExamples.map((e) => ({
              ...e,
              code: trimMessage(e.code)
            })) : void 0
          })),
          void 0,
          2
        )
      );
    } else {
      console.warn(`
${chalk.bold("warning: no rules found")}`);
    }
  }
  if (files) {
    if (files.length) {
      console.log(
        `
${chalk.bold("input files")}`,
        JSON.stringify(
          files.map((file) => file.fileRelativePath),
          void 0,
          2
        )
      );
    } else {
      console.warn(`
${chalk.bold("warning: no input source files found")}`);
    }
  }
}
function logLintResultStats({
  lintResult,
  config,
  prefix
}) {
  const lintDurationMs = getLintDurationMs(lintResult);
  const lintDuration = lintDurationMs ? `${Math.ceil(lintDurationMs / 1e3)}s` : void 0;
  console.log(
    `${prefix ?? ""}Linter stats; ${config.linterOptions.dryRun ? "dry run estimated cost" : "total cost"} $${(lintResult.totalCost / 100).toFixed(2)}`,
    pruneUndefined({
      ...pick(config.llmOptions, "model", "weakModel"),
      ...pick(
        lintResult,
        "numModelCalls",
        "numModelCallsCached",
        "numPromptTokens",
        "numCompletionTokens",
        "numTotalTokens"
      ),
      lintDuration
    })
  );
}
function createPromiseWithResolvers() {
  let resolve;
  let reject;
  const promise = new Promise((res, rej) => {
    resolve = res;
    reject = rej;
  });
  return { promise, resolve, reject };
}
async function resolveGlobFilePatterns(patternOrPatterns, options) {
  const patterns = Array.isArray(patternOrPatterns) ? patternOrPatterns : [patternOrPatterns];
  const invalidPatterns = patterns.filter((pattern) => !pattern);
  if (invalidPatterns.length) {
    throw new Error(
      `Invalid file glob empty pattern: "${invalidPatterns.join(", ")}"`
    );
  }
  options = {
    followSymbolicLinks: false,
    ...options
  };
  const cwd = (options == null ? void 0 : options.cwd) ?? process.cwd();
  const absolutePatterns = patterns.filter((pattern) => path.isAbsolute(pattern) || pattern.startsWith("..")).map((pattern) => path.relative(cwd, pattern));
  const relativePatterns = patterns.filter(
    (pattern) => !(path.isAbsolute(pattern) || pattern.startsWith(".."))
  ).map((pattern) => path.relative(cwd, pattern));
  for (const pattern of absolutePatterns) {
    if (/\*/.test(pattern)) {
      throw new Error(
        `File globs must be local to cwd or not use "*" glob syntax: ${pattern}`
      );
    }
  }
  try {
    const resolvedFilePatterns = await globby(relativePatterns, options);
    return absolutePatterns.concat(resolvedFilePatterns);
  } catch (err) {
    console.error("error resolving glob patterns:", err.message);
    throw err;
  }
}
function dirname(meta = import.meta) {
  return meta.dirname ?? path.dirname(fileURLToPath(meta.url));
}
function fileMatchesIncludeExclude(file, {
  include,
  exclude
}) {
  if (include) {
    const matches = multimatch(file.fileRelativePath, include);
    if (!matches.length) {
      return false;
    }
  }
  if (exclude == null ? void 0 : exclude.length) {
    const matches = multimatch(file.fileRelativePath, exclude);
    if (matches.length) {
      return false;
    }
  }
  return true;
}
function validateLinterInputs({
  config,
  files,
  rules
}) {
  if (config.linterOptions.printConfig) {
    logDebugConfig({ files, rules, config });
    gracefulExit(0);
    return false;
  }
  if (files && !files.length) {
    console.error(
      `
${chalk.bold("Error: no source files found")} (${chalk.italic("run with --print-config to debug")})
`
    );
    gracefulExit(1);
    return false;
  }
  if (rules && !rules.length) {
    console.error(
      `
${chalk.bold("Error: no rules enabled")} (${chalk.italic("run with --print-config to debug")})
`
    );
    console.error(
      "\nNote: If you want to use the built-in rules with a custom config file, you must enable tem explicitly: https://gptlint.dev/guide/config#config-file\n"
    );
    gracefulExit(1);
    return false;
  }
  return true;
}

// src/cache.ts
var LinterCache = class {
  noCache;
  dryRun;
  cacheDir;
  cacheFile;
  cache;
  _exitHookCleanupFn;
  constructor({
    cacheDir,
    cacheFileName = "cache.json",
    noCache = false,
    dryRun = false
  }) {
    this.cacheDir = cacheDir;
    this.noCache = !!noCache;
    this.dryRun = !!dryRun;
    this.cacheFile = this.cacheDir ? path2.join(this.cacheDir, cacheFileName) : void 0;
    this._exitHookCleanupFn = asyncExitHook(() => this.close(), {
      wait: 1e3
    });
  }
  async init() {
    if (this.cache) return this;
    this.cache = {};
    if (!this.cacheDir) {
      return this;
    }
    const cacheFile = this.cacheFile;
    try {
      await fs.mkdir(this.cacheDir, { recursive: true });
      if (await pathExists(cacheFile)) {
        const encodedCache = fsSync.readFileSync(cacheFile, {
          encoding: "utf8"
        });
        this.cache = JSON.parse(encodedCache);
      }
    } catch (err) {
      console.warn(
        `Failed to initialize cache "${cacheFile}". Continuing with empty cache.`,
        err.message
      );
    }
    return this;
  }
  async close() {
    if (this._exitHookCleanupFn) {
      this.flush();
      delete this.cache;
      delete this._exitHookCleanupFn;
    }
  }
  async get(key) {
    if (this.noCache) return;
    default4(this.cache, "Must call LinterCache.init");
    const encodedValue = this.cache[key];
    if (encodedValue === void 0) {
      return void 0;
    } else {
      const decodedValue = JSON.parse(encodedValue);
      return decodedValue;
    }
  }
  async set(key, value) {
    default4(this.cache, "Must call LinterCache.init");
    const encodedValue = JSON.stringify(value);
    this.cache[key] = encodedValue;
    await this.flush();
  }
  async flush() {
    if (!this.cache || this.dryRun) return;
    const cacheFile = this.cacheFile;
    if (cacheFile) {
      await fs.mkdir(this.cacheDir, { recursive: true });
      if (!this.cache) return;
      fsSync.writeFileSync(cacheFile, stableStringify(this.cache), {
        encoding: "utf8"
      });
    }
  }
};
async function createLinterCache(config) {
  const cache = new LinterCache({
    cacheDir: config.linterOptions.cacheDir,
    noCache: config.linterOptions.noCache,
    dryRun: config.linterOptions.dryRun
  });
  await cache.init();
  return cache;
}
function createCacheKey({
  rule,
  file,
  config,
  ...extra
}) {
  const cacheKeySource = pruneUndefined({
    ...extra,
    file: file ? (
      // Only keep the relative file path, content, and detected language
      pruneUndefined(pick(file, "fileRelativePath", "content", "language"))
    ) : void 0,
    // Only keep the rule fields which affect the linting logic
    rule: pruneUndefined(
      pick(
        rule,
        "name",
        "title",
        "description",
        "positiveExamples",
        "negativeExamples",
        "level",
        "scope",
        "model",
        "languages",
        "gritql",
        "gritqlNumLinesContext"
        // TODO: include / exclude? languages?
      )
    ),
    // Ensure the cache key depends on how the LLM is parameterized
    llmOptions: pruneUndefined(
      pick(
        config.llmOptions ?? {},
        "model",
        "weakModel",
        "temperature",
        "apiBaseUrl"
      )
    ),
    linterOptions: pruneUndefined(pick(config.linterOptions ?? {}, "noGrit"))
  });
  return hashObject(cacheKeySource);
}

// src/create-chat-model.ts
import { ChatModel, createOpenAIClient } from "@dexaai/dexter";
function createChatModel(config) {
  const { llmOptions, linterOptions } = config;
  default4(llmOptions);
  default4(linterOptions);
  const client = createOpenAIClient({
    apiKey: llmOptions.apiKey,
    organizationId: llmOptions.apiOrganizationId,
    baseUrl: llmOptions.apiBaseUrl,
    kyOptions: llmOptions.kyOptions
  });
  if (config.linterOptions.dryRun) {
    client.createChatCompletion = createChatCompletionDryRun;
  }
  return new ChatModel({
    client,
    params: {
      model: llmOptions.model,
      temperature: llmOptions.temperature
    },
    debug: !!linterOptions.debugModel
  });
}
async function createChatCompletionDryRun(params, _opts) {
  const inputMessageText = params.messages.map((m) => m.content).join("\n");
  const output = `# EXPLANATION

This is a fake LLM response because the \`dryRun\` option was set. No actual API request was made.

# VIOLATIONS

\`\`\`json
[]
\`\`\`
`;
  const numPromptTokensEstimate = Math.ceil(inputMessageText.length / 3);
  const numCompletionTokensEstimate = 120;
  const numTotalTokensEstimate = numPromptTokensEstimate + numCompletionTokensEstimate;
  return {
    id: "chat:dry-run-id",
    object: "chat.completion",
    created: Math.floor(Date.now() / 1e3),
    model: params.model,
    system_fingerprint: "dry-run-fingerprint",
    choices: [
      {
        finish_reason: "stop",
        logprobs: null,
        index: 0,
        message: {
          role: "assistant",
          content: output
        }
      }
    ],
    usage: {
      prompt_tokens: numPromptTokensEstimate,
      completion_tokens: numCompletionTokensEstimate,
      total_tokens: numTotalTokensEstimate
    }
  };
}

// src/lint-files.ts
import pMap from "p-map";
import plur3 from "plur";
import task from "tasuku";

// src/gritql.ts
import fs2 from "node:fs/promises";
import path3 from "node:path";
import { execa } from "execa";
import { packageDirectory } from "pkg-dir";
import plur from "plur";
import which from "which";

// src/constants.ts
var minSourceFileSizeBytes = 0;
var maxSourceFileSizeBytes = 200 * 1024;
var maxSourceFileNumLines = 1e4;
var maxSourceFileLineLength = 1024;
var gritNumLinesContext = 0;
var defaultFiles = ["**/*.{js,ts,jsx,tsx,cjs,mjs}"];

// src/gritql.ts
async function resolveGritQLPattern(pattern, {
  files,
  numLinesContext = gritNumLinesContext
}) {
  if (!await hasGrit()) {
    return /* @__PURE__ */ new Map();
  }
  const matches = await applyGritQLPattern(pattern, { files });
  return resolveGritQLMatches(matches, { files, numLinesContext });
}
async function applyGritQLPattern(pattern, {
  files
}) {
  const gritBinary = await whichGritBinary();
  if (!gritBinary) {
    throw new Error(`Could not find 'grit' binary in $PATH`);
  }
  const paths = files.map((file) => file.filePath);
  const res = await execa(gritBinary, [
    "apply",
    "--dry-run",
    "--jsonl",
    pattern,
    ...paths
  ]);
  const lines = res.stdout.split("\n").map((line) => line.trim()).filter(Boolean);
  const gritMatches = lines.map((line) => {
    try {
      const potentialMatch = JSON.parse(line);
      if ((potentialMatch == null ? void 0 : potentialMatch.__typename) !== "Match") {
        return void 0;
      }
      const { debug: _, ...match } = potentialMatch;
      return match;
    } catch {
      return void 0;
    }
  }).filter(Boolean);
  return gritMatches;
}
async function hasGrit() {
  const gritBinary = await whichGritBinary();
  return !!gritBinary;
}
async function whichGritBinary() {
  const gritBinary = await which("grit", { nothrow: true });
  if (gritBinary) return gritBinary;
  const pkgDir = await packageDirectory({
    cwd: dirname()
  });
  if (!pkgDir) return null;
  const maybeLocalGritBinary = path3.resolve(
    pkgDir,
    "node_modules",
    ".bin",
    "grit"
  );
  try {
    await fs2.access(maybeLocalGritBinary, fs2.constants.R_OK | fs2.constants.X_OK);
    return maybeLocalGritBinary;
  } catch {
    return null;
  }
}
function resolveGritQLMatches(matches, {
  files,
  numLinesContext = gritNumLinesContext
}) {
  const matchesByFilePath = /* @__PURE__ */ new Map();
  for (const match of matches) {
    if (!matchesByFilePath.has(match.sourceFile)) {
      matchesByFilePath.set(match.sourceFile, []);
    }
    matchesByFilePath.get(match.sourceFile).push(match);
  }
  const partialFilesByFilePath = /* @__PURE__ */ new Map();
  for (const file of files) {
    const { filePath } = file;
    if (!partialFilesByFilePath.has(filePath)) {
      partialFilesByFilePath.set(filePath, {
        ...file,
        ranges: [],
        partialContent: ""
      });
    }
  }
  for (const [filePath, matches2] of matchesByFilePath.entries()) {
    const partialFile = partialFilesByFilePath.get(filePath);
    default4(partialFile);
    const matchRanges = matches2.flatMap(
      (m) => {
        var _a;
        return ((_a = m.variables.find((v) => v.name === "$match")) == null ? void 0 : _a.ranges) ?? m.ranges;
      }
    );
    partialFile.ranges = partialFile.ranges.concat(matchRanges).sort((a, b) => a.start.line - b.start.line);
  }
  for (const partialFile of partialFilesByFilePath.values()) {
    const lines = partialFile.content.split("\n");
    const { ranges } = partialFile;
    let partialContentLines = [];
    let maxLine = -1;
    for (const range of ranges) {
      const startLine = Math.max(
        Math.max(0, maxLine),
        range.start.line - 1 - numLinesContext
      );
      const endLine = range.end.line + numLinesContext;
      if (startLine >= endLine) continue;
      maxLine = Math.max(endLine, maxLine);
      const partialLines = lines.slice(startLine, endLine);
      partialContentLines = partialContentLines.concat(partialLines);
    }
    partialFile.partialContent = partialContentLines.join("\n").trim();
  }
  return partialFilesByFilePath;
}
async function preProcessFileWithGrit({
  file,
  files,
  rule,
  config,
  ruleNameToPartialSourceFileMap
}) {
  if (!rule.gritql || config.linterOptions.noGrit) {
    return;
  }
  if (!ruleNameToPartialSourceFileMap.has(rule.name)) {
    const partialSourceFileMapP = resolveGritQLPattern(rule.gritql, {
      files: files ?? [file],
      numLinesContext: rule.gritqlNumLinesContext
    });
    ruleNameToPartialSourceFileMap.set(rule.name, partialSourceFileMapP);
    const partialSourceFileMap2 = await partialSourceFileMapP;
    if (config.linterOptions.debugGrit) {
      console.log(
        `rule ${rule.name} gritql matches:

${[
          ...partialSourceFileMap2.values()
        ].map(
          (f) => {
            var _a, _b;
            return `  ${f.fileRelativePath} found ${((_a = f.ranges) == null ? void 0 : _a.length) || 0} ${plur("match", ((_b = f.ranges) == null ? void 0 : _b.length) || 0)}`;
          }
        ).join("\n\n")}

`
      );
    }
  }
  const partialSourceFileMap = await ruleNameToPartialSourceFileMap.get(
    rule.name
  );
  const partialSourceFile = partialSourceFileMap.get(file.filePath);
  if (!partialSourceFile) {
    return;
  }
  file.ranges = partialSourceFile.ranges;
  file.partialContent = partialSourceFile.partialContent.trim();
  if (!file.ranges.length || !file.partialContent) {
    return createLintResult({
      skipped: true,
      skipReason: "grit-pattern",
      skipDetail: "no gritql matches"
    });
  }
}

// src/lint-file.ts
import { Msg } from "@dexaai/dexter";
import plur2 from "plur";

// src/config.ts
import path4 from "node:path";
import findCacheDirectory from "find-cache-dir";
import { z as z2 } from "zod";

// src/rule.ts
import { z } from "zod";

// src/rule-utils.ts
function stringifyRuleForModel(rule) {
  var _a, _b, _c, _d;
  return `<RULE ${rule.name}>

# ${rule.title}

${rule.description ?? ""}

${((_a = rule.negativeExamples) == null ? void 0 : _a.length) ? "<INCORRECT EXAMPLES>\n\nThese are examples of bad code snippets which would VIOLATE this rule if they appear in the SOURCE:\n\n" : ""}
${stringifyExamples(rule.negativeExamples)}
${((_b = rule.negativeExamples) == null ? void 0 : _b.length) ? "</INCORRECT EXAMPLES>" : ""}

${((_c = rule.positiveExamples) == null ? void 0 : _c.length) ? "<CORRECT EXAMPLES>\n\nThese are examples of good code snippets which conform to this rule and should be ignored in the SOURCE:\n\n" : ""}
${stringifyExamples(rule.positiveExamples)}
${((_d = rule.positiveExamples) == null ? void 0 : _d.length) ? "</CORRECT EXAMPLES>" : ""}

</RULE ${rule.name}>
`;
}
function stringifyExamples(examples) {
  return examples ? examples.map(
    (example) => `\`\`\`${example.language ?? ""}
${example.code}
\`\`\``
  ).join("\n\n") : "";
}
function validateRule(ruleDefinition) {
  var _a;
  const name = (ruleDefinition == null ? void 0 : ruleDefinition.name) || "unknown";
  const parsedRule = RuleDefinitionSchema.passthrough().safeParse(ruleDefinition);
  default4(
    parsedRule.success,
    `Invalid rule "${name}": ${(_a = parsedRule.error) == null ? void 0 : _a.message}`
  );
  const rule = {
    source: "custom",
    cacheable: true,
    metadata: {},
    ...parsedRule.data
  };
  default4(isValidRuleName(rule.name), `Invalid rule name "${name}"`);
  default4(
    isValidRuleScope(rule.scope),
    `Invalid rule scope "${rule.scope}" for rule "${rule.name}"`
  );
  default4(
    isValidRuleSetting(rule.level),
    `Invalid rule level "${rule.level}" for rule "${rule.name}"`
  );
  if (rule.scope !== "file") {
    default4(
      rule.gritql === void 0,
      `Rule "${rule.name}" with scope "${rule.scope}" cannot have a "gritql" pattern because they are only supported for "file" scoped rules.`
    );
  }
  return rule;
}
function isValidRuleName(name) {
  if (!name) return false;
  if (name.toLowerCase() !== name) return false;
  const parts = name.split("/");
  if (parts.length === 2) {
    if (!/^@[a-z][\w-]*$/i.test(parts[0])) return false;
    if (!/^[a-z][\w-]*$/i.test(parts[1])) return false;
  } else if (!/^[a-z][\w-]*$/i.test(name)) return false;
  return true;
}
function isValidRuleSetting(value) {
  if (!value) return false;
  if (value.toLowerCase() !== value) return false;
  return value === "off" || value === "warn" || value === "error";
}
function isValidRuleScope(value) {
  if (!value) return false;
  if (value.toLowerCase() !== value) return false;
  return value === "file" || value === "project" || value === "repo";
}

// src/rule.ts
var RuleDefinitionExampleSchema = z.object({
  code: z.string().describe("Example code."),
  language: z.string().optional().describe("Language of the example code snippet.")
}).strict();
var RuleDefinitionSchema = z.object({
  name: z.string().refine((name) => isValidRuleName(name)).describe(
    "Primary identifier for the rule. Uses lowercase kebab-case. Examples: 'consistent-identifier-casing' and '@foo/bar'."
  ),
  title: z.string().describe(
    "A short, human-readable title for the rule. Defaults to the name if not set."
  ),
  description: z.string().optional().describe(
    "Longer description of the rule which is passed to the linting engine's LLM as part of the rule's prompt. Accepts Markdown."
  ),
  positiveExamples: z.array(RuleDefinitionExampleSchema).optional().describe("Example code snippets which correctly conform to the rule."),
  negativeExamples: z.array(RuleDefinitionExampleSchema).optional().describe("Example code snippets which violate to the rule."),
  fixable: z.boolean().optional().describe("Whether or not this rule is auto-fixable."),
  cacheable: z.boolean().optional().describe("Whether or not this rule should be cached."),
  level: z.enum(["off", "warn", "error"]).optional().default("error").describe("Default rule severity."),
  scope: z.enum(["file", "project", "repo"]).optional().default("file").describe("Granularity at which this rule is applied."),
  languages: z.array(z.string()).optional().describe(
    "Programming languages this rule should be restricted to. If empty, this rule will apply to all languages."
  ),
  tags: z.array(z.string()).optional().describe(
    "An optional array of tags / labels to associate with this rule."
  ),
  eslint: z.array(z.string()).optional().describe(
    "An optional array of `eslint` rule identifiers which are related to this rule."
  ),
  resources: z.array(z.string()).optional().describe(
    "An optional array of URLs which give more detail around this rule's intent."
  ),
  model: z.string().optional().describe(
    "Specific model to use for this rule. Useful for using a fine-tuned model which is specfic to a single rule. If a `model` is given, it will override the general config's `model` and `weakModel` when enforcing this rule with the built-in LLM-based linting engine."
  ),
  include: z.array(z.string()).optional().describe(
    "An optional array of file glob patterns to include when enforcing this rule. If not specified, will operate on all input source files not excluded by `exclude`."
  ),
  exclude: z.array(z.string()).optional().describe(
    "An optional array of file glob patterns to ignore when enforcing this rule."
  ),
  gritql: z.string().optional().describe(
    "An optional GritQL pattern to filter source code by for this rule."
  ),
  gritqlNumLinesContext: z.number().optional().describe(
    "Number of lines before & after GritQL matches to include in the context sent to the LLM. Defaults to 0."
  ),
  preProcessFile: z.function(z.tuple([z.any()]), z.any()).optional().describe(
    "Optional pre-processing linter logic specific to this rule. Will be run after the built-in pre-processing logic which handles caching and validation."
  ),
  processFile: z.function(z.tuple([z.any()]), z.any()).optional().describe(
    "Optional file processing / linting logic specific to this rule. If provided, this will **override** the default LLM-based file linting engine and is intended to be an escape hatch for fully customizing the linting logic for rules which aren't a good fit for LLM-based linting. If you still want to use the built-in LLM-based linting and just want to customize it's functionality, consider using `preProcessFile` or `postProcessFile` instead."
  ),
  postProcessFile: z.function(z.tuple([z.any()]), z.any()).optional().describe(
    "Optional post-processing linter logic specific to this rule. Will be run after the built-in post-processing logic. Useful for customizing the linting results in a rule-specific way such as pruning common false positives."
  ),
  preProcessProject: z.function(z.tuple([z.any()]), z.any()).optional().describe(
    "Optional pre-processing linter logic specific to this rule. Will be run after the built-in pre-processing logic which handles caching and validation."
  ),
  processProject: z.function(z.tuple([z.any()]), z.any()).optional().describe(
    "Optional project processing / linting logic specific to this rule."
  ),
  postProcessProject: z.function(z.tuple([z.any()]), z.any()).optional().describe(
    "Optional post-processing linter logic specific to this rule. Will be run after the built-in post-processing logic. Useful for customizing the linting results in a rule-specific way such as pruning common false positives."
  ),
  source: z.string().optional()
}).passthrough();

// src/config.ts
var LinterConfigRuleSettingSchema = z2.enum(["off", "warn", "error"]);
var LinterConfigRuleSettingsSchema = z2.record(
  z2.string(),
  LinterConfigRuleSettingSchema
);
var defaultCacheDir = findCacheDirectory({ name: "gptlint" }) ?? path4.join(".gptlint", "cache");
var LLMOptionsSchema = z2.object({
  model: z2.string().optional().describe("Which LLM to use for assessing rule conformance."),
  weakModel: z2.string().optional().nullable().describe(
    'If defined, will use a two-pass approach for assessing rule conformance. The `weakModel` should be cheaper and will be used to generate potential rule violations, with the stronger `model` being used in a second pass to validate these potential rule violations and filter out false positives. Set to "none" or `null` to disable two-pass linting.'
  ),
  temperature: z2.number().min(0).max(2).optional().describe("LLM temperature parameter."),
  modelSupportsJsonResponseFormat: z2.boolean().optional().describe(
    "A Boolean value indicating whether or not `model` supports OpenAI's JSON output mode."
  ),
  apiKey: z2.string().optional().describe(
    "API key for the OpenAI-compatible LLM API. Defaults to the value of the `OPENAI_API_KEY` environment variable."
  ),
  apiOrganizationId: z2.string().optional().describe(
    "Optional organization ID that should be billed for LLM API requests. This is only necessary if your OpenAI API key is scoped to multiple organizations."
  ),
  apiBaseUrl: z2.string().optional().describe(
    "Base URL for the OpemAI-compatible LLM API. Defaults to the OpenAI API `https://api.openai.com/v1`"
  ),
  kyOptions: z2.record(z2.any()).optional().describe(
    "Additional options for customizing HTTP calls to the LLM API, such as custom `headers` to pass with every request. All options are passed to `ky` which is the HTTP `fetch` wrapper used under the hood."
  )
}).strict();
var LinterOptionsSchema = z2.object({
  noInlineConfig: z2.boolean().optional().describe("A Boolean value for whether inline configuration is allowed."),
  earlyExit: z2.boolean().optional().describe(
    "A Boolean value for whether to exit greedily after finding the first error."
  ),
  debug: z2.boolean().optional().describe("Enables debug logging."),
  printConfig: z2.boolean().optional().describe(
    "When enabled, logs the resolved config and parsed rules and then exits."
  ),
  debugModel: z2.boolean().optional().describe("Enables verbose LLM logging."),
  debugGrit: z2.boolean().optional().describe("Enables verbose Grit logging."),
  debugStats: z2.boolean().optional().describe(
    "Enables logging of cumulative LLM stats (total tokens and cost)."
  ),
  noCache: z2.boolean().optional().describe("Disables the built-in cache."),
  noGrit: z2.boolean().optional().describe("Disables grit."),
  disabled: z2.boolean().optional().describe("Disables linting entirely."),
  dryRun: z2.boolean().optional().describe(
    "Disables all external LLM calls and outputs an estimate of what it would cost to run the linter on the given config."
  ),
  cacheDir: z2.string().optional().describe("A string path to the shared cache directory."),
  concurrency: z2.number().int().nonnegative().optional().describe("Limits the maximum number of concurrent tasks.")
}).strict();
var LinterConfigOverrideSchema = z2.object({
  include: z2.array(z2.string()).optional().describe(
    "An optional array of glob patterns for the files to process. If not specified, the configuration object applies to all files matched by any other configuration object."
  ),
  exclude: z2.array(z2.string()).optional().describe(
    "An optional array of glob patterns for source files that should be ignored."
  ),
  rules: LinterConfigRuleSettingsSchema.optional().describe(
    "An object customizing the configured rules."
  )
}).strict();
var LinterConfigOverridesSchema = z2.array(LinterConfigOverrideSchema);
var LinterConfigSchema = z2.object({
  files: z2.array(z2.string()).optional().describe(
    "An optional array of glob patterns for the files to process. If not specified, the configuration object applies to all files matched by any other configuration object."
  ),
  ignores: z2.array(z2.string()).optional().describe(
    "An optional array of glob patterns for source files that should be ignored."
  ),
  ruleFiles: z2.array(z2.string()).optional().describe("An array of glob patterns to rule definition markdown files."),
  ruleDefinitions: z2.array(RuleDefinitionSchema).optional().describe(
    "An array of custom rule definitions which are better expressed in code as opposed to the `ruleFiles` definitions which are expressed as markdown. These rule definitions will be merged with the rules definitions inferred by `ruleFiles`."
  ),
  rules: LinterConfigRuleSettingsSchema.optional().describe(
    "An object customizing the configured rules."
  ),
  linterOptions: LinterOptionsSchema.optional().describe(
    "An object containing settings related to the linting process."
  ),
  llmOptions: LLMOptionsSchema.optional().describe(""),
  overrides: LinterConfigOverridesSchema.optional().describe(
    "Rule config overrides for specific file patterns."
  )
}).strict();
var defaultLinterOptions = {
  noInlineConfig: false,
  earlyExit: false,
  concurrency: 24,
  debug: false,
  printConfig: false,
  debugModel: false,
  debugGrit: false,
  debugStats: true,
  disabled: false,
  noCache: false,
  noGrit: false,
  dryRun: false,
  cacheDir: defaultCacheDir
};
var defaultLLMOptions = {
  apiKey: getEnv("OPENAI_API_KEY"),
  apiBaseUrl: "https://api.openai.com/v1",
  model: "gpt-4o",
  weakModel: "gpt-4o-mini",
  temperature: 0
};
var defaultLinterConfig = {
  ruleFiles: [".gptlint/**/*.md", "!.gptlint/readme.md", "!.gptlint/README.md"],
  linterOptions: defaultLinterOptions,
  llmOptions: defaultLLMOptions
};
function parseLinterConfig(config) {
  return LinterConfigSchema.parse(config);
}
function isValidModel(model) {
  return !!model && model !== "none";
}
function dedupeRuleDefinitions(ruleDefinitions2) {
  const seen = /* @__PURE__ */ new Set();
  return ruleDefinitions2.filter((ruleDefinition) => {
    if (!seen.has(ruleDefinition.name)) {
      seen.add(ruleDefinition.name);
      return true;
    }
    return false;
  });
}
function mergeLinterConfigs(configA, configB) {
  return pruneUndefined({
    ...pruneUndefined(configA),
    ...pruneUndefined(configB),
    files: configA.files || configB.files ? default3(
      [...configA.files ?? [], ...configB.files ?? []].filter(Boolean)
    ) : void 0,
    ignores: configA.ignores || configB.ignores ? default3(
      [...configA.ignores ?? [], ...configB.ignores ?? []].filter(
        Boolean
      )
    ) : void 0,
    ruleFiles: configA.ruleFiles || configB.ruleFiles ? default3(
      [...configA.ruleFiles ?? [], ...configB.ruleFiles ?? []].filter(
        Boolean
      )
    ) : void 0,
    ruleDefinitions: configA.ruleDefinitions || configB.ruleDefinitions ? dedupeRuleDefinitions([
      ...configA.ruleDefinitions ?? [],
      ...configB.ruleDefinitions ?? []
    ]) : void 0,
    rules: configA.rules || configB.rules ? {
      ...pruneUndefined(configA.rules ?? {}),
      ...pruneUndefined(configB.rules ?? {})
    } : void 0,
    linterOptions: configA.linterOptions || configB.linterOptions ? {
      ...pruneUndefined(configA.linterOptions ?? {}),
      ...pruneUndefined(configB.linterOptions ?? {})
    } : void 0,
    llmOptions: configA.llmOptions || configB.llmOptions ? {
      ...pruneUndefined(configA.llmOptions ?? {}),
      ...pruneUndefined(configB.llmOptions ?? {})
    } : void 0,
    overrides: configA.overrides || configB.overrides ? [...configA.overrides ?? [], ...configB.overrides ?? []].filter(
      Boolean
    ) : void 0
  });
}
function mergeLinterConfigsOverride(configA, configB) {
  return pruneUndefined({
    ...pruneUndefined(configA),
    ...pruneUndefined(configB),
    ruleFiles: configB.ruleFiles || configB.ruleDefinitions ? configB.ruleFiles ?? [] : configA.ruleFiles,
    ruleDefinitions: configB.ruleFiles || configB.ruleDefinitions ? configB.ruleDefinitions ?? [] : configA.ruleDefinitions,
    linterOptions: configA.linterOptions || configB.linterOptions ? {
      ...pruneUndefined(configA.linterOptions ?? {}),
      ...pruneUndefined(configB.linterOptions ?? {})
    } : void 0,
    llmOptions: configA.llmOptions || configB.llmOptions ? {
      ...pruneUndefined(configA.llmOptions ?? {}),
      ...pruneUndefined(configB.llmOptions ?? {})
    } : void 0,
    overrides: configA.overrides || configB.overrides ? [...configA.overrides ?? [], ...configB.overrides ?? []].filter(
      Boolean
    ) : void 0
  });
}
function mergeLinterConfigRuleSettings(rulesA, rulesB) {
  return {
    ...pruneUndefined(rulesA ?? {}),
    ...pruneUndefined(rulesB ?? {})
  };
}
function resolveLinterConfig(config) {
  return mergeLinterConfigs(
    {
      files: [],
      ignores: [],
      ruleFiles: [],
      ruleDefinitions: [],
      rules: {},
      linterOptions: defaultLinterOptions,
      llmOptions: defaultLLMOptions,
      overrides: []
    },
    config
  );
}
var ResolvedLinterConfig = class {
  config;
  ruleSettingsFileCache = /* @__PURE__ */ new Map();
  constructor({
    configs,
    cliConfigOverride
  }) {
    let linterConfig = {};
    for (const config of configs) {
      linterConfig = mergeLinterConfigs(linterConfig, config);
    }
    linterConfig = mergeLinterConfigsOverride(linterConfig, cliConfigOverride);
    this.config = resolveLinterConfig(linterConfig);
    if (this.config.files.length === 0 && !cliConfigOverride.files) {
      this.config.files = defaultFiles;
    }
  }
  get files() {
    return this.config.files;
  }
  get ignores() {
    return this.config.ignores;
  }
  get ruleFiles() {
    return this.config.ruleFiles;
  }
  get rules() {
    return this.config.rules;
  }
  get ruleDefinitions() {
    return this.config.ruleDefinitions;
  }
  get linterOptions() {
    return this.config.linterOptions;
  }
  get llmOptions() {
    return this.config.llmOptions;
  }
  getRuleSettingsForFile(file) {
    if (this.ruleSettingsFileCache.has(file.fileRelativePath)) {
      return this.ruleSettingsFileCache.get(file.fileRelativePath);
    }
    const settings = this.config.overrides ?? [].filter((override) => fileMatchesIncludeExclude(file, override));
    let rules = {};
    for (const setting of settings) {
      rules = mergeLinterConfigRuleSettings(rules, setting.rules);
    }
    this.ruleSettingsFileCache.set(file.fileRelativePath, rules);
    return rules;
  }
  getSanitizedDebugConfig() {
    return sanitizeConfig(this.config);
  }
};
function sanitizeConfig(config) {
  var _a, _b;
  return pruneUndefined({
    ...config,
    ruleDefinitions: (_a = config.ruleDefinitions) == null ? void 0 : _a.map(
      (ruleDefinition) => `${ruleDefinition.name} { ... }`
    ),
    llmOptions: pruneUndefined({
      ...config.llmOptions,
      apiKey: ((_b = config.llmOptions) == null ? void 0 : _b.apiKey) ? "<redacted>" : void 0
    })
  });
}

// src/errors.ts
import { AbortError } from "p-retry";
var RetryableError = class extends Error {
};
var ParseError = class extends RetryableError {
};

// src/rule-violations.ts
import { toString as toString2 } from "mdast-util-to-string";
import { z as z4 } from "zod";

// src/markdown-utils.ts
import path5 from "node:path";
import { gfmToMarkdown } from "mdast-util-gfm";
import { toMarkdown } from "mdast-util-to-markdown";
import { toString } from "mdast-util-to-string";
import remarkFrontmatter from "remark-frontmatter";
import remarkGfm from "remark-gfm";
import remarkParse from "remark-parse";
import { unified } from "unified";
import { is } from "unist-util-is";
import { inspectColor } from "unist-util-inspect";
function parseMarkdownAST(content) {
  return unified().use(remarkParse).use(remarkFrontmatter).use(remarkGfm).parse(content);
}
function convertASTToMarkdown(nodes) {
  return toMarkdown(nodes, {
    bullet: "-",
    rule: "-",
    extensions: [gfmToMarkdown()]
  });
}
function convertASTToPlaintext(node) {
  return toString(node);
}
function parseRuleNode({
  headingRuleNode,
  bodyRuleNodes,
  filePath,
  partialRule
}) {
  const firstNonBodyRuleNodeIndex = bodyRuleNodes.findIndex(
    (node) => node.type === "heading" && node.depth >= 3
  );
  let exampleRuleNodes = [];
  if (firstNonBodyRuleNodeIndex >= 0) {
    exampleRuleNodes = bodyRuleNodes.slice(firstNonBodyRuleNodeIndex);
    bodyRuleNodes = bodyRuleNodes.slice(0, firstNonBodyRuleNodeIndex);
  }
  const bodyRuleNode = {
    type: "root",
    children: bodyRuleNodes
  };
  const title = convertASTToPlaintext(headingRuleNode);
  default4(title, "Rule title must not be empty");
  const fileNameRuleName = path5.basename(filePath).replace(/\.\w+$/, "");
  const defaultRuleName = isValidRuleName(fileNameRuleName) ? fileNameRuleName : default2(title).trim();
  const description = convertASTToMarkdown(bodyRuleNode);
  const rule = pruneUndefined({
    name: defaultRuleName,
    title,
    description,
    positiveExamples: [],
    negativeExamples: [],
    cacheable: true,
    level: "error",
    scope: "file",
    source: filePath,
    metadata: {},
    ...partialRule
  });
  default4(rule.name, `Rule name must not be empty: ${title}`);
  default4(
    isValidRuleName(rule.name),
    `Rule name is invalid "${rule.name}": ${title}`
  );
  const exampleRuleNode = {
    type: "root",
    children: exampleRuleNodes
  };
  const h3Nodes = exampleRuleNodes.filter(
    (node) => node.type === "heading" && node.depth >= 3
  );
  default4(
    h3Nodes.length <= 2,
    `Rule must not contain more than 2 H3 markdown nodes: ${rule.name} (${filePath})`
  );
  let numPositiveSections = 0;
  let numNegativeSections = 0;
  for (let i = 0; i < h3Nodes.length; ++i) {
    const h3Node = h3Nodes[i];
    const sectionNodes = findAllBetween(exampleRuleNode, h3Node, h3Nodes[i + 1]);
    const sectionLabel = convertASTToPlaintext(h3Node).toLowerCase().trim();
    const isPositive = /\bgood\b/i.test(sectionLabel) || /\bcorrect\b/.test(sectionLabel) || /\bpass\b/.test(sectionLabel);
    const isNegative = /\bbad\b/i.test(sectionLabel) || /\bincorrect\b/.test(sectionLabel) || /\bfail\b/.test(sectionLabel);
    default4(
      isPositive || isNegative,
      `Rule h3 header for examples section "${sectionLabel}" must include a known positive label (good, correct, or pass) or negative label (bad, incorrect, or fail): ${rule.name} (${filePath})`
    );
    const codeBlockNodes = sectionNodes.filter(
      (node) => node.type === "code"
    );
    if (isPositive) {
      numPositiveSections++;
    } else if (isNegative) {
      numNegativeSections++;
    }
    for (const codeBlockNode of codeBlockNodes) {
      const code = convertASTToPlaintext(codeBlockNode);
      const language = codeBlockNode.lang || void 0;
      if (isPositive) {
        rule.positiveExamples.push({ code, language });
      } else if (isNegative) {
        rule.negativeExamples.push({ code, language });
      }
    }
  }
  default4(
    numPositiveSections <= 1,
    `Rule must not contain more than 1 positive examples section: ${rule.name} (${filePath})`
  );
  default4(
    numNegativeSections <= 1,
    `Rule must not contain more than 1 negative examples section: ${rule.name} (${filePath})`
  );
  return rule;
}
function findAllBetween(parent, start, end, test) {
  if (!parent || !parent.type || !parent.children) {
    throw new Error("Expected parent node");
  }
  const { children } = parent;
  const results = [];
  const startIndex = check(start);
  const endIndex = check(end);
  let child;
  let index = startIndex;
  while (++index < endIndex) {
    child = children[index];
    if (is(child, test, index, parent)) {
      results.push(child);
    }
  }
  return results;
  function check(indexOrNode) {
    let index2 = 0;
    if (indexOrNode === void 0) {
      return children.length;
    } else if (typeof indexOrNode === "number") {
      index2 = indexOrNode;
      if (index2 < 0) {
        index2 = children.length;
      }
    } else if (indexOrNode.type) {
      index2 = parent.children.indexOf(indexOrNode);
    }
    if (Number.isNaN(index2) || index2 < 0 || index2 === Number.POSITIVE_INFINITY) {
      throw new Error("Expected positive finite index or child node");
    }
    if (index2 > children.length) {
      index2 = children.length;
    }
    return index2;
  }
}
function findAllCodeBlockNodes(tree) {
  return tree.children.filter((node) => node.type === "code");
}
function findAllHeadingNodes(tree, { depth } = {}) {
  return tree.children.filter(
    (node) => node.type === "heading" && (depth === void 0 || node.depth === depth)
  );
}
function findAllYAMLNodes(tree) {
  return tree.children.filter((node) => node.type === "yaml");
}

// src/parse-structured-output.ts
import { jsonrepair, JSONRepairError } from "jsonrepair";
import { z as z3 } from "zod";
function parseStructuredOutput(output, outputSchema) {
  let result;
  if (outputSchema instanceof z3.ZodArray) {
    result = parseArrayOutput(output);
  } else if (outputSchema instanceof z3.ZodObject) {
    result = parseObjectOutput(output);
  } else if (outputSchema instanceof z3.ZodBoolean) {
    result = parseBooleanOutput(output);
  } else if (outputSchema instanceof z3.ZodNumber) {
    result = parseNumberOutput(output, outputSchema);
  } else {
    result = output;
  }
  const safeResult = outputSchema.safeParse(result);
  if (!safeResult.success) {
    throw new ParseError(safeResult.error);
  }
  return safeResult.data;
}
function safeParseStructuredOutput(output, outputSchema) {
  try {
    const data = parseStructuredOutput(output, outputSchema);
    return {
      success: true,
      data
    };
  } catch (err) {
    return {
      success: false,
      error: err.message
    };
  }
}
function isEscaped(str, i) {
  return i > 0 && str[i - 1] === "\\" && !(i > 1 && str[i - 2] === "\\");
}
function extractJSONFromString(input, jsonStructureType) {
  const startChar = jsonStructureType === "object" ? "{" : "[";
  const endChar = jsonStructureType === "object" ? "}" : "]";
  const extractedJSONValues = [];
  let nestingLevel = 0;
  let startIndex = 0;
  const isInsideQuoted = { '"': false, "'": false };
  for (let i = 0; i < input.length; i++) {
    const ch = input.charAt(i);
    switch (ch) {
      case '"':
      case "'":
        if (!isInsideQuoted[ch === '"' ? "'" : '"'] && !isEscaped(input, i)) {
          isInsideQuoted[ch] = !isInsideQuoted[ch];
        }
        break;
      default:
        if (!isInsideQuoted['"'] && !isInsideQuoted["'"]) {
          switch (ch) {
            case startChar:
              if (nestingLevel === 0) {
                startIndex = i;
              }
              nestingLevel += 1;
              break;
            case endChar:
              nestingLevel -= 1;
              if (nestingLevel === 0) {
                const candidate = input.slice(startIndex, i + 1);
                const parsed = JSON.parse(jsonrepair(candidate));
                if (parsed && typeof parsed === "object") {
                  extractedJSONValues.push(parsed);
                }
              } else if (nestingLevel < 0) {
                throw new ParseError(
                  `Invalid JSON string: unexpected ${endChar} at position ${i}`
                );
              }
          }
        }
    }
  }
  if (nestingLevel !== 0) {
    throw new ParseError(
      "Invalid JSON string: unmatched " + startChar + " or " + endChar
    );
  }
  return extractedJSONValues;
}
var BOOLEAN_OUTPUTS = {
  true: true,
  false: false,
  t: true,
  f: false,
  yes: true,
  no: false,
  y: true,
  n: false,
  "1": true,
  "0": false
};
function parseArrayOutput(output) {
  try {
    const arrayOutput = extractJSONFromString(output, "array");
    if (arrayOutput.length === 0) {
      throw new ParseError(`Invalid JSON array: ${output}`);
    }
    const parsedOutput = arrayOutput[0];
    if (!Array.isArray(parsedOutput)) {
      throw new ParseError(
        `Invalid JSON array: ${JSON.stringify(parsedOutput)}`
      );
    }
    return parsedOutput;
  } catch (err) {
    if (err instanceof JSONRepairError) {
      throw new ParseError(err.message, { cause: err });
    } else if (err instanceof SyntaxError) {
      throw new ParseError(`Invalid JSON array: ${err.message}`, { cause: err });
    } else {
      throw err;
    }
  }
}
function parseObjectOutput(output) {
  try {
    const arrayOutput = extractJSONFromString(output, "object");
    if (arrayOutput.length === 0) {
      throw new ParseError(`Invalid JSON object: ${output}`);
    }
    let parsedOutput = arrayOutput[0];
    if (Array.isArray(parsedOutput)) {
      parsedOutput = parsedOutput[0];
    } else if (typeof parsedOutput !== "object") {
      throw new ParseError(
        `Invalid JSON object: ${JSON.stringify(parsedOutput)}`
      );
    }
    return parsedOutput;
  } catch (err) {
    if (err instanceof JSONRepairError) {
      throw new ParseError(err.message, { cause: err });
    } else if (err instanceof SyntaxError) {
      throw new ParseError(`Invalid JSON object: ${err.message}`, {
        cause: err
      });
    } else {
      throw err;
    }
  }
}
function parseBooleanOutput(output) {
  output = output.toLowerCase().trim().replace(/[!.?]+$/, "");
  const booleanOutput = BOOLEAN_OUTPUTS[output];
  if (booleanOutput === void 0) {
    throw new ParseError(`Invalid boolean output: ${output}`);
  } else {
    return booleanOutput;
  }
}
function parseNumberOutput(output, outputSchema) {
  output = output.trim();
  const numberOutput = outputSchema.isInt ? Number.parseInt(output) : Number.parseFloat(output);
  if (Number.isNaN(numberOutput)) {
    throw new ParseError(`Invalid number output: ${output}`);
  }
  return numberOutput;
}

// src/rule-violations.ts
var ruleViolationSchema = z4.object({
  ruleName: z4.string().optional().describe("The name of the RULE which this `codeSnippet` violates."),
  codeSnippet: z4.string().describe(
    'The offending code snippet which fails to conform to the given RULE. CODE SNIPPETS MUST BE SHORT and should include an ellipsis "..." if they would be more than 10 lines of code.'
  ),
  codeSnippetSource: z4.enum(["examples", "source", "unknown"]).optional().describe(
    'Where this rule violation\'s `codeSnippet` comes from. If it comes from the RULE examples, then use "examples". If it comes from the SOURCE, then use "source".'
  ),
  reasoning: z4.string().optional().describe(
    "An explanation of why this code snippet VIOLATES the RULE. Think step-by-step when describing your reasoning."
  ),
  violation: z4.boolean().describe(
    "Whether or not this `codeSnippet` violates the RULE. If the `codeSnippet` does VIOLATE the RULE, then `violation` should be `true`. If the `codeSnippet` conforms to the RULE correctly or does not appear in the SOURCE, then `violation` should be `false`."
  ),
  confidence: z4.enum(["low", "medium", "high"]).describe("Your confidence that the `codeSnippet` VIOLATES the RULE.")
});
var ruleViolationsOutputSchema = z4.array(ruleViolationSchema);
var ruleViolationsValidatedOutputSchema = z4.object({
  ruleViolations: ruleViolationsOutputSchema
});
function parseRuleViolationsFromJSONModelResponse(response) {
  const ruleViolationsParseResult = safeParseStructuredOutput(
    response,
    ruleViolationsValidatedOutputSchema
  );
  if (!ruleViolationsParseResult.success) {
    throw new RetryableError(
      `Invalid output: the JSON output failed to parse according to the given RULE_VIOLATION schema. Parser error: ${ruleViolationsParseResult.error}`
    );
  }
  return ruleViolationsParseResult.data.ruleViolations;
}
function parseRuleViolationsFromMarkdownModelResponse(response, {
  numExpectedMarkdownHeadings = 2
} = {}) {
  const ast = parseMarkdownAST(response);
  const codeBlocksNodes = findAllCodeBlockNodes(ast);
  let codeBlockNode;
  if (codeBlocksNodes.length === 0) {
    const h1Nodes = findAllHeadingNodes(ast, { depth: 1 });
    if (h1Nodes.length >= numExpectedMarkdownHeadings) {
      return [];
    }
    throw new RetryableError(
      "Invalid output: missing VIOLATIONS code block which should contain an array of RULE_VIOLATION objects."
    );
  } else if (codeBlocksNodes.length > 1) {
    const h1Nodes = findAllHeadingNodes(ast, { depth: 1 });
    if (h1Nodes.length === 0) {
      throw new RetryableError("Invalid output: missing VIOLATIONS header.");
    } else {
      const headers = h1Nodes.map((node) => toString2(node).toLowerCase().trim());
      const violationsHeaderIndex = headers.findLastIndex(
        (header) => /violation/i.test(header)
      );
      if (violationsHeaderIndex < 0) {
        throw new RetryableError(
          "Invalid output: missing VIOLATIONS header section which should contain a json code block with an array of RULE_VIOLATION objects."
        );
      }
      const violationsNode = h1Nodes[violationsHeaderIndex];
      const violationsBodyNodes = findAllBetween(ast, violationsNode);
      let violationsCodeBlocksNodes = findAllCodeBlockNodes({
        type: "root",
        children: violationsBodyNodes
      });
      if (violationsCodeBlocksNodes.length > 1) {
        const jsonViolationCodeBlockNodes = violationsCodeBlocksNodes.filter(
          (node) => node.lang === "json"
        );
        if (jsonViolationCodeBlockNodes.length === 0) {
          const parseableCodeBlockNodes = violationsCodeBlocksNodes.filter(
            (node) => safeParseStructuredOutput(node.value, ruleViolationsOutputSchema).success
          );
          if (parseableCodeBlockNodes.length === 0) {
          } else if (parseableCodeBlockNodes.length >= 1) {
            violationsCodeBlocksNodes = parseableCodeBlockNodes;
          }
        } else if (jsonViolationCodeBlockNodes.length === 1) {
          violationsCodeBlocksNodes = jsonViolationCodeBlockNodes;
        }
      }
      if (!violationsCodeBlocksNodes.length) {
        throw new RetryableError(
          "Invalid output: missing a valid json code block with an array of RULE_VIOLATION objects."
        );
      } else if (violationsCodeBlocksNodes.length > 1) {
        throw new RetryableError(
          "Invalid output: the VIOLATIONS section should contain a single json code block with an array of RULE_VIOLATION objects."
        );
      } else {
        codeBlockNode = violationsCodeBlocksNodes[0];
      }
    }
  } else {
    codeBlockNode = codeBlocksNodes[0];
  }
  if (!codeBlockNode) {
    throw new RetryableError(
      "Invalid output: the VIOLATIONS section should contain a single json code block with an array of RULE_VIOLATION objects."
    );
  }
  const parsedRuleViolationsResult = safeParseStructuredOutput(
    codeBlockNode.value,
    ruleViolationsOutputSchema
  );
  if (!parsedRuleViolationsResult.success) {
    throw new RetryableError(
      `Invalid output: the VIOLATIONS code block does not contain valid RULE_VIOLATION objects. Please make sure the RULE_VIOLATION objects are formatted correctly according to their schema. Parser error: ${parsedRuleViolationsResult.error}`
    );
  }
  const ruleViolations = parsedRuleViolationsResult.data;
  return ruleViolations;
}
function stringifyRuleViolationSchemaForModel(rule, file) {
  return `\`\`\`ts
interface RULE_VIOLATION {
  // The name of the RULE which this \`codeSnippet\` violates.
  ruleName: string

  // The offending code snippet which fails to conform to the given RULE. CODE SNIPPETS MUST BE SHORT and should include an ellipsis "..." if they would be more than 10 lines of code.
  codeSnippet: string

  // Where this rule violation's \`codeSnippet\` comes from. If it comes from the RULE ${rule.name} examples, then use "examples". If it comes from the SOURCE code "${file.fileRelativePath}", then use "source".
  codeSnippetSource: "examples" | "source"

  // An explanation of why this code snippet VIOLATES the RULE. Think step-by-step when describing your reasoning.
  reasoning: string

  // Whether or not this \`codeSnippet\` violates the RULE. If this \`codeSnippet\` does VIOLATE the RULE, then \`violation\` should be \`true\`. If the \`codeSnippet\` conforms to the RULE correctly or does not appear in the SOURCE, then \`violation\` should be \`false\`.
  violation: boolean

  // Your confidence that the \`codeSnippet\` VIOLATES the RULE.
  confidence: "low" | "medium" | "high"
}
\`\`\``;
}
function stringifyExampleRuleViolationsObjectOutputForModel(rule) {
  return `\`\`\`json
{
  "ruleViolations": [
    {
      "ruleName": "${rule.name}",
      "codeSnippet": "...",
      "codeSnippetSource": "source",
      "reasoning": "..."
      "violation": true,
      "confidence": "high"
    }
  ]
}
\`\`\``;
}
function stringifyExampleRuleViolationsArrayOutputForModel(rule) {
  return `\`\`\`json
[
  {
    "ruleName": "${rule.name}",
    "codeSnippet": "...",
    "codeSnippetSource": "source",
    "reasoning": "..."
    "violation": true,
    "confidence": "high"
  }
]
\`\`\``;
}
function stringifyRuleViolationForModel(ruleViolations) {
  return `\`\`\`json
{
  ruleViolations: ${JSON.stringify(ruleViolations, null, 2)}
}
\`\`\``;
}
function isRuleViolationLikelyFalsePositive({
  ruleViolation,
  rule,
  file
}) {
  var _a;
  const { violation, confidence } = ruleViolation;
  if (!violation) {
    return true;
  }
  if (confidence !== "high" && confidence !== "medium") {
    return true;
  }
  const ruleName = (_a = ruleViolation.ruleName) == null ? void 0 : _a.toLowerCase().trim();
  if (ruleName && rule.name !== ruleName) {
    return true;
  }
  if (isRuleViolationLikelyFalsePositiveFromExamples({
    ruleViolation,
    rule,
    file
  })) {
    return true;
  }
  return false;
}
function isRuleViolationLikelyFalsePositiveFromExamples({
  ruleViolation,
  rule,
  file
}) {
  if (ruleViolation.codeSnippetSource !== "source") {
    return true;
  }
  if (!rule.negativeExamples) {
    return false;
  }
  const codeSnippetExample = rule.negativeExamples.find(
    (example) => fuzzyStringEquality(example.code, ruleViolation.codeSnippet)
  );
  if (!codeSnippetExample) {
    return false;
  }
  const fileContent = file.partialContent || file.content;
  if (fuzzyStringEquality(fileContent, ruleViolation.codeSnippet)) {
    return false;
  }
  return true;
}
function fuzzyStringEquality(a, b) {
  a = a.toLowerCase().trim();
  b = b.toLowerCase().trim();
  if (a.length > b.length) {
    return a.includes(b);
  } else if (a.length < b.length) {
    return b.includes(a);
  } else {
    return a === b;
  }
}

// src/lint-file.ts
async function lintFile({
  file,
  rule,
  lintResult,
  chatModel,
  cache,
  config,
  cwd,
  retryOptions = {
    retries: 2
  },
  enableGrit = false
}) {
  var _a;
  lintResult = createLintResult(lintResult);
  const isTwoPassLintingEnabled = isValidModel(config.llmOptions.weakModel);
  const model = rule.model ?? isTwoPassLintingEnabled ? config.llmOptions.weakModel : config.llmOptions.model;
  if (enableGrit && rule.gritql) {
    const ruleNameToPartialSourceFileMap = /* @__PURE__ */ new Map();
    const maybeLintResult = await preProcessFileWithGrit({
      file,
      rule,
      config,
      ruleNameToPartialSourceFileMap
    });
    if (maybeLintResult) {
      return maybeLintResult;
    }
  }
  if (config.linterOptions.debug) {
    console.log(
      `>>> Linting rule "${rule.name}" file "${file.fileRelativePath}" with model "${model}"`
    );
  }
  const messages = [
    Msg.system(`<INSTRUCTIONS>

You are an expert senior TypeScript software engineer at Vercel who loves to lint code. You make sure source code conforms to project-specific guidelines and best practices. You will be given a RULE with a description of the RULE's intent and some positive examples where the RULE is used correctly and some negative examples where the RULE is VIOLATED (used incorrectly).

Your task is to take the given SOURCE code and determine whether any portions of it VIOLATE the RULE's intent.

</INSTRUCTIONS>

---

${stringifyRuleForModel(rule)}

---

<SOURCE ${file.fileName}>

${file.partialContent || file.content}

</SOURCE ${file.fileName}> 
`),
    Msg.user(`Your job is to identify any portions of the SOURCE ${file.fileName} which are related to the RULE ${rule.name} and explain whether they VIOLATE or conform to the RULE's intent. Your answer should contain two markdown sections, EXPLANATION and VIOLATIONS.

Accuracy is important, so be sure to think step-by-step and explain your reasoning briefly in the EXPLANATION section. Do not list out all variable names or identifiers in the EXPLANATION section, but rather focus on listing out the most relevant portions of the SOURCE that the given RULE may apply to.

If you find any code snippets which VIOLATE the RULE, then output them as RULE_VIOLATION objects in the VIOLATIONS section. The VIOLATIONS section should be a JSON array of RULE_VIOLATION objects. This array may be empty if there are no RULE VIOLATIONS. Ignore code snippets which correctly conform to the RULE.

---

<RULE_VIOLATION schema>

${stringifyRuleViolationSchemaForModel(rule, file)}

</RULE_VIOLATION schema>

---

Example markdown output format:

# EXPLANATION

Plain text explanation of any areas of the SOURCE code which may be affected by the RULE and brief reasoning for any potential VIOLATIONS.

# VIOLATIONS

${stringifyExampleRuleViolationsArrayOutputForModel(rule)}
`)
  ];
  let retries = retryOptions.retries;
  do {
    try {
      const res = await chatModel.run({
        model,
        messages
      });
      const response = res.message.content;
      lintResult.message = response;
      if (config.linterOptions.debug) {
        console.log(
          `
rule "${rule.name}" file "${file.fileRelativePath}" response from model "${model}":

${response}

`
        );
      }
      messages.push(Msg.assistant(response));
      if (res.cached) {
        lintResult.numModelCallsCached++;
      } else {
        lintResult.numModelCalls++;
      }
      if (res.cost) {
        lintResult.totalCost += res.cost;
      } else if ((_a = res.usage) == null ? void 0 : _a.total_cost) {
        lintResult.totalCost += 100 * res.usage.total_cost;
      }
      if (res.usage) {
        lintResult.numPromptTokens += res.usage.prompt_tokens;
        lintResult.numCompletionTokens += res.usage.completion_tokens;
        lintResult.numTotalTokens += res.usage.total_tokens;
      }
      const ruleViolations = parseRuleViolationsFromMarkdownModelResponse(response);
      for (const ruleViolation of ruleViolations) {
        if (isRuleViolationLikelyFalsePositive({ ruleViolation, rule, file })) {
          continue;
        }
        const { confidence, codeSnippet, reasoning } = ruleViolation;
        lintResult.lintErrors.push({
          message: rule.title,
          filePath: file.filePath,
          language: file.language,
          ruleName: rule.name,
          level: rule.level,
          model,
          codeSnippet,
          confidence,
          reasoning
        });
      }
      break;
    } catch (err) {
      if (err instanceof AbortError || err.name === "AbortError") {
        throw err;
      }
      if (retries-- <= 0) {
        throw err;
      }
      if (err instanceof RetryableError) {
        if (config.linterOptions.debug) {
          console.warn(
            `
RETRYING error processing rule "${rule.name}" file "${file.fileRelativePath}": ${err.message}

`
          );
        }
        if (retryOptions == null ? void 0 : retryOptions.onFailedAttempt) {
          if (retryOptions == null ? void 0 : retryOptions.onFailedAttempt) {
            ;
            err.attemptNumber = Math.max(
              0,
              retryOptions.retries - retries - 1
            );
            err.retriesLeft = retries;
            await Promise.resolve(
              retryOptions.onFailedAttempt(err)
            );
          }
        }
        const errMessage = err.message;
        messages.push(
          Msg.user(
            `There was an error validating the response. Please check the error message and try again.
Error:
${errMessage}`
          )
        );
      } else {
        if (config.linterOptions.debug) {
          console.error(
            `Unexpected error processing rule "${rule.name}" file "${file.fileRelativePath}":`,
            trimMessage(err.message, { maxLength: 400 })
          );
        }
        throw new TypeError(
          `Unexpected error processing rule "${rule.name}" file "${file.fileRelativePath}": ${trimMessage(err.message)}`,
          { cause: err }
        );
      }
    }
  } while (true);
  lintResult.lintErrors = dedupeLintErrors(lintResult.lintErrors);
  if (lintResult.lintErrors.length > 0 && isTwoPassLintingEnabled) {
    const { lintErrors: originalLintErrors } = lintResult;
    if (config.linterOptions.debug) {
      console.log(
        `
>>> VALIDATING ${originalLintErrors.length} ${plur2(
          "error",
          originalLintErrors.length
        )} for rule "${rule.name}" file "${file.fileRelativePath}":`,
        originalLintErrors
      );
    }
    lintResult = await validateRuleViolations({
      file,
      rule,
      lintResult,
      chatModel,
      cache,
      config,
      retryOptions,
      cwd
    });
    if (config.linterOptions.debug) {
      const { lintErrors } = lintResult;
      console.log(
        `
<<< DONE VALIDATING ${originalLintErrors.length} ${plur2(
          "error",
          originalLintErrors.length
        )} \u21D2 ${lintErrors.length} ${plur2(
          "error",
          lintErrors.length
        )} for rule "${rule.name}" file "${file.fileRelativePath}":`,
        lintErrors
      );
    }
  }
  if (config.linterOptions.debug) {
    const { lintErrors } = lintResult;
    if (lintErrors.length > 0) {
      console.log(
        `
<<< FAIL Rule "${rule.name}" file "${file.fileRelativePath}": ${lintErrors.length} ${plur2("error", lintErrors.length)} found:`,
        lintErrors
      );
    } else {
      console.log(
        `
<<< PASS Rule "${rule.name}" file "${file.fileRelativePath}"`
      );
    }
  }
  return lintResult;
}
async function validateRuleViolations({
  file,
  rule,
  lintResult,
  chatModel,
  config,
  retryOptions = {
    retries: 2
  }
}) {
  var _a;
  const model = rule.model ?? config.llmOptions.model;
  lintResult = createLintResult(lintResult);
  const modelSupportsJsonResponseFormat = config.llmOptions.modelSupportsJsonResponseFormat ?? (config.llmOptions.apiBaseUrl === defaultLinterConfig.llmOptions.apiBaseUrl && model !== "gpt-4" || config.llmOptions.apiBaseUrl === "https://api.groq.com/openai/v1");
  const potentialRuleViolations = lintResult.lintErrors.map((error) => ({
    ruleName: rule.name,
    codeSnippet: error.codeSnippet,
    codeSnippetSource: "unknown"
    // We intentionally omit the weak model's `reasoning` here because it may
    // be misleading, and that's what we're relying on the strong model for.
  }));
  const messages = [
    Msg.system(`<INSTRUCTIONS>

You are an expert senior TypeScript software engineer at Vercel who loves to lint code. You make sure source code conforms to project-specific guidelines and best practices. You will be given a RULE with a description of the RULE's intent and some positive examples where the RULE is used correctly and some negative examples where the RULE is VIOLATED (used incorrectly).

Your task is to take the given SOURCE code and an array of POTENTIAL RULE_VIOLATION objects and determine whether these rule violations actually VIOLATE the RULE's intent.

</INSTRUCTIONS>

---

${stringifyRuleForModel(rule)}

---

<SOURCE ${file.fileName}>

${file.partialContent || file.content}

</SOURCE ${file.fileName}> 
`),
    Msg.user(`Given the POTENTIAL RULE_VIOLATION objects from the SOURCE code ${file.fileName}, determine whether these rule violations actually VIOLATE the RULE's intent.

For any potential RULE_VIOLATION objects which VIOLATE the RULE, include them in the output with \`violation\` set to \`true\` and explain your \`reasoning\`. For any potential RULE_VIOLATION objects which correctly conform to the RULE, then include them in the output with \`violation\` set to \`false\` and explain your \`reasoning\`.

---

<RULE_VIOLATION schema>

${stringifyRuleViolationSchemaForModel(rule, file)}

</RULE_VIOLATION schema>

---

POTENTIAL RULE_VIOLATION objects to check:

${stringifyRuleViolationForModel(potentialRuleViolations)}

---

Example ${modelSupportsJsonResponseFormat ? "JSON" : "markdown"} output format:

${modelSupportsJsonResponseFormat ? stringifyExampleRuleViolationsObjectOutputForModel(rule) : `# VIOLATIONS

${stringifyExampleRuleViolationsArrayOutputForModel(rule)}`}
`)
  ];
  let retries = retryOptions.retries;
  do {
    try {
      const res = await chatModel.run(
        pruneUndefined({
          model,
          messages,
          response_format: modelSupportsJsonResponseFormat ? { type: "json_object" } : void 0
        })
      );
      const response = res.message.content;
      lintResult.message = response;
      if (config.linterOptions.debug) {
        console.log(
          `
rule "${rule.name}" file "${file.fileRelativePath}" response from model "${model}":

${response}

`
        );
      }
      messages.push(Msg.assistant(response));
      if (res.cached) {
        lintResult.numModelCallsCached++;
      } else {
        lintResult.numModelCalls++;
      }
      if (res.cost) {
        lintResult.totalCost += res.cost;
      } else if ((_a = res.usage) == null ? void 0 : _a.total_cost) {
        lintResult.totalCost += 100 * res.usage.total_cost;
      }
      if (res.usage) {
        lintResult.numPromptTokens += res.usage.prompt_tokens;
        lintResult.numCompletionTokens += res.usage.completion_tokens;
        lintResult.numTotalTokens += res.usage.total_tokens;
      }
      const ruleViolations = modelSupportsJsonResponseFormat ? parseRuleViolationsFromJSONModelResponse(response) : parseRuleViolationsFromMarkdownModelResponse(response, {
        numExpectedMarkdownHeadings: 1
      });
      lintResult.lintErrors = [];
      for (const ruleViolation of ruleViolations) {
        if (isRuleViolationLikelyFalsePositive({ ruleViolation, rule, file })) {
          continue;
        }
        const { confidence, codeSnippet, reasoning } = ruleViolation;
        lintResult.lintErrors.push({
          message: rule.title,
          filePath: file.filePath,
          language: file.language,
          ruleName: rule.name,
          level: rule.level,
          model,
          codeSnippet,
          confidence,
          reasoning
        });
      }
      break;
    } catch (err) {
      if (err instanceof AbortError || err.name === "AbortError") {
        throw err;
      }
      if (retries-- <= 0) {
        throw err;
      }
      if (err instanceof RetryableError) {
        if (config.linterOptions.debug) {
          console.warn(
            `
RETRYING error processing rule "${rule.name}" file "${file.fileRelativePath}": ${err.message}

`
          );
        }
        if (retryOptions == null ? void 0 : retryOptions.onFailedAttempt) {
          ;
          err.attemptNumber = Math.max(
            0,
            retryOptions.retries - retries - 1
          );
          err.retriesLeft = retries;
          await Promise.resolve(
            retryOptions.onFailedAttempt(err)
          );
        }
        const errMessage = err.message;
        messages.push(
          Msg.user(
            `There was an error validating the response. Please check the error message and try again.
Error:
${errMessage}`
          )
        );
      } else {
        if (config.linterOptions.debug) {
          console.error(
            `Unexpected error processing rule "${rule.name}" file "${file.fileRelativePath}":`,
            trimMessage(err.message, { maxLength: 400 })
          );
        }
        throw new TypeError(
          `Unexpected error processing rule "${rule.name}" file "${file.fileRelativePath}": ${trimMessage(err.message)}`,
          { cause: err }
        );
      }
    }
  } while (true);
  lintResult.lintErrors = dedupeLintErrors(lintResult.lintErrors);
  return lintResult;
}

// src/lint-task.ts
function createLintTask({
  rule,
  file,
  config
}) {
  const { scope } = rule;
  if (scope === "file") {
    default4(file);
    if (!fileMatchesIncludeExclude(file, rule)) {
      return null;
    }
    const fileRuleSettings = config.getRuleSettingsForFile(file);
    if (fileRuleSettings[rule.name] === "off") {
      return null;
    }
  }
  const lintTaskP = createPromiseWithResolvers();
  const lintTask = {
    ...lintTaskP,
    scope,
    group: scope === "file" ? file.fileRelativePath : scope,
    rule,
    file,
    config,
    cacheKey: createCacheKey({ file, rule, config })
  };
  return lintTask;
}
function stringifyLintTask(lintTask) {
  return [
    `rule "${lintTask.rule.name}"`,
    lintTask.file ? `file "${lintTask.file.fileRelativePath}"` : void 0
  ].filter(Boolean).join(" ");
}

// src/parse-inline-config.ts
function parseInlineConfig({
  file
}) {
  var _a;
  const rules = {};
  const inlineDisableRe = /^\s*\/\*+\s*gptlint-disable\s*\*+\//gim;
  const inlineEnableRe = /^\s*\/\*+\s*gptlint-enable\s*\*+\//gim;
  let lastDisableIndex = -1;
  let lastEnableIndex = -1;
  for (const match of file.content.matchAll(inlineDisableRe)) {
    lastDisableIndex = Math.max(lastDisableIndex, match.index);
  }
  for (const match of file.content.matchAll(inlineEnableRe)) {
    lastEnableIndex = Math.max(lastEnableIndex, match.index);
  }
  if (lastDisableIndex >= 0 && lastDisableIndex > lastEnableIndex) {
    return {
      linterOptions: {
        disabled: true
      }
    };
  }
  const inlineConfigRe = /^\s*\/\*+\s*gptlint\s+([^*]+)\s*\*+\//gim;
  for (const match of file.content.matchAll(inlineConfigRe)) {
    const inlineConfig = (_a = match[1]) == null ? void 0 : _a.trim();
    if (!inlineConfig) continue;
    const inlineConfigParts = inlineConfig.split(",").map((c) => c.trim());
    for (const inlineConfigPart of inlineConfigParts) {
      const inlineConfigRuleSettingParts = inlineConfigPart.split(":").map((c) => c.trim().toLowerCase());
      default4(
        inlineConfigRuleSettingParts.length === 2,
        `Invalid inline config setting "${inlineConfig}" (${file.fileRelativePath})`
      );
      const [ruleName, ruleSetting] = inlineConfigRuleSettingParts;
      default4(
        isValidRuleName(ruleName),
        `Invalid inline config setting "${inlineConfig}"; invalid rule name "${ruleName}" (${file.fileRelativePath})`
      );
      default4(
        isValidRuleSetting(ruleSetting),
        `Invalid inline config setting "${inlineConfig}"; invalid rule setting "${ruleSetting}" (${file.fileRelativePath})`
      );
      rules[ruleName] = ruleSetting;
    }
  }
  if (Object.keys(rules).length > 0) {
    return { rules };
  }
}

// src/pre-process-task.ts
async function preProcessTask(lintTask, { cache }) {
  var _a;
  const lintResult = createLintResult();
  const { scope, rule, file, config } = lintTask;
  if (scope === "file") {
    default4(file);
    const content = file.partialContent || file.content;
    if (!content.trim()) {
      return {
        ...lintTask,
        lintResult: { ...lintResult, skipped: true, skipReason: "empty" }
      };
    }
    if (rule.cacheable || rule.cacheable === void 0) {
      const cachedResult = await cache.get(lintTask.cacheKey);
      if (cachedResult) {
        lintResult.lintErrors = cachedResult.lintErrors;
        lintResult.message = cachedResult.message;
        lintResult.numModelCallsCached++;
        lintResult.skipped = true;
        lintResult.skipReason = "cached";
        return { ...lintTask, lintResult };
      }
    }
    if (!config.linterOptions.noInlineConfig) {
      const configFileOverride = parseInlineConfig({ file });
      if (configFileOverride) {
        if ((_a = configFileOverride.linterOptions) == null ? void 0 : _a.disabled) {
          await cache.set(lintTask.cacheKey, lintResult);
          return {
            ...lintTask,
            lintResult: {
              ...lintResult,
              skipped: true,
              skipReason: "inline-linter-disabled"
            }
          };
        } else {
          lintTask.config = mergeLinterConfigs(
            lintTask.config,
            configFileOverride
          );
        }
      }
    }
  }
  if (lintTask.config.rules[rule.name] === "off") {
    return {
      ...lintTask,
      lintResult: { ...lintResult, skipped: true, skipReason: "rule-disabled" }
    };
  }
  return lintTask;
}

// src/lint-files.ts
async function lintFiles({
  files,
  rules,
  config,
  cache,
  chatModel,
  cwd = process.cwd(),
  retryOptions = {
    retries: 2
  },
  onProgress,
  onProgressInit
}) {
  await pMap(
    rules,
    async (rule) => {
      var _a;
      return (
        // TODO: add error handling to this so one rule doesn't prevent others from
        // running properly
        (_a = rule.init) == null ? void 0 : _a.call(rule, {
          rule,
          cache,
          config,
          chatModel,
          cwd,
          retryOptions
        })
      );
    }
  );
  const fileScopeRules = rules.filter((rule) => rule.scope === "file");
  const projectLintTasks = rules.map((rule) => {
    if (rule.scope === "project" || rule.scope === "repo") {
      return createLintTask({ rule, config });
    } else {
      return void 0;
    }
  }).filter(Boolean);
  const fileLintTasks = fileScopeRules.flatMap(
    (rule) => files.map((file) => createLintTask({ file, rule, config })).filter(Boolean)
  );
  const initialLintTasks = projectLintTasks.concat(fileLintTasks);
  let lintResult = createLintResult();
  let earlyExitTripped = false;
  const warnings = [];
  const ruleNameToPartialSourceFileMap = /* @__PURE__ */ new Map();
  const preProcessTaskRunner = await task(
    `Preprocessing ${files.length} files and ${rules.length} rules`,
    async () => pMap(
      initialLintTasks,
      async (lintTask) => {
        if (earlyExitTripped) {
          return;
        }
        try {
          const { rule, scope } = lintTask;
          const model = rule.model ?? config.llmOptions.weakModel ?? config.llmOptions.model;
          if (rule.preProcessProject) {
            const partialProjectLintResult = await Promise.resolve(
              rule.preProcessProject({
                ...lintTask,
                chatModel,
                cache,
                retryOptions,
                cwd
              })
            );
            if (partialProjectLintResult) {
              const { lintErrors, skipped } = partialProjectLintResult;
              lintTask.lintResult = resolvePartialLintResult(
                lintErrors || skipped ? {
                  ...partialProjectLintResult,
                  skipped: true,
                  skipReason: "pre-process-project"
                } : partialProjectLintResult,
                {
                  model,
                  rule,
                  filePath: cwd
                }
              );
            }
          }
          if (lintTask.lintResult) {
            return lintTask;
          }
          lintTask = await preProcessTask(lintTask, { cache });
          if (lintTask.lintResult) {
            return lintTask;
          }
          if (scope === "file") {
            const file = lintTask.file;
            default4(file);
            if (rule.gritql) {
              const maybeFileLintResult = await preProcessFileWithGrit({
                file,
                files,
                rule,
                config,
                ruleNameToPartialSourceFileMap
              });
              if (maybeFileLintResult) {
                lintTask.lintResult = maybeFileLintResult;
                return lintTask;
              }
            }
            if (rule.preProcessFile) {
              const partialFileLintResult = await Promise.resolve(
                rule.preProcessFile({
                  ...lintTask,
                  file,
                  chatModel,
                  cache,
                  retryOptions,
                  cwd
                })
              );
              if (partialFileLintResult) {
                const { lintErrors, skipped } = partialFileLintResult;
                lintTask.lintResult = resolvePartialLintResult(
                  lintErrors || skipped ? {
                    ...partialFileLintResult,
                    skipped: true,
                    skipReason: "pre-process-file"
                  } : partialFileLintResult,
                  {
                    model,
                    rule,
                    file
                  }
                );
              }
            }
          }
          return lintTask;
        } catch (err) {
          const error = new Error(
            `${stringifyLintTask(lintTask)} unexpected preProcess error: ${err.message}`,
            { cause: err }
          );
          console.warn(error);
          warnings.push(error);
        } finally {
          if (lintTask.lintResult) {
            lintResult = mergeLintResults(lintResult, lintTask.lintResult);
          }
          if (config.linterOptions.earlyExit && lintResult.lintErrors.length > 0) {
            earlyExitTripped = true;
          }
        }
      },
      {
        concurrency: config.linterOptions.concurrency
      }
    )
  );
  const preProcessedLintTasks = preProcessTaskRunner.result.filter(Boolean);
  const outstandingLintTasks = preProcessedLintTasks.filter(
    (r) => {
      var _a, _b;
      return !((_a = r.lintResult) == null ? void 0 : _a.skipped) && !((_b = r.lintResult) == null ? void 0 : _b.lintErrors);
    }
  );
  const skippedLintTasks = preProcessedLintTasks.filter(
    (r) => {
      var _a, _b;
      return ((_a = r.lintResult) == null ? void 0 : _a.skipped) || ((_b = r.lintResult) == null ? void 0 : _b.lintErrors);
    }
  );
  const numTasksCached = skippedLintTasks.filter(
    (r) => r.lintResult.skipReason === "cached"
  ).length;
  const numTasksEmpty = skippedLintTasks.filter(
    (r) => r.lintResult.skipReason === "empty"
  ).length;
  const numTasksFilteredPrecheck = skippedLintTasks.filter(
    (r) => r.lintResult.skipReason === "pre-process-file" || r.lintResult.skipReason === "pre-process-project"
  ).length;
  const numTasksFilteredGrit = skippedLintTasks.filter(
    (r) => r.lintResult.skipReason === "grit-pattern"
  ).length;
  const numTasksDisabled = skippedLintTasks.filter(
    (r) => r.lintResult.skipReason === "inline-linter-disabled" || r.lintResult.skipReason === "rule-disabled"
  ).length;
  console.log(
    "Linter tasks",
    pruneUndefined({
      numFiles: files.length,
      numRules: rules.length,
      numTasks: outstandingLintTasks.length,
      numTasksCached: numTasksCached || void 0,
      numTasksFilteredPrecheck: numTasksFilteredPrecheck || void 0,
      numTasksFilteredGrit: numTasksFilteredGrit || void 0,
      numTasksEmpty: numTasksEmpty || void 0,
      numTasksDisabled: numTasksDisabled || void 0
    })
  );
  if (config.linterOptions.debug) {
    console.log(
      outstandingLintTasks.map(
        (task2) => {
          var _a;
          return pruneUndefined({
            file: (_a = task2.file) == null ? void 0 : _a.fileRelativePath,
            rule: task2.rule.name
          });
        }
      )
    );
  }
  if (config.linterOptions.earlyExit && lintResult.lintErrors.length > 0) {
    earlyExitTripped = true;
  }
  if (onProgressInit) {
    await Promise.resolve(
      onProgressInit({ numTasks: outstandingLintTasks.length })
    );
  }
  const lintTaskGroups = {};
  for (const lintTask of outstandingLintTasks) {
    const { group } = lintTask;
    if (!lintTaskGroups[group]) {
      const lintTaskGroupName = config.linterOptions.dryRun ? `Dry run ${group}` : `Linting ${group}`;
      const lintTaskP = createPromiseWithResolvers();
      lintTaskGroups[group] = {
        ...lintTaskP,
        lintTasks: [],
        lintResults: [],
        taskP: void 0,
        innerTask: void 0,
        async init() {
          if (!this.taskP) {
            await new Promise((resolve) => {
              this.taskP = task(lintTaskGroupName, async (innerTask) => {
                this.innerTask = innerTask;
                resolve();
                return lintTaskP;
              });
            });
          }
        }
      };
    }
    const lintTaskGroup = lintTaskGroups[group];
    lintTaskGroup.lintTasks.push(lintTask);
  }
  let sortedLintTasks = [];
  for (const lintTaskGroup of Object.values(lintTaskGroups)) {
    sortedLintTasks = sortedLintTasks.concat(lintTaskGroup.lintTasks);
    lintTaskGroup.promise = Promise.all(
      lintTaskGroup.lintTasks.map((t) => t.promise)
    );
    lintTaskGroup.promise.then((value) => {
      lintTaskGroup.resolve(value);
      const hasLintErrors = lintTaskGroup.lintResults.some(
        (result) => result.lintErrors.length > 0
      );
      if (!hasLintErrors) {
        lintTaskGroup.taskP.then((task2) => {
          task2.clear();
        });
      }
    }, lintTaskGroup.reject);
  }
  await pMap(
    sortedLintTasks,
    async (lintTask, index) => {
      if (earlyExitTripped) {
        return;
      }
      const {
        group,
        scope,
        file,
        rule,
        cacheKey,
        config: config2,
        lintResult: preProcessedTaskLintResult
      } = lintTask;
      const lintTaskGroup = lintTaskGroups[group];
      default4(lintTaskGroup);
      await lintTaskGroup.init();
      const lintTaskGroupInnerTask = lintTaskGroup.innerTask;
      let taskLintResult;
      let taskLintError;
      const nestedTask = await lintTaskGroupInnerTask.task(
        rule.name,
        async (task2) => {
          var _a, _b;
          try {
            const processProjectFnParams = {
              rule,
              lintResult: preProcessedTaskLintResult,
              chatModel,
              cache,
              config: config2,
              cwd,
              retryOptions: {
                ...retryOptions,
                onFailedAttempt: (err) => {
                  var _a2;
                  task2.setOutput(`Retrying: ${err.message}`);
                  return (_a2 = retryOptions.onFailedAttempt) == null ? void 0 : _a2.call(retryOptions, err);
                }
              }
            };
            if (scope === "file") {
              const processFileFn = rule.processFile ?? lintFile;
              const processFileFnParams = {
                ...processProjectFnParams,
                file
              };
              const partialTaskLintResult = await processFileFn(processFileFnParams);
              taskLintResult = resolvePartialLintResult(partialTaskLintResult, {
                rule,
                file
              });
              if (rule.postProcessFile) {
                const partialPostTaskLintResult = await Promise.resolve(
                  rule.postProcessFile({
                    ...processFileFnParams,
                    lintResult: taskLintResult
                  })
                );
                if (partialPostTaskLintResult) {
                  taskLintResult = resolvePartialLintResult(
                    partialPostTaskLintResult,
                    {
                      rule,
                      file
                    }
                  );
                }
              }
            } else {
              if (rule.processProject) {
                const partialTaskLintResult = await rule.processProject(
                  processProjectFnParams
                );
                taskLintResult = resolvePartialLintResult(
                  partialTaskLintResult,
                  {
                    rule,
                    file
                  }
                );
              }
              if (rule.postProcessProject) {
                const partialPostTaskLintResult = await Promise.resolve(
                  rule.postProcessProject({
                    ...processProjectFnParams,
                    lintResult: taskLintResult
                  })
                );
                if (partialPostTaskLintResult) {
                  taskLintResult = resolvePartialLintResult(
                    partialPostTaskLintResult,
                    {
                      rule,
                      file
                    }
                  );
                }
              }
            }
            if (!taskLintResult) {
              return;
            }
            if (cacheKey) {
              await cache.set(cacheKey, taskLintResult);
            }
            lintResult = mergeLintResults(lintResult, taskLintResult);
            const { lintErrors } = taskLintResult;
            if (config2.linterOptions.earlyExit && lintErrors.length > 0) {
              earlyExitTripped = true;
            }
            if (onProgress) {
              await Promise.resolve(
                onProgress({
                  progress: index / sortedLintTasks.length,
                  message: stringifyLintTask(lintTask),
                  result: lintResult
                })
              );
            }
            if (lintErrors.length > 0) {
              const lintErrorPrefixDesc = `found ${lintErrors.length} lint ${plur3(
                "error",
                lintErrors.length
              )}`;
              const lintErrorShortDesc = lintErrors.length === 1 ? `\`${trimMessage(
                ((_a = lintErrors[0]) == null ? void 0 : _a.codeSnippet) ?? ((_b = lintErrors[0]) == null ? void 0 : _b.message),
                { maxLength: 60 }
              )}\`` : "";
              const lintErrorDesc = [lintErrorPrefixDesc, lintErrorShortDesc].filter(Boolean).join(" ");
              task2.setError(lintErrorDesc);
            }
          } catch (err) {
            const error = new Error(
              `${stringifyLintTask(lintTask)} unexpected error: ${err.message}`,
              { cause: err }
            );
            console.warn(error);
            taskLintError = error;
            warnings.push(error);
            task2.setError(err.message);
          }
        }
      );
      if (taskLintResult) {
        if (!taskLintResult.lintErrors.length) {
          nestedTask.clear();
        }
        lintTaskGroup.lintResults.push(taskLintResult);
      } else if (!taskLintError) {
        nestedTask.clear();
      }
      lintTask.resolve(void 0);
    },
    {
      concurrency: config.linterOptions.concurrency
    }
  );
  lintResult.endedAtMs = Date.now();
  return lintResult;
}

// src/resolve-cli-config.ts
import { readFile } from "node:fs/promises";
import { cli } from "cleye";
import { gracefulExit as gracefulExit2 } from "exit-hook";
import parseGitIgnore from "parse-gitignore";
import { pathExists as pathExists3 } from "path-exists";
import plur5 from "plur";

// src/resolve-config.ts
import path9 from "node:path";
import { pathExists as pathExists2 } from "path-exists";

// rules/custom/index.ts
var custom_exports = {};
__export(custom_exports, {
  effectiveTSConfig: () => effectiveTSConfig,
  preferFetchOverAxios: () => preferFetchOverAxios
});

// rules/custom/effective-tsconfig.ts
import { getTsconfig } from "get-tsconfig";

// src/parse-rule-file.ts
import { parseDocument as parseYAMLDocument } from "yaml";
async function parseRuleFile({
  content,
  filePath
}) {
  var _a, _b;
  const ast = parseMarkdownAST(content);
  const h1RuleNodes = findAllHeadingNodes(ast, { depth: 1 });
  default4(
    h1RuleNodes.length === 1,
    `Rule file must contain a single h1 header: ${filePath}`
  );
  const yamlNodes = findAllYAMLNodes(ast);
  default4(
    h1RuleNodes.length <= 1,
    `Rule must not contain more than 1 yaml frontmatter nodes: ${filePath}`
  );
  const maybePartialRule = yamlNodes.length === 1 ? parseRuleFrontmatter((_a = yamlNodes[0]) == null ? void 0 : _a.value) : void 0;
  const headingRuleNode = h1RuleNodes[0];
  let bodyRuleNodes = findAllBetween(ast, headingRuleNode);
  const gritCodeBlockNodes = findAllCodeBlockNodes(ast).filter(
    (codeNode) => codeNode.lang === "grit" || codeNode.lang === "gritql"
  );
  default4(
    gritCodeBlockNodes.length <= 1,
    `Rule must not contain more than 1 "grit" code blocks: ${filePath}`
  );
  const codeBlockNode = gritCodeBlockNodes[0];
  let gritql;
  if (codeBlockNode) {
    gritql = (_b = convertASTToPlaintext(codeBlockNode)) == null ? void 0 : _b.trim();
    bodyRuleNodes = bodyRuleNodes.filter((node) => node !== codeBlockNode);
  }
  const rule = parseRuleNode({
    headingRuleNode,
    bodyRuleNodes,
    filePath,
    partialRule: {
      ...maybePartialRule,
      gritql
    }
  });
  return validateRule(rule);
}
function parseRuleFrontmatter(yaml) {
  if (!yaml) {
    return;
  }
  try {
    const yamlData = parseYAMLDocument(yaml).toJSON();
    const parsedRule = RuleDefinitionSchema.strict().safeParse({
      name: "dummy-rule-title",
      title: "dummy rule title",
      ...yamlData
    });
    if (!parsedRule.success) {
      throw new Error(
        `Rule contains invalid frontmatter metadata: ${parsedRule.error}`
      );
    }
    const rule = parsedRule.data;
    return omit(rule, "name", "title");
  } catch (err) {
    throw new Error(`Error parsing rule frontmatter: ${err.message}`, {
      cause: err
    });
  }
}

// src/resolve-files.ts
import fs4 from "node:fs/promises";
import path7 from "node:path";
import pMap2 from "p-map";
import plur4 from "plur";

// src/is-valid-source-file.ts
import fs3 from "node:fs/promises";
import path6 from "node:path";

// src/is-binary-file.ts
import { fileTypeFromFile } from "file-type";
var textFileMimeTypePrefixes = [
  "text/",
  "application/json",
  "application/xml",
  "application/javascript"
];
async function isBinaryFile(filePath) {
  try {
    const fileType = await fileTypeFromFile(filePath);
    if (!fileType) {
      return false;
    }
    for (const mimeTypePrefix of textFileMimeTypePrefixes) {
      if (fileType.mime.startsWith(mimeTypePrefix)) {
        return false;
      }
    }
    return true;
  } catch (err) {
    throw new Error(`Error reading file: ${filePath}: ${err.message}`, {
      cause: err
    });
  }
}

// src/is-valid-source-file.ts
var knownGeneratedFileNames = /* @__PURE__ */ new Set([
  "package-lock.json",
  "pnpm-lock.yaml",
  "yarn.lock",
  "bun.lockb"
]);
async function isValidSourceFile(filePath, {
  minFileSizeBytes = minSourceFileSizeBytes,
  maxFileSizeBytes = maxSourceFileSizeBytes
} = {}) {
  try {
    if (!filePath) {
      return false;
    }
    const fileName = path6.basename(filePath);
    if (!fileName) {
      return false;
    }
    if (knownGeneratedFileNames.has(fileName)) {
      return false;
    }
    const stats = await fs3.stat(filePath);
    if (!stats.isFile()) {
      return false;
    }
    if (stats.size <= minFileSizeBytes) {
      return false;
    }
    if (stats.size > maxFileSizeBytes) {
      return false;
    }
    if (await isBinaryFile(filePath)) {
      return false;
    }
    return true;
  } catch (err) {
    throw new Error(`Error reading file: ${filePath}: ${err.message}`, {
      cause: err
    });
  }
}

// src/resolve-files.ts
async function resolveFiles({
  config,
  cwd = process.cwd()
}) {
  const sourceFilePaths = await resolveGlobFilePatterns(config.files, {
    gitignore: true,
    ignore: config.ignores,
    cwd
  });
  const sourceFiles = await readSourceFiles(sourceFilePaths, {
    concurrency: config.linterOptions.concurrency
  });
  return sourceFiles;
}
async function readSourceFiles(filePaths, {
  concurrency = 32,
  cwd = process.cwd(),
  minFileSizeBytes,
  maxFileSizeBytes,
  maxFileNumLines = maxSourceFileNumLines,
  maxFileLineLength = maxSourceFileLineLength
} = {}) {
  filePaths.sort((a, b) => b.localeCompare(a));
  return (await pMap2(
    filePaths,
    async (filePath) => {
      var _a;
      filePath = path7.resolve(cwd, filePath);
      if (!await isValidSourceFile(filePath, {
        minFileSizeBytes,
        maxFileSizeBytes
      })) {
        console.warn(`Ignoring invalid source file: ${filePath}`);
        return;
      }
      let content = await fs4.readFile(filePath, { encoding: "utf8" });
      if (!content.trim()) {
        console.warn(`Ignoring empty source file: ${filePath}`);
        return;
      }
      let lines = content.split(/\r?\n/);
      if (lines.length > maxFileNumLines) {
        console.warn(
          `Ignoring source file with too many lines: ${filePath} (${lines.length} is more than the configured limit ${maxFileNumLines})`
        );
        return;
      }
      let numLongLines = 0;
      lines = lines.map((line) => {
        if (line.length > maxFileLineLength) {
          ++numLongLines;
          return line.slice(0, maxFileLineLength);
        } else {
          return line;
        }
      });
      if (numLongLines > 1) {
        console.warn(
          `Ignoring source file with ${numLongLines} long ${plur4("line", numLongLines)}: ${filePath} (a long line has at least ${maxFileLineLength} characters, and a file can have at most 1 long line which will be truncated)`
        );
        return;
      }
      if (numLongLines > 0) {
        content = lines.join("\n");
      }
      const fileRelativePath = path7.relative(cwd, filePath);
      const fileName = path7.basename(filePath);
      const ext = ((_a = fileName.split(".").at(-1)) == null ? void 0 : _a.toLowerCase()) ?? "";
      const jsExtensions = /* @__PURE__ */ new Set(["js", "jsx", "cjs", "mjs"]);
      const tsExtensions = /* @__PURE__ */ new Set(["ts", "tsx"]);
      const language = jsExtensions.has(ext) ? "javascript" : tsExtensions.has(ext) ? "typescript" : "unknown";
      return {
        filePath,
        fileRelativePath,
        fileName,
        language,
        content
      };
    },
    {
      concurrency
    }
  )).filter(Boolean);
}

// src/resolve-rules.ts
import fs5 from "node:fs/promises";
import path8 from "node:path";
import pMap3 from "p-map";
async function resolveRules({
  config,
  cwd = process.cwd()
}) {
  const ruleFilePaths = await resolveGlobFilePatterns(config.ruleFiles ?? [], {
    gitignore: true,
    cwd
  });
  const processedRuleFilePaths = /* @__PURE__ */ new Set();
  let rules = (await pMap3(
    ruleFilePaths,
    async (ruleFilePath) => {
      try {
        if (processedRuleFilePaths.has(ruleFilePath)) {
          return;
        }
        processedRuleFilePaths.add(ruleFilePath);
        const ruleFilePathAbsolute = path8.join(cwd, ruleFilePath);
        const ruleFileContent = await fs5.readFile(
          ruleFilePathAbsolute,
          "utf8"
        );
        const rule = await parseRuleFile({
          content: ruleFileContent,
          filePath: ruleFilePath
        });
        return rule;
      } catch (err) {
        throw new Error(
          `Error parsing rule file "${ruleFilePath}": ${err.message}`,
          { cause: err }
        );
      }
    },
    {
      concurrency: config.linterOptions.concurrency
    }
  )).filter(Boolean);
  const customRules = (config.ruleDefinitions ?? []).map(
    (ruleDefinition) => {
      const rule = {
        source: "custom",
        cacheable: true,
        ...ruleDefinition,
        metadata: {}
      };
      default4(isValidRuleName(rule.name), `Invalid rule name "${rule.name}"`);
      return rule;
    }
  );
  rules = customRules.concat(rules);
  const processedRules = /* @__PURE__ */ new Set();
  rules = rules.filter((rule) => {
    rule = validateRule(rule);
    if (processedRules.has(rule.name)) {
      return false;
    }
    processedRules.add(rule.name);
    return true;
  });
  if (config.rules) {
    rules = rules.filter((rule) => config.rules[rule.name] !== "off");
  }
  return rules;
}

// rules/custom/effective-tsconfig.ts
var tsConfigCache = /* @__PURE__ */ new Map();
var effectiveTSConfig = {
  name: "effective-tsconfig",
  title: "Follow tsconfig best practices",
  level: "error",
  scope: "project",
  resources: [
    "https://typescriptlang.org/tsconfig",
    "https://www.youtube.com/watch?v=eJXVEju3XLM&ab_channel=MattPocock"
  ],
  preProcessProject: async ({ rule, cache, config, cwd }) => {
    var _a, _b, _c;
    const parsedTSConfig = getTsconfig(cwd, "tsconfig.json", tsConfigCache);
    if (!parsedTSConfig) {
      return {
        lintErrors: [
          {
            message: "No tsconfig found."
          }
        ]
      };
    }
    const { config: tsconfig, path: filePath } = parsedTSConfig;
    const lintErrors = [];
    const cacheKey = createCacheKey({ rule, config, filePath, tsconfig });
    const cachedResult = await cache.get(cacheKey);
    if (cachedResult) {
      return cachedResult;
    }
    if (!((_a = tsconfig.compilerOptions) == null ? void 0 : _a.strict)) {
      lintErrors.push({
        message: 'Recommended setting "strict" to `true`.',
        level: "warn",
        filePath
      });
    }
    if (!((_b = tsconfig.compilerOptions) == null ? void 0 : _b.forceConsistentCasingInFileNames)) {
      lintErrors.push({
        message: 'Recommended setting "forceConsistentCasingInFileNames" to `true`.',
        level: "warn",
        filePath
      });
    }
    if (!((_c = tsconfig.compilerOptions) == null ? void 0 : _c.noUncheckedIndexedAccess)) {
      lintErrors.push({
        message: 'Recommended setting "noUncheckedIndexedAccess" to `true`.',
        level: "warn",
        filePath
      });
    }
    await cache.set(cacheKey, { lintErrors });
    return { lintErrors };
  }
};

// rules/custom/prefer-fetch-over-axios.ts
var preferFetchOverAxios = {
  name: "prefer-fetch-over-axios",
  title: "Prefer fetch over axios",
  level: "error",
  scope: "file",
  description: `The NPM package \`axios\` should be avoided in favor of native \`fetch\`. Now that native \`fetch\` has widespread support, \`axios\` is effectively deprecated and is generally a code smell when encountered.

  Convenience wrappers around \`fetch\` such as \`ky\` and \`ofetch\` are encouraged.
  
  Code which doesn't use the \`axios\` module should be ignored.`,
  tags: ["best practices"],
  eslint: ["no-restricted-imports"],
  preProcessFile: async (ctx) => {
    if (!/["']axios["']/g.test(ctx.file.content)) {
      return {
        lintErrors: []
      };
    } else {
    }
  }
};

// src/built-in-rules.json
var built_in_rules_default = [
  {
    source: "/Users/tfischer/dev/modules/gptlint/rules/always-handle-promises.md",
    cacheable: true,
    metadata: {},
    name: "always-handle-promises",
    title: "Always handle Promises",
    description: "Promises (and `async` functions which implicitly create Promises) must always be handled at some level of the program, either via:\n\n- using `await` to wait for the Promise to resolve successfully\n- using `.then` or `.catch` to handle Promise resolution\n- returning a Promise to a calling function which itself has to handle the Promise\n\nCreating a Promise or calling an `async` function and NOT awaiting or propagating the resulting Promise using one of these approaches is a code smell and violates this rule.\n\n**Important**: This rule should only apply to function calls which you are 100% sure return a `Promise`. If you do not know for sure that a function returns a `Promise`, then disregard it.\n",
    positiveExamples: [
      {
        code: "async function saveFile() {\n  // ...\n}\n\n// This is fine because we explicitly `await` the Promise returned by `saveFile`\nawait saveFile()",
        language: "js"
      },
      {
        code: "async function saveFile() {\n  // ...\n}\n\n// This is fine because the Promise returned from `saveFile` is propagated to `main`'s caller\nasync function main() {\n  return saveFile()\n}",
        language: "js"
      },
      {
        code: "async function saveFile() {\n  // ...\n}\n\n// This is fine because we explicitly `await` the promise results\nawait Promise.all([saveFile(), saveFile()])",
        language: "js"
      }
    ],
    negativeExamples: [
      {
        code: "async function saveFile() {\n  // ...\n}\n\n// This is bad because we're not handling the Promise returned by `saveFile`\nsaveFile()",
        language: "js"
      }
    ],
    fixable: false,
    level: "error",
    scope: "file",
    languages: [
      "javascript",
      "typescript"
    ],
    tags: [
      "best practices"
    ]
  },
  {
    source: "/Users/tfischer/dev/modules/gptlint/rules/avoid-type-info-in-docs.md",
    cacheable: true,
    metadata: {},
    name: "avoid-type-info-in-docs",
    title: "Don\u2019t repeat type information in documentation",
    description: "Avoid repeating type information in comments and variable names. In the best case it is duplicative of type declarations, and in the worst it will lead to conflicting information.\n\nConsider including units in variable names if they aren\u2019t clear from the type (e.g., timeMs or temperatureC).\n\nHere is an example of incorrect code:\n\n```ts\n/**\n * Returns a string with the foreground color.\n * Takes zero or one arguments. With no arguments, returns the standard\n * foreground color. With one argument, returns the foreground color for a\n * particular page.\n */\nfunction getForegroundColor(page?: string) {\n  return page === 'login' ? { r: 127, g: 127, b: 127 } : { r: 0, g: 0, b: 0 }\n}\n```\n\nThis is a VIOLATION because the comment describes the types of the function parameters and return type which duplicates the more precise TS definition. Even worse, this example is a VIOLATION because the code and the comment contradict each other.\n\nLet\u2019s assume that the code represents the desired behavior. There are a few issues with this comment:\n\n- It says that the function returns the color as a string when it actually returns an `{r, g, b}` object.\n- It explains that the function takes zero or one arguments, which is already clear from the type signature.\n- It\u2019s needlessly wordy: the comment is longer than the function declaration and implementation.\n\nSince your type annotations are checked by the TypeScript compiler, they\u2019ll never get out of sync with the implementation.\n\nA better comment might look like this:\n\n```ts\n/** Get the foreground color for the application or a specific page. */\nfunction getForegroundColor(page?: string): Color {\n  // ...\n}\n```\n\nComments about a lack of mutation are also suspect. Don\u2019t just say that you don\u2019t modify a parameter:\n\n```ts\n/** Does not modify nums */\nfunction sort(nums: number[]) {\n  /* ... */\n}\n```\n\nInstead, declare the parameter as `readonly` and let TypeScript enforce the contract:\n\n```ts\nfunction sort(nums: readonly number[]) {\n  /* ... */\n}\n```\n\n## Caveats\n\nNote that you do NOT have to include JSDoc comments for a function, and you do NOT have to include `@param` or `@returns` JSDoc properties. These are purely optional, but if they are included, they should not discuss the types of function parameters because TypeScript does a better job of capturing this info in the function definition itself.\n\nIf a comment is providing useful context or clarifying what a parameter is used for, then it should be ignored. This rule is only aimed at comments which duplicate type info or comments which imply immutability.\n",
    positiveExamples: [
      {
        code: "/**\n * Upserts a user into the database.\n */\nexport async function upsertUser(\n  user: User | NewUserData,\n  ctx?: Context\n): Promise<User> {\n  // ...\n}",
        language: "ts"
      },
      {
        code: "/**\n * Upserts a user into the database.\n *\n * @param user - The user to upsert.\n * @param ctx - Optional context for the database operation.\n *\n * @returns The upserted user.\n */\nexport async function upsertUser(\n  user: User | NewUserData,\n  ctx?: Context\n): Promise<User> {\n  // ...\n}",
        language: "ts"
      },
      {
        code: "/**\n * Parses a string using a zod schema.\n *\n * @param output - string to parse\n * @param outputSchema - zod schema\n *\n * @returns parsed output\n */\nexport function parseStructuredOutput<T>(\n  output: string,\n  outputSchema: ZodType<T>\n): T {\n  // ...\n}\n\n// This example is fine because the type info in the JSDoc `@param` comments is relevant and simple.",
        language: "ts"
      }
    ],
    negativeExamples: [],
    fixable: false,
    level: "error",
    scope: "file",
    languages: [
      "typescript"
    ],
    tags: [
      "best practices"
    ],
    resources: [
      "https://effectivetypescript.com"
    ],
    exclude: [
      "**/*\\.test\\.{js,ts,jsx,tsx,cjs,mjs}"
    ],
    gritql: "comment",
    gritqlNumLinesContext: 3
  },
  {
    source: "/Users/tfischer/dev/modules/gptlint/rules/consistent-identifier-casing.md",
    cacheable: true,
    metadata: {},
    name: "consistent-identifier-casing",
    title: "Be consistent with identifier casing",
    description: "Identifiers of the same type should try to use consistent casing.\n\nVariable names should use camelCase.\nGlobal const variable names should either use camelCase, PascalCase, or CONSTANT\\_CASE.\nType names should use PascalCase.\nClass names should use PascalCase.\nFunction names should use camelCase.\n\nExamples of camelCase identifiers include: foo, fooBar, h1RuleNodes, cwd, apiBaseUrl, apiBaseURL, validRuleTableKeysL, and \\_getKey.\n\n## Caveats\n\nThird-party APIs may use inconsistent casing, which is an exception to this rule.\n\nKeys in JSON objects, JS objects, and TypeScript objects may use inconsistent casing, so they are exceptions to this rule.\n\nIgnore identifiers which mix PascalCase with camelCase.\n\nIgnore the casing of common acronyms like API, IP, HTTP, and LLM.\n\nIgnore the casing of identifiers which start with acronyms like `LLMOptionsSchema`.\n\nIgnore parameter names used in inline functions.\n\nIgnore string literals and module names for this rule.\n\nClass member variables and functions may include `_` prefixes.\n",
    positiveExamples: [
      {
        code: "const fooBar = true\nconst defaultTimeout = 5000\n\nfunction helloWorld() {}\nfunction helloTwitter() {}",
        language: "ts"
      },
      {
        code: "import foo from 'foo'\n\n// This is fine because `foo` is a third-party API which this rule should ignore.\nfoo({ camelCase: true, snake_case: true, SNAKE_CASE: true })",
        language: "ts"
      },
      {
        code: "// These are all fine as common exceptions to this rule\nexport const HTTPConfig = {}\nconst LLMOptions = {}\nconst validKeysL = new Set()\nconst loadingP = new Promise()\nconst cwd = process.cwd",
        language: "ts"
      },
      {
        code: "// This is fine because `i` is a parameter of an inline function and `res` is a common exception.\nconst res = [1, 2, 3].filter((i) => i >= 0)",
        language: "ts"
      }
    ],
    negativeExamples: [
      {
        code: "// These are bad because variable identifiers should use consistent casing.\nconst fooBar = true\nconst default_timeout = 5000\n\n// These are bad because function identifiers should use consistent casing.\nfunction helloWorld() {}\nfunction hello_twitter() {}",
        language: "ts"
      }
    ],
    fixable: false,
    level: "error",
    scope: "file",
    languages: [
      "javascript",
      "typescript"
    ],
    tags: [
      "best practices"
    ],
    eslint: [
      "@typescript-eslint/naming-convention",
      "camelcase"
    ],
    gritql: "or {\n  type_identifier() as $id where {\n    and {\n      $id <: within or {\n        type_alias_declaration($name),\n        interface_declaration($name),\n        class_declaration($name)\n      },\n      $id <: $name\n    }\n  },\n\n  identifier() as $id where {\n    or {\n      and {\n        $id <: within or {\n          variable_declarator($name),\n          function_declaration($name),\n          class_declaration($name),\n          method_signature($name),\n          method_definition($name),\n          required_parameter($name),\n          optional_parameter($name)\n        },\n        $id <: $name\n      },\n\n      or {\n        and {\n          $id <: within `function $func($props): $ret {$body}`,\n          $id <: not or { within $body, within $func }\n        },\n        and {\n          $id <: within `function $func($props) {$body}`,\n          $id <: not or { within $body, within $func }\n        },\n        and {\n          $id <: within `($props) => $body`,\n          $id <: not or { within $body }\n        }\n      }\n    }\n  },\n\n  property_identifier() as $id where {\n    and {\n      $id <: within or { method_signature($name), method_definition($name) },\n      $id <: $name\n    }\n  }\n}"
  },
  {
    source: "/Users/tfischer/dev/modules/gptlint/rules/liberal-accept-strict-produce.md",
    cacheable: true,
    metadata: {},
    name: "liberal-accept-strict-produce",
    title: "Be liberal in what you accept and strict in what you produce",
    description: "This idea is known as the robustness principle or Postel\u2019s Law.\n\nAs a general best practice, input types should be broader than output types. Optional properties and union types are more common in parameter types than return types.\n\nTo reuse types between parameters and return types, it's often useful to introduce a canonical form (for return types) and a looser form (for parameters).\n\n---\n\nAs an example, a 3D mapping API might provide a way to position the camera and to calculate a viewport for a bounding box:\n\n```ts\ndeclare function setCamera(camera: CameraOptions): void\ndeclare function viewportForBounds(bounds: LngLatBounds): CameraOptions\n```\n\nIt is convenient that the result of `viewportForBounds` can be passed directly to `setCamera` to position the camera.\n\nLet\u2019s look at the definitions of these types:\n\n```ts\ninterface CameraOptions {\n  center?: LngLat\n  zoom?: number\n  bearing?: number\n  pitch?: number\n}\n\ntype LngLat =\n  | { lng: number; lat: number }\n  | { lon: number; lat: number }\n  | [number, number]\n```\n\nThe fields in `CameraOptions` are all optional because you might want to set just the center or zoom without changing the bearing or pitch. The `LngLat` type also makes `setCamera` liberal in what it accepts: you can pass in a `{lng, lat}` object, a `{lon, lat}` object, or a `[lng, lat]` pair if you\u2019re confident you got the order right. These accommodations make the function easy to call.\n\nThe viewportForBounds function takes in another \u201Cliberal\u201D type:\n\n```ts\ntype LngLatBounds =\n  | { northeast: LngLat; southwest: LngLat }\n  | [LngLat, LngLat]\n  | [number, number, number, number]\n```\n\nYou can specify the bounds either using named corners, a pair of lat/lngs, or a four- tuple if you\u2019re confident you got the order right. Since LngLat already accommodates three forms, there are no fewer than 19 possible forms for LngLatBounds. Liberal indeed!\n\nNow let\u2019s write a function that adjusts the viewport to accommodate a GeoJSON Fea\u2010 ture and stores the new viewport in the URL:\n\n```ts\nfunction focusOnFeature(f: Feature) {\n  const bounds = calculateBoundingBox(f)\n  const camera = viewportForBounds(bounds)\n  setCamera(camera)\n  const {\n    center: { lat, lng },\n    zoom\n  } = camera\n  // ~~~ Property 'lat' does not exist on type ...\n  // ~~~ Property 'lng' does not exist on type ... zoom; // Type is number | undefined\n  window.location.search = `?v=@${lat},${lng}z${zoom}`\n}\n```\n\nWhoops! Only the zoom property exists, but its type is inferred as `number|undefined`, which is also problematic. The issue is that the type declaration for `viewportFor Bounds` indicates that it is liberal not just in what it accepts but also in what it pro\u2010 duces. The only type-safe way to use the camera result is to introduce a code branch for each component of the union type.\n\nThe return type with lots of optional properties and union types makes `viewportFor Bounds` difficult to use. **Its broad parameter type is convenient, but its broad return type is not. A more convenient API would be strict in what it produces.**\n\nOne way to do this is to distinguish a canonical format for coordinates. Following JavaScript\u2019s convention of distinguishing \u201CArray\u201D and \u201CArray-like\u201D, you can draw a distinction between `LngLat` and `LngLatLike`. You can also distinguish between a fully defined Camera type and the partial version accepted by setCamera:\n\n```ts\ninterface LngLat {\n  lng: number\n  lat: number\n}\ntype LngLatLike = LngLat | { lon: number; lat: number } | [number, number]\ninterface Camera {\n  center: LngLat\n  zoom: number\n  bearing: number\n  pitch: number\n}\ninterface CameraOptions extends Omit<Partial<Camera>, 'center'> {\n  center?: LngLatLike\n}\ntype LngLatBounds =\n  | { northeast: LngLatLike; southwest: LngLatLike }\n  | [LngLatLike, LngLatLike]\n  | [number, number, number, number]\n\ndeclare function setCamera(camera: CameraOptions): void\ndeclare function viewportForBounds(bounds: LngLatBounds): Camera\n```\n\nThe loose `CameraOptions` type adapts the stricter `Camera` type.\n\nUsing `Partial<Camera>` as the parameter type in `setCamera` would not work here since you do want to allow `LngLatLike` objects for the `center` property. And you can\u2019t write `\"CameraOptions extends Partial<Camera>\"` since `LngLatLike` is a superset of `LngLat`, not a subset. If this seems too complicated, you could also write the type out explicitly at the cost of some repetition:\n\n```ts\ninterface CameraOptions {\n  center?: LngLatLike\n  zoom?: number\n  bearing?: number\n  pitch?: number\n}\n```\n\nIn either case, with these new type declarations the `focusOnFeature` function passes the type checker:\n\n```ts\nfunction focusOnFeature(f: Feature) {\n  const bounds = calculateBoundingBox(f)\n  const camera = viewportForBounds(bounds)\n  setCamera(camera)\n\n  const {\n    center: { lat, lng },\n    zoom\n  } = camera // OK zoom; // Type is number\n  window.location.search = `?v=@${lat},${lng}z${zoom}`\n}\n```\n\nThis time the type of zoom is number, rather than `number|undefined`. The `viewport ForBounds` function is now much easier to use. If there were any other functions that produced bounds, you would also need to introduce a canonical form and a distinction between `LngLatBounds` and `LngLatBoundsLike`.\n\nIs allowing 19 possible forms of bounding box a good design? Perhaps not. But if you\u2019re writing type declarations for a library that does this, you need to model its behavior. Just don\u2019t have 19 return types.\n",
    positiveExamples: [],
    negativeExamples: [],
    fixable: false,
    level: "error",
    scope: "file",
    languages: [
      "typescript"
    ],
    tags: [
      "best practices"
    ],
    resources: [
      "https://effectivetypescript.com"
    ],
    exclude: [
      "**/*\\.test\\.{js,ts,jsx,tsx,cjs,mjs}"
    ],
    gritql: "function_declaration",
    gritqlNumLinesContext: 3
  },
  {
    source: "/Users/tfischer/dev/modules/gptlint/rules/no-hardcoded-secrets.md",
    cacheable: true,
    metadata: {},
    name: "no-hardcoded-secrets",
    title: "No hardcoded secrets",
    description: "Sensitive secrets should never be hardcoded in git because they represent a serious security risk.\n\nCommon use cases for secrets include:\n\n- private API keys and tokens\n- authentication and authorization\n- third-party service config\n- private encryption keys\n- cryptographic secrets for signing requests\n\nThe most common solution is to only access secrets from environment variables so they aren't committed as code.\n",
    positiveExamples: [
      {
        code: "const apiKey = process.env.OPENAI_API_KEY",
        language: "js"
      },
      {
        code: "const apiKey = process.env['OPENAI_API_KEY']",
        language: "js"
      },
      {
        code: "const apiKey = getEnv('OPENAI_API_KEY')",
        language: "js"
      },
      {
        code: "import OpenAI from 'openai'\n\nconst openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY\n})",
        language: "ts"
      }
    ],
    negativeExamples: [
      {
        code: "const apiKey = 'sk-J6tsSvil9M7zF76PkyU...'",
        language: "js"
      },
      {
        code: "import OpenAI from 'openai'\n\nconst openai = new OpenAI({\n  apiKey: 'sk-J6tsSvil9M7zF76PkyU...'\n})",
        language: "js"
      }
    ],
    fixable: false,
    level: "error",
    scope: "file",
    languages: [
      "all"
    ],
    tags: [
      "security"
    ],
    gritql: "or { string(), template_string() } as $str where {\n  $str <: not within import_statement(),\n  $length = length($str),\n  not or {\n    $length <: 1,\n    $length <: 2,\n    $length <: 3,\n    $length <: 4,\n    $length <: 5,\n    $length <: 6,\n  }\n}",
    gritqlNumLinesContext: 3
  },
  {
    source: "/Users/tfischer/dev/modules/gptlint/rules/prefer-array-at-negative-indexing.md",
    cacheable: true,
    metadata: {},
    name: "prefer-array-at-negative-indexing",
    title: "Prefer using Array.at when indexing from the end of an array",
    description: "When accessing items in an array from the end, like the last item, prefer using `Array.at` with a negative index because it is less error-prone. Note that using `Array.at` with a positive index is equivalent to indexing into the array normally, and if `Array.at` references a non-existing index, it will return `undefined`.\n",
    positiveExamples: [
      {
        code: "const items = [1, 2, 3, 4, 5, 6, 7]\nconst lastItem = items.at(-1)",
        language: "ts"
      },
      {
        code: "const items = [1, 2, 3, 4, 5, 6, 7]\n\n// This example is fine because it uses a normal, positive index\nconst firstItem = items[0]",
        language: "ts"
      },
      {
        code: "const items = [1, 2, 3, 4, 5, 6, 7]\nconst index = example()\n\n// This example is fine because it uses a variable index\nconst item = items[index]",
        language: "ts"
      }
    ],
    negativeExamples: [
      {
        code: "const items = [1, 2, 3, 4, 5, 6, 7]\nconst lastItem = items[items.length - 1]",
        language: "ts"
      }
    ],
    fixable: false,
    level: "error",
    scope: "file",
    languages: [
      "javascript",
      "typescript"
    ],
    tags: [
      "best practices"
    ],
    eslint: [
      "@unicorn/prefer-negative-index"
    ],
    resources: [
      "https://twitter.com/housecor/status/1768622518179369036"
    ],
    gritql: "subscript_expression",
    gritqlNumLinesContext: 3
  },
  {
    source: "/Users/tfischer/dev/modules/gptlint/rules/prefer-loose-array-bounds-checks-in-loops.md",
    cacheable: true,
    metadata: {},
    name: "prefer-loose-array-bounds-checks-in-loops",
    title: "Prefer loose array bounds checks in loops",
    description: "Array bounds checks within loops should verify if a variable is `>=` or `<=` the array length instead of exactly equal to the array length. Performing strict bound checks on arrays in loops is brittle and a common cause of subtle bugs.\n\n```js\nfunction handleTasks() {\n  const tasks = [\n    // ...\n  ]\n  let currentTaskIndex = 0\n\n  do {\n    const currentTask = tasks[currentTaskIndex]\n\n    // process task\n    // ...\n\n    currentTaskIndex++\n  } while (currentTaskIndex !== tasks.length)\n}\n```\n\nThis example has two bugs:\n\n- if `tasks` is empty, the first iteration of the while loop will throw an error\n- the `while` loop guard is very brittle which is a code smell. if `currentTaskIndex` somehow gets changed in an unexpected way with future code changes, then the `while` loop guard could end up going past the end of the tasks array!\n\nAn improved version of this code which fixes these buse looks like:\n\n```js\nfunction handleTasks() {\n  const tasks = [\n    // ...\n  ]\n  let currentTaskIndex = 0\n\n  while (currentTaskIndex < tasks.length) {\n    const currentTask = tasks[currentTaskIndex]\n\n    // process task\n    // ...\n\n    currentTaskIndex++\n  }\n}\n```\n",
    positiveExamples: [
      {
        code: "for (let i = 0; i < arr.length; i++) {}",
        language: "js"
      },
      {
        code: "for (let i = arr.length; i >= 0; i--) {}",
        language: "ts"
      },
      {
        code: "while (i < tasks.length) {\n  ++i\n}",
        language: "js"
      }
    ],
    negativeExamples: [
      {
        code: "for (let i = 0; i !== arr.length; i++) {\n  // this is bad because it should use `i < arr.length` to be safer\n}",
        language: "js"
      },
      {
        code: "for (let i = arr.length; i !== -1; i--) {\n  // this is bad because it should use `i >= 0` or `i > -1` to be safer\n}",
        language: "ts"
      },
      {
        code: "while (i !== tasks.length) {\n  // this is bad because it should use `i < tasks.length` to be safer\n  ++i\n}",
        language: "js"
      },
      {
        code: "const length = arr.length\nlet i = 0\nwhile (i !== length) {\n  // this is bad because the while loop should use `i < length` to be safer\n  ++i\n}",
        language: "ts"
      }
    ],
    fixable: false,
    level: "error",
    scope: "file",
    languages: [
      "javascript",
      "typescript"
    ],
    tags: [
      "best practices"
    ],
    exclude: [
      "**/*.test\\.{js,ts,jsx,tsx,cjs,mjs}"
    ],
    gritql: "or {\n  any_equals(a = `$foo.length`, $b),\n  any_not_equals(a = `$foo.length`, $b)\n} as $op where {\n  $op <: within or {\n    do_statement(),\n    while_statement(),\n    for_statement()\n  }\n}"
  },
  {
    source: "/Users/tfischer/dev/modules/gptlint/rules/prefer-types-always-valid-states.md",
    cacheable: true,
    metadata: {},
    name: "prefer-types-always-valid-states",
    title: "Prefer types that always represent valid states",
    description: "A key to effective type design is crafting types that can only represent a valid state. This rule walks through a few examples of how this can go wrong and shows you how to fix them.\n\nAs an example, suppose you\u2019re building a web application that lets you select a page, loads the con\u2010 tent of that page, and then displays it. You might write the state like this:\n\n```ts\ninterface State {\n  pageText: string\n  isLoading: boolean\n  error?: string\n}\n```\n\nWhen you write your code to render the page, you need to consider all of these fields:\n\n```ts\nfunction renderPage(state: State) {\n  if (state.error) {\n    return `Error! Unable to load ${currentPage}: ${state.error}`\n  } else if (state.isLoading) {\n    return `Loading ${currentPage}...`\n  }\n  return `<h1>${currentPage}</h1>\\n${state.pageText}`\n}\n```\n\nIs this right, though? What if `isLoading` and `error` are both set? What would that mean? Is it better to display the loading message or the error message? It\u2019s hard to say! There\u2019s not enough information available.\n\nOr what if you\u2019re writing a `changePage` function? Here\u2019s an attempt:\n\n```ts\nasync function changePage(state: State, newPage: string) {\n  state.isLoading = true\n  try {\n    const response = await fetch(getUrlForPage(newPage))\n    if (!response.ok) {\n      throw new Error(`Unable to load ${newPage}: ${response.statusText}`)\n    }\n    const text = await response.text()\n    state.isLoading = false\n    state.pageText = text\n  } catch (e) {\n    state.error = '' + e\n  }\n}\n```\n\nThere are many problems with this! Here are a few:\n\n- We forgot to set `state.isLoading` to `false` in the error case.\n- We didn\u2019t clear out `state.error`, so if the previous request failed, then you\u2019ll keep seeing that error message instead of a loading message.\n- If the user changes pages again while the page is loading, who knows what will happen. They might see a new page and then an error, or the first page and not the second depending on the order in which the responses come back.\n\nThe problem is that the state includes both too little information (which request failed? which is loading?) and too much: the `State` type allows both `isLoading` and `error` to be set, **even though this represents an invalid state**. This makes both `render()` and `changePage()` impossible to implement well.\n\nHere\u2019s a better way to represent the application state:\n\n```ts\ninterface RequestPending {\n  state: 'pending'\n}\ninterface RequestError {\n  state: 'error'\n  error: string\n}\ninterface RequestSuccess {\n  state: 'ok'\n  pageText: string\n}\ntype RequestState = RequestPending | RequestError | RequestSuccess\ninterface State {\n  currentPage: string\n  requests: { [page: string]: RequestState }\n}\n```\n\nThis uses a tagged union (also known as a \u201Cdiscriminated union\u201D) to explicitly model the different states that a network request can be in. This version of the state is three to four times longer, but it has the enormous advantage of not admitting invalid states. The current page is modeled explicitly, as is the state of every request that you issue. As a result, the `renderPage` and `changePage` functions are easy to implement:\n\n```ts\nfunction renderPage(state: State) {\n  const { currentPage } = state\n  const requestState = state.requests[currentPage]\n\n  switch (requestState.state) {\n    case 'pending':\n      return `Loading ${currentPage}...`\n    case 'error':\n      return `Error! Unable to load ${currentPage}: ${requestState.error}`\n    case 'ok':\n      return `<h1>${currentPage}</h1>\\n${requestState.pageText}`\n  }\n}\n\nasync function changePage(state: State, newPage: string) {\n  state.requests[newPage] = { state: 'pending' }\n  state.currentPage = newPage\n\n  try {\n    const response = await fetch(getUrlForPage(newPage))\n    if (!response.ok) {\n      throw new Error(`Unable to load ${newPage}: ${response.statusText}`)\n    }\n    const pageText = await response.text()\n    state.requests[newPage] = { state: 'ok', pageText }\n  } catch (e) {\n    state.requests[newPage] = { state: 'error', error: '' + e }\n  }\n}\n```\n\nThe ambiguity from the first implementation is entirely gone: it\u2019s clear what the cur\u2010 rent page is, and every request is in exactly one state. If the user changes the page after a request has been issued, that\u2019s no problem either. The old request still com\u2010 pletes, but it doesn\u2019t affect the UI.\n\n---\n\nOftentimes this rule pairs with the ideal of having as little mutable state as possible and preferring to derive state based on a small source of truth which is always valid.\n\nFor example, let's say you have a product resource:\n\n```ts\nclass Product {\n  isInStock: boolean\n  quantityAvailable: number\n}\n```\n\n`Product` has a few problems here:\n\n- `isInStock` can be false with `quantityAvailable > 0` which doesn't make any sense\n- `isInStock` can be true with `quantityAvailable === 0` which doesn't make any sense\n\nThe problem comes from `Product.isInStock` and `Product.quantityAvailable` both representing different aspects of the same underling data: in this case, how much of a product is currently available.\n\nA better solution would be to only store the minimal state necessary to model the `Product`'s valid states, and then derive any additional fields based on the model's minimal, valid state:\n\n```ts\nclass Product {\n  quantityAvailable: number\n\n  get isInStock() {\n    // Derived based on `quantityAvailable` which guarantees that the product's\n    // state is always valid.\n    return this.quantityAvailable > 0\n  }\n}\n```\n\n## Caveats\n\nWhen working with external APIs and data sources, it's not always possible to work with types which only represent valid state. So this rule should ignore any data coming from external dependencies and focus instead on types used internally within this project.\n\n## Key Takeaways\n\nTypes that represent both valid and invalid states are likely to lead to confusing and error-prone code.\n\nPrefer types that only represent valid states. Even if they are longer or harder to express, they will save you time and pain in the end.\n\nIf a field is useful, but adding it to a type could result the type representing invalid states, then consider whether that field can be derived from a minimal set of state that is always valid.\n",
    positiveExamples: [],
    negativeExamples: [],
    fixable: false,
    level: "error",
    scope: "file",
    languages: [
      "typescript"
    ],
    tags: [
      "best practices"
    ],
    resources: [
      "https://effectivetypescript.com"
    ],
    exclude: [
      "**/*\\.test\\.{js,ts,jsx,tsx,cjs,mjs}",
      "**/*\\.{js,cjs,mjs,json}"
    ],
    gritql: "or {\n  type_alias_declaration(),\n  interface_declaration()\n}",
    gritqlNumLinesContext: 3
  },
  {
    source: "/Users/tfischer/dev/modules/gptlint/rules/react-avoid-class-components.md",
    cacheable: true,
    metadata: {},
    name: "react-avoid-class-components",
    title: "Don't use React class components",
    description: "React class components are deprecated. Use React functions and hooks instead.\n\nNote that uses `classes` is fine for non-react components.\n",
    positiveExamples: [
      {
        code: "export function Button() {\n  return <div>Hello</div>\n}",
        language: "tsx"
      },
      {
        code: "import EventEmitter from 'eventemitter3'\n\n// This is fine because it is a normal class and not a React component.\nclass Foo extends EventEmitter {\n  constructor() {}\n}",
        language: "ts"
      }
    ],
    negativeExamples: [
      {
        code: "import { Component } from 'react'\n\nexport class Label extends Component {\n  render() {\n    return <div>Hello</div>\n  }\n}",
        language: "tsx"
      },
      {
        code: "import react from 'react'\n\nexport class Label extends react.Component {\n  render() {\n    return <div />\n  }\n}",
        language: "tsx"
      }
    ],
    fixable: false,
    level: "error",
    scope: "file",
    languages: [
      "javascript",
      "typescript"
    ],
    tags: [
      "react"
    ],
    eslint: [
      "eslint-plugin-react-prefer-function-component"
    ],
    include: [
      "**/*.{jsx,tsx}"
    ],
    gritql: "react_class_component"
  },
  {
    source: "/Users/tfischer/dev/modules/gptlint/rules/semantic-variable-names.md",
    cacheable: true,
    metadata: {},
    name: "semantic-variable-names",
    title: "Use semantic variable names",
    description: "Variable names should be descriptive and capture the semantics of the value they represent. This makes it easier to read and understand code. It also makes it clearer when variables are being misused.\n\n## Caveats\n\nAn exception to this rule is that it is acceptable to use simple variable names like `i` in `for` loops.\n\nAn exception to this rule is that math-heavy code may use simple variable names within the scope of a mathematically dense function.\n\nCommon acronyms like `api`, `ast`, and `llm` are fine even though they aren't as descriptive.\n\n`res`, `result`, and `data` are common exceptions that are okay to ignore.\n\nVariables names which mirror the corresponding type name are okay to ignore.\n\nKeys in objects and JS/TS strings are not variable names, so they should be ignored.\n\nIf a value isn't a variable name, then it should be ignored.\n\nThis rule should be ignored in test files.\n\nThe names of file imports from third-party APIs and modules should be ignored because we have no control over them.\n\nIf you are unsure whether or not a variable name is descriptive enough, err on the side of caution by setting `confidence` to `low`.\n",
    positiveExamples: [
      {
        code: '// Good because "numTokens" is descriptive\nconst numTokens = 5\n\n// Good because "isFinished" is descriptive\nconst isFinished = true\n\n// Good because "ast" is an acronym\nconst ast = parseAST()\n\n// Good because "fileTypeToParserMap" is very descriptive\nconst fileTypeToParserMap: Record<string, string> = {}',
        language: "ts"
      },
      {
        code: '// "i" is okay here because it is a simple for loop\nfor (let i = 0; i < 10; i++) {}',
        language: "ts"
      },
      {
        code: '// "x", "y", and "r" are all okay here because they represent real, mathematical\n// concepts, and concise variable names are often preferred in math-heavy code.\nfunction normalDist(mu = 0, sigma = 1) {\n  let x: number, y: number, r: number\n\n  do {\n    x = Math.random() * 2 - 1\n    y = Math.random() * 2 - 1\n    r = x * x + y * y\n  } while (!r || r > 1)\n\n  return mu + sigma * y * Math.sqrt((-2 * Math.log(r)) / r)\n}',
        language: "ts"
      },
      {
        code: "// These are fine because the simple variable names match the corresponding type names.\nconst rule: Rule = {}\nconst data: Data = {}",
        language: "ts"
      },
      {
        code: "// This is fine because `z` is an external dependency that we have no control over.\nimport { z } from 'zod'",
        language: "ts"
      }
    ],
    negativeExamples: [
      {
        code: '// Bad because "a" is not a descriptive variable name\nconst a = 5\n\n// Bad because "b" is not a descriptive variable name\nconst b = false',
        language: "ts"
      },
      {
        code: `// Bad because "obj" is not a descriptive variable name
const obj = { id: 5, name: 'Bob' }`,
        language: "js"
      }
    ],
    fixable: false,
    level: "error",
    scope: "file",
    languages: [
      "javascript",
      "typescript"
    ],
    tags: [
      "best practices"
    ],
    exclude: [
      "**/*\\.test\\.{js,ts,jsx,tsx,cjs,mjs}"
    ],
    gritql: "identifier() as $id where {\n  or {\n    and {\n      $id <: within or {\n        variable_declarator($name),\n        required_parameter($name),\n        optional_parameter($name)\n      },\n      $id <: $name\n    },\n\n    or {\n      and {\n        $id <: within `function $func($props): $ret {$body}`,\n        $id <: not or { within $body, within $func }\n      },\n      and {\n        $id <: within `function $func($props) {$body}`,\n        $id <: not or { within $body, within $func }\n      },\n      and {\n        $id <: within `($props) => $body`,\n        $id <: not within $body\n      }\n    }\n  }\n}",
    gritqlNumLinesContext: 2
  },
  {
    source: "/Users/tfischer/dev/modules/gptlint/rules/soc2-no-leak-user-data.md",
    cacheable: true,
    metadata: {},
    name: "soc2-no-leak-user-data",
    title: "SOC2 Don't leak user data",
    description: "Don't log potentially sensitive customer data or we'll lose our SOC2 certification.\n\nNon-identifying user data such as internal IDs or other internal models related to a user are fine to log and expose.\n",
    positiveExamples: [
      {
        code: "// Logging non-identifying user data such as internal IDs is fine\nconsole.log(user.id)",
        language: "js"
      },
      {
        code: "// Logging non-identifying user data such as internal IDs is fine\nlogger.warn(`Invalid user: ${user.id}`)",
        language: "js"
      },
      {
        code: "// Exposing non-identifying user data such as internal IDs is fine\nthrow new Error(`User error ${user.id}`)",
        language: "ts"
      },
      {
        code: "// Logging internal resources related to a user is okay\nconsole.log(user.posts)",
        language: "js"
      }
    ],
    negativeExamples: [
      {
        code: "// Don't log potentially sensitive user data\nconsole.log(user)",
        language: "js"
      },
      {
        code: "// Don't log potentially sensitive user data\nlog.info(user)",
        language: "js"
      },
      {
        code: "// Don't log sensitive user information like `email`\nconsole.error('Invalid user', user.email)",
        language: "js"
      },
      {
        code: "// Don't log request bodies which may contain sensitive user data\nlog.info({ body: req.body })",
        language: "js"
      },
      {
        code: "// Don't expose request bodies which may contain sensitive user data\nthrow new Error('error', { body: req.body })",
        language: "js"
      }
    ],
    fixable: false,
    level: "error",
    scope: "file",
    languages: [
      "javascript",
      "typescript"
    ],
    tags: [
      "security"
    ],
    gritql: "or {\n  `console.$method($args)`,\n  `logger.$method($args)`,\n  `log.$method($args)`,\n  `throw new $Error($msg)`\n}",
    gritqlNumLinesContext: 2
  },
  {
    source: "/Users/tfischer/dev/modules/gptlint/rules/use-correct-english.md",
    cacheable: true,
    metadata: {},
    name: "use-correct-english",
    title: "Docs should use correct English spelling and grammar",
    description: "All comments and documentation should use correct English spelling and grammar. Obvious spelling errors should be repoted as violations.\n\nThis rule applies to code comments, JSDoc comments, and markdown documentation.\n\n## Caveats\n\nThis rule does *not* apply to code identifiers (variable names, function names, type names, etc) which often use shorthand.\n\nThis rule also does not apply to `TODO` comments.\n",
    positiveExamples: [],
    negativeExamples: [
      {
        code: "This is a violation becuse it includs spelling errors.",
        language: "md"
      },
      {
        code: "This example uses broken english grammar because bad.",
        language: "md"
      }
    ],
    fixable: false,
    level: "error",
    scope: "file",
    tags: [
      "best practices"
    ],
    gritql: "comment"
  }
];

// src/default-config.ts
var ruleDefinitions = [
  ...built_in_rules_default,
  ...Object.values(custom_exports)
];
var ruleSettings = Object.fromEntries(
  ruleDefinitions.map((rule) => [rule.name, "error"])
);
var recommendedConfig = [
  {
    files: defaultFiles,
    ruleDefinitions,
    rules: ruleSettings
  }
];

// src/resolve-config.ts
async function resolveLinterConfig2(cliConfigOverride, opts) {
  const configsToCheck = [
    opts.configFilePath,
    "gptlint.config.js",
    "gptlint.config.mjs",
    "gptlint.config.cjs"
  ].filter(Boolean);
  let configs = [];
  if (opts.linterConfigDefaults) {
    configs.push(opts.linterConfigDefaults);
  }
  configs.push(defaultLinterConfig);
  let hasProjectConfig = false;
  for (const configFileRelativePath of configsToCheck) {
    const configFilePath = path9.resolve(opts.cwd, configFileRelativePath);
    if (!await pathExists2(configFilePath)) {
      if (configFileRelativePath === opts.configFilePath) {
        throw new Error(`Error missing config file "${opts.configFilePath}"`);
      }
      continue;
    }
    const configFile = await import(configFilePath);
    default4(
      configFile == null ? void 0 : configFile.default,
      `Config file "${configFilePath}" must have a default export containing a valid config array`
    );
    const rawConfigs = configFile.default;
    default4(
      Array.isArray(rawConfigs),
      `Config file "${configFilePath}" must have a default export containing a valid config array`
    );
    for (const rawConfig of rawConfigs) {
      const config = parseLinterConfig(rawConfig);
      configs.push(config);
    }
    hasProjectConfig = true;
    break;
  }
  if (!hasProjectConfig) {
    configs = configs.concat(recommendedConfig);
  }
  return new ResolvedLinterConfig({ configs, cliConfigOverride });
}

// src/resolve-cli-config.ts
async function resolveLinterCLIConfig(cliArgs, {
  name,
  cwd,
  linterConfigDefaults,
  flagsToAdd
}) {
  const args = cli(
    {
      name,
      parameters: ["[file/dir/glob ...]"],
      flags: {
        ...flagsToAdd,
        config: {
          type: String,
          description: "Path to a configuration file",
          alias: "c"
        },
        rules: {
          type: [String],
          description: "Glob pattern to rule definition markdown files.",
          alias: "r"
        },
        ignoreFile: {
          type: String,
          description: "Path to file containing ignore patterns",
          default: ".gptlintignore"
        },
        ignorePattern: {
          type: [String],
          description: "Pattern of files to ignore (in addition to .gptlintignore)"
        },
        noIgnore: {
          type: Boolean,
          description: "Disables the use of ignore files and patterns"
        },
        noInlineConfig: {
          type: Boolean,
          description: "Disables the use of inline rule config inside of source files"
        },
        noCache: {
          type: Boolean,
          description: "Disables caching",
          alias: "C"
        },
        noGrit: {
          type: Boolean,
          description: "Disables grit",
          alias: "G"
        },
        cacheDir: {
          type: String,
          description: "Customize the path to the cache directory"
        },
        concurrency: {
          type: Number,
          description: "Limits the maximum number of concurrent tasks"
        },
        debug: {
          type: Boolean,
          description: "Enables debug logging",
          alias: "d"
        },
        dryRun: {
          type: Boolean,
          description: "Disables all external LLM calls and outputs an estimate of what it would cost to run the linter on the given config"
        },
        printConfig: {
          type: Boolean,
          description: "When enabled, logs the resolved config and parsed rules and then exits"
        },
        debugModel: {
          type: Boolean,
          description: "Enables verbose LLM logging",
          alias: "D"
        },
        debugGrit: {
          type: Boolean,
          description: "Enables verbose Grit logging",
          alias: "g"
        },
        noDebugStats: {
          type: Boolean,
          description: "Disables logging of cumulative LLM stats, including total tokens and cost (logging LLM stats is enabled by default)",
          alias: "S"
        },
        earlyExit: {
          type: Boolean,
          description: "Exits after finding the first error",
          alias: "e"
        },
        apiKey: {
          type: String,
          description: "API key for the OpenAI-compatible LLM API. Defaults to the value of the `OPENAI_API_KEY` environment variable.",
          alias: "k"
        },
        apiOrganizationId: {
          type: String,
          description: "Optional organization ID that should be billed for LLM API requests. This is only necessary if your OpenAI API key is scoped to multiple organizations."
        },
        apiBaseUrl: {
          type: String,
          description: "Base URL for the LLM API to use which must be compatible with the OpenAI chat completions API. Defaults to the OpenAI API."
        },
        model: {
          type: String,
          description: "Which LLM to use for assessing rule conformance. Defaults to gpt-4.",
          alias: "m"
        },
        weakModel: {
          type: String,
          description: 'Which weak LLM to use for assessing rule conformance (optional; used for multi-pass linting; set to "none" to disable two-pass linting). Defaults to gpt-4o-mini.',
          alias: "M"
        },
        temperature: {
          type: Number,
          description: "LLM temperature parameter"
        }
      }
    },
    () => {
    },
    cliArgs
  );
  if (Object.keys(args.unknownFlags).length > 0) {
    const message = `Error unknown ${plur5("flag", Object.keys(args.unknownFlags).length)}: ${Object.keys(args.unknownFlags).join(", ")}`;
    console.error(`${message}
`);
    args.showHelp();
    gracefulExit2(1);
    throw new Error(message);
  }
  const files = args._.fileDirGlob.slice(2);
  let ignores = args.flags.noIgnore ? [] : args.flags.ignorePattern;
  if (args.flags.ignoreFile && !args.flags.noIgnore) {
    if (await pathExists3(args.flags.ignoreFile)) {
      const ignoreFileContent = await readFile(args.flags.ignoreFile, {
        encoding: "utf8"
      });
      const ignoreFile = `
${ignoreFileContent}
`;
      const { patterns: ignoreFilePatterns } = parseGitIgnore(ignoreFile);
      ignores = ignores.concat(ignoreFilePatterns);
    }
  }
  const cliLinterConfig = parseLinterConfig({
    files: files.length > 0 ? files : void 0,
    ignores: ignores.length > 0 ? ignores : void 0,
    ruleFiles: args.flags.rules.length > 0 ? args.flags.rules : void 0,
    linterOptions: {
      noInlineConfig: args.flags.noInlineConfig,
      earlyExit: args.flags.earlyExit,
      concurrency: args.flags.concurrency,
      debug: args.flags.debug,
      printConfig: args.flags.printConfig,
      debugModel: args.flags.debugModel,
      debugGrit: args.flags.debugGrit,
      debugStats: args.flags.noDebugStats === void 0 ? void 0 : !args.flags.noDebugStats,
      noCache: args.flags.noCache,
      noGrit: args.flags.noGrit,
      dryRun: args.flags.dryRun,
      cacheDir: args.flags.cacheDir
    },
    llmOptions: {
      model: args.flags.model,
      weakModel: args.flags.weakModel,
      temperature: args.flags.temperature,
      apiKey: args.flags.apiKey,
      apiOrganizationId: args.flags.apiOrganizationId,
      apiBaseUrl: args.flags.apiBaseUrl
    }
  });
  const linterConfig = await resolveLinterConfig2(cliLinterConfig, {
    cwd,
    configFilePath: args.flags.config,
    linterConfigDefaults
  });
  return {
    args,
    linterConfig
  };
}

// bin/gptlint.ts
async function main() {
  restoreCursor();
  const cwd = process.cwd();
  const { args, linterConfig: config } = await resolveLinterCLIConfig(
    process.argv,
    {
      name: "gptlint",
      cwd
    }
  );
  let files;
  let rules;
  try {
    ;
    [files, rules] = await Promise.all([
      resolveFiles({ cwd, config }),
      resolveRules({ cwd, config })
    ]);
  } catch (err) {
    console.error(
      "Unexpected error initializing linter via config",
      err,
      "\n\n"
    );
    args.showHelp();
    return gracefulExit3(1);
  }
  if (!validateLinterInputs({ files, rules, config })) {
    return;
  }
  const chatModel = createChatModel(config);
  const cache = await createLinterCache(config);
  const lintResult = await lintFiles({
    files,
    rules,
    config,
    cache,
    chatModel,
    cwd
  });
  if (config.linterOptions.debugStats) {
    logLintResultStats({ lintResult, config });
  }
  if (config.linterOptions.dryRun) {
    return gracefulExit3(0);
  }
  if (lintResult.lintErrors.length > 0) {
    console.log(
      `
${chalk2.bold("lint errors:")}`,
      JSON.stringify(lintResult.lintErrors, void 0, 2)
    );
    console.log(
      `
${chalk2.bold(
        `found ${lintResult.lintErrors.length} lint ${plur6(
          "error",
          lintResult.lintErrors.length
        )}`
      )}`
    );
    return gracefulExit3(1);
  } else {
    console.log(`
${chalk2.bold("no lint errors")} \u{1F389}`);
    return gracefulExit3(0);
  }
}
try {
  await main();
} catch (err) {
  console.error("Unexpected error", err);
  gracefulExit3(1);
}
//# sourceMappingURL=gptlint.js.map